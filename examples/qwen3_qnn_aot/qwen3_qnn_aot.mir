@main () -> () {
    graph.SubGraphOp @init <notype> [symbol:init] {
        () -> () {
            tensor.CPU.register () -> (%361:tensor<[151936, 2048], Float32, CPU>[@model.embed_tokens.weight][quant_recipe:QuantSpec(Raw(type: Float32), uuid=61), symbol:model.embed_tokens.weight])[symbol:model.embed_tokens.weight]
            tensor.CPU.register () -> (%8204:tensor<[1024, 5, 128], UInt16PerTensor, CPU>[@rope_sin][symbol:rope_sin])[symbol:rope_sin]
            tensor.CPU.register () -> (%8205:tensor<[1024, 5, 128], UInt16PerTensor, CPU>[@rope_cos][symbol:rope_cos])[symbol:rope_cos]
            tensor.CPU.register () -> (%4256:tensor<[2048], Float32, CPU>[@model.layers.0.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=67), symbol:model.layers.0.input_layernorm.weight])[symbol:model.layers.0.input_layernorm.weight]
            tensor.CPU.register () -> (%6100:tensor<[2048, 2048], Float32, CPU>[@model.layers.0.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=68), symbol:model.layers.0.self_attn.q_proj.weight])[symbol:model.layers.0.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%326:tensor<[1024, 2048], Float32, CPU>[@model.layers.0.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=70), symbol:model.layers.0.self_attn.k_proj.weight])[symbol:model.layers.0.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%4416:tensor<[1024, 2048], Float32, CPU>[@model.layers.0.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=72), symbol:model.layers.0.self_attn.v_proj.weight])[symbol:model.layers.0.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%7842:tensor<[128], Float32, CPU>[@model.layers.0.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=75), symbol:model.layers.0.self_attn.q_norm.weight])[symbol:model.layers.0.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%8182:tensor<[128], Float32, CPU>[@model.layers.0.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=77), symbol:model.layers.0.self_attn.k_norm.weight])[symbol:model.layers.0.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%7659:tensor<[2048, 2048], Float32, CPU>[@model.layers.0.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=90), symbol:model.layers.0.self_attn.o_proj.weight])[symbol:model.layers.0.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%875:tensor<[2048], Float32, CPU>[@model.layers.0.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=93), symbol:model.layers.0.post_attention_layernorm.weight])[symbol:model.layers.0.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%6720:tensor<[6144, 2048], Float32, CPU>[@model.layers.0.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=94), symbol:model.layers.0.mlp.up_proj.weight])[symbol:model.layers.0.mlp.up_proj.weight]
            tensor.CPU.register () -> (%2083:tensor<[6144, 2048], Float32, CPU>[@model.layers.0.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=96), symbol:model.layers.0.mlp.gate_proj.weight])[symbol:model.layers.0.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%1968:tensor<[2048, 6144], Float32, CPU>[@model.layers.0.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=99), symbol:model.layers.0.mlp.down_proj.weight])[symbol:model.layers.0.mlp.down_proj.weight]
            tensor.CPU.register () -> (%2912:tensor<[2048], Float32, CPU>[@model.layers.1.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=102), symbol:model.layers.1.input_layernorm.weight])[symbol:model.layers.1.input_layernorm.weight]
            tensor.CPU.register () -> (%2564:tensor<[2048, 2048], Float32, CPU>[@model.layers.1.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=103), symbol:model.layers.1.self_attn.q_proj.weight])[symbol:model.layers.1.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%3192:tensor<[1024, 2048], Float32, CPU>[@model.layers.1.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=105), symbol:model.layers.1.self_attn.k_proj.weight])[symbol:model.layers.1.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%3127:tensor<[1024, 2048], Float32, CPU>[@model.layers.1.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=107), symbol:model.layers.1.self_attn.v_proj.weight])[symbol:model.layers.1.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%6782:tensor<[128], Float32, CPU>[@model.layers.1.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=110), symbol:model.layers.1.self_attn.q_norm.weight])[symbol:model.layers.1.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%5890:tensor<[128], Float32, CPU>[@model.layers.1.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=112), symbol:model.layers.1.self_attn.k_norm.weight])[symbol:model.layers.1.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%683:tensor<[2048, 2048], Float32, CPU>[@model.layers.1.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=125), symbol:model.layers.1.self_attn.o_proj.weight])[symbol:model.layers.1.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%181:tensor<[2048], Float32, CPU>[@model.layers.1.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=128), symbol:model.layers.1.post_attention_layernorm.weight])[symbol:model.layers.1.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%2963:tensor<[6144, 2048], Float32, CPU>[@model.layers.1.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=129), symbol:model.layers.1.mlp.up_proj.weight])[symbol:model.layers.1.mlp.up_proj.weight]
            tensor.CPU.register () -> (%5173:tensor<[6144, 2048], Float32, CPU>[@model.layers.1.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=131), symbol:model.layers.1.mlp.gate_proj.weight])[symbol:model.layers.1.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%5467:tensor<[2048, 6144], Float32, CPU>[@model.layers.1.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=134), symbol:model.layers.1.mlp.down_proj.weight])[symbol:model.layers.1.mlp.down_proj.weight]
            tensor.CPU.register () -> (%2379:tensor<[2048], Float32, CPU>[@model.layers.2.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=137), symbol:model.layers.2.input_layernorm.weight])[symbol:model.layers.2.input_layernorm.weight]
            tensor.CPU.register () -> (%3865:tensor<[2048, 2048], Float32, CPU>[@model.layers.2.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=138), symbol:model.layers.2.self_attn.q_proj.weight])[symbol:model.layers.2.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%1586:tensor<[1024, 2048], Float32, CPU>[@model.layers.2.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=140), symbol:model.layers.2.self_attn.k_proj.weight])[symbol:model.layers.2.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%4803:tensor<[1024, 2048], Float32, CPU>[@model.layers.2.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=142), symbol:model.layers.2.self_attn.v_proj.weight])[symbol:model.layers.2.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%6973:tensor<[128], Float32, CPU>[@model.layers.2.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=145), symbol:model.layers.2.self_attn.q_norm.weight])[symbol:model.layers.2.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%1763:tensor<[128], Float32, CPU>[@model.layers.2.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=147), symbol:model.layers.2.self_attn.k_norm.weight])[symbol:model.layers.2.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%6817:tensor<[2048, 2048], Float32, CPU>[@model.layers.2.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=160), symbol:model.layers.2.self_attn.o_proj.weight])[symbol:model.layers.2.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%984:tensor<[2048], Float32, CPU>[@model.layers.2.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=163), symbol:model.layers.2.post_attention_layernorm.weight])[symbol:model.layers.2.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%1952:tensor<[6144, 2048], Float32, CPU>[@model.layers.2.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=164), symbol:model.layers.2.mlp.up_proj.weight])[symbol:model.layers.2.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6793:tensor<[6144, 2048], Float32, CPU>[@model.layers.2.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=166), symbol:model.layers.2.mlp.gate_proj.weight])[symbol:model.layers.2.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%7125:tensor<[2048, 6144], Float32, CPU>[@model.layers.2.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=169), symbol:model.layers.2.mlp.down_proj.weight])[symbol:model.layers.2.mlp.down_proj.weight]
            tensor.CPU.register () -> (%1636:tensor<[2048], Float32, CPU>[@model.layers.3.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=172), symbol:model.layers.3.input_layernorm.weight])[symbol:model.layers.3.input_layernorm.weight]
            tensor.CPU.register () -> (%5214:tensor<[2048, 2048], Float32, CPU>[@model.layers.3.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=173), symbol:model.layers.3.self_attn.q_proj.weight])[symbol:model.layers.3.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%6900:tensor<[1024, 2048], Float32, CPU>[@model.layers.3.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=175), symbol:model.layers.3.self_attn.k_proj.weight])[symbol:model.layers.3.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%2141:tensor<[1024, 2048], Float32, CPU>[@model.layers.3.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=177), symbol:model.layers.3.self_attn.v_proj.weight])[symbol:model.layers.3.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%3669:tensor<[128], Float32, CPU>[@model.layers.3.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=180), symbol:model.layers.3.self_attn.q_norm.weight])[symbol:model.layers.3.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%4334:tensor<[128], Float32, CPU>[@model.layers.3.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=182), symbol:model.layers.3.self_attn.k_norm.weight])[symbol:model.layers.3.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%8150:tensor<[2048, 2048], Float32, CPU>[@model.layers.3.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=195), symbol:model.layers.3.self_attn.o_proj.weight])[symbol:model.layers.3.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%4105:tensor<[2048], Float32, CPU>[@model.layers.3.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=198), symbol:model.layers.3.post_attention_layernorm.weight])[symbol:model.layers.3.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%6926:tensor<[6144, 2048], Float32, CPU>[@model.layers.3.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=199), symbol:model.layers.3.mlp.up_proj.weight])[symbol:model.layers.3.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6632:tensor<[6144, 2048], Float32, CPU>[@model.layers.3.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=201), symbol:model.layers.3.mlp.gate_proj.weight])[symbol:model.layers.3.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%1818:tensor<[2048, 6144], Float32, CPU>[@model.layers.3.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=204), symbol:model.layers.3.mlp.down_proj.weight])[symbol:model.layers.3.mlp.down_proj.weight]
            tensor.CPU.register () -> (%269:tensor<[2048], Float32, CPU>[@model.layers.4.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=207), symbol:model.layers.4.input_layernorm.weight])[symbol:model.layers.4.input_layernorm.weight]
            tensor.CPU.register () -> (%973:tensor<[2048, 2048], Float32, CPU>[@model.layers.4.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=208), symbol:model.layers.4.self_attn.q_proj.weight])[symbol:model.layers.4.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%6187:tensor<[1024, 2048], Float32, CPU>[@model.layers.4.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=210), symbol:model.layers.4.self_attn.k_proj.weight])[symbol:model.layers.4.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%6381:tensor<[1024, 2048], Float32, CPU>[@model.layers.4.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=212), symbol:model.layers.4.self_attn.v_proj.weight])[symbol:model.layers.4.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%466:tensor<[128], Float32, CPU>[@model.layers.4.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=215), symbol:model.layers.4.self_attn.q_norm.weight])[symbol:model.layers.4.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%6834:tensor<[128], Float32, CPU>[@model.layers.4.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=217), symbol:model.layers.4.self_attn.k_norm.weight])[symbol:model.layers.4.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%7756:tensor<[2048, 2048], Float32, CPU>[@model.layers.4.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=230), symbol:model.layers.4.self_attn.o_proj.weight])[symbol:model.layers.4.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%4372:tensor<[2048], Float32, CPU>[@model.layers.4.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=233), symbol:model.layers.4.post_attention_layernorm.weight])[symbol:model.layers.4.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%6103:tensor<[6144, 2048], Float32, CPU>[@model.layers.4.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=234), symbol:model.layers.4.mlp.up_proj.weight])[symbol:model.layers.4.mlp.up_proj.weight]
            tensor.CPU.register () -> (%2402:tensor<[6144, 2048], Float32, CPU>[@model.layers.4.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=236), symbol:model.layers.4.mlp.gate_proj.weight])[symbol:model.layers.4.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%355:tensor<[2048, 6144], Float32, CPU>[@model.layers.4.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=239), symbol:model.layers.4.mlp.down_proj.weight])[symbol:model.layers.4.mlp.down_proj.weight]
            tensor.CPU.register () -> (%7342:tensor<[2048], Float32, CPU>[@model.layers.5.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=242), symbol:model.layers.5.input_layernorm.weight])[symbol:model.layers.5.input_layernorm.weight]
            tensor.CPU.register () -> (%756:tensor<[2048, 2048], Float32, CPU>[@model.layers.5.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=243), symbol:model.layers.5.self_attn.q_proj.weight])[symbol:model.layers.5.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%7540:tensor<[1024, 2048], Float32, CPU>[@model.layers.5.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=245), symbol:model.layers.5.self_attn.k_proj.weight])[symbol:model.layers.5.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%1477:tensor<[1024, 2048], Float32, CPU>[@model.layers.5.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=247), symbol:model.layers.5.self_attn.v_proj.weight])[symbol:model.layers.5.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%3429:tensor<[128], Float32, CPU>[@model.layers.5.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=250), symbol:model.layers.5.self_attn.q_norm.weight])[symbol:model.layers.5.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%2834:tensor<[128], Float32, CPU>[@model.layers.5.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=252), symbol:model.layers.5.self_attn.k_norm.weight])[symbol:model.layers.5.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%8077:tensor<[2048, 2048], Float32, CPU>[@model.layers.5.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=265), symbol:model.layers.5.self_attn.o_proj.weight])[symbol:model.layers.5.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%5901:tensor<[2048], Float32, CPU>[@model.layers.5.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=268), symbol:model.layers.5.post_attention_layernorm.weight])[symbol:model.layers.5.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%769:tensor<[6144, 2048], Float32, CPU>[@model.layers.5.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=269), symbol:model.layers.5.mlp.up_proj.weight])[symbol:model.layers.5.mlp.up_proj.weight]
            tensor.CPU.register () -> (%1874:tensor<[6144, 2048], Float32, CPU>[@model.layers.5.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=271), symbol:model.layers.5.mlp.gate_proj.weight])[symbol:model.layers.5.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%4892:tensor<[2048, 6144], Float32, CPU>[@model.layers.5.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=274), symbol:model.layers.5.mlp.down_proj.weight])[symbol:model.layers.5.mlp.down_proj.weight]
            tensor.CPU.register () -> (%3540:tensor<[2048], Float32, CPU>[@model.layers.6.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=277), symbol:model.layers.6.input_layernorm.weight])[symbol:model.layers.6.input_layernorm.weight]
            tensor.CPU.register () -> (%4173:tensor<[2048, 2048], Float32, CPU>[@model.layers.6.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=278), symbol:model.layers.6.self_attn.q_proj.weight])[symbol:model.layers.6.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%877:tensor<[1024, 2048], Float32, CPU>[@model.layers.6.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=280), symbol:model.layers.6.self_attn.k_proj.weight])[symbol:model.layers.6.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%1344:tensor<[1024, 2048], Float32, CPU>[@model.layers.6.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=282), symbol:model.layers.6.self_attn.v_proj.weight])[symbol:model.layers.6.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%7487:tensor<[128], Float32, CPU>[@model.layers.6.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=285), symbol:model.layers.6.self_attn.q_norm.weight])[symbol:model.layers.6.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%5126:tensor<[128], Float32, CPU>[@model.layers.6.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=287), symbol:model.layers.6.self_attn.k_norm.weight])[symbol:model.layers.6.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%3940:tensor<[2048, 2048], Float32, CPU>[@model.layers.6.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=300), symbol:model.layers.6.self_attn.o_proj.weight])[symbol:model.layers.6.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%5378:tensor<[2048], Float32, CPU>[@model.layers.6.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=303), symbol:model.layers.6.post_attention_layernorm.weight])[symbol:model.layers.6.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%4973:tensor<[6144, 2048], Float32, CPU>[@model.layers.6.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=304), symbol:model.layers.6.mlp.up_proj.weight])[symbol:model.layers.6.mlp.up_proj.weight]
            tensor.CPU.register () -> (%7150:tensor<[6144, 2048], Float32, CPU>[@model.layers.6.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=306), symbol:model.layers.6.mlp.gate_proj.weight])[symbol:model.layers.6.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%5276:tensor<[2048, 6144], Float32, CPU>[@model.layers.6.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=309), symbol:model.layers.6.mlp.down_proj.weight])[symbol:model.layers.6.mlp.down_proj.weight]
            tensor.CPU.register () -> (%1865:tensor<[2048], Float32, CPU>[@model.layers.7.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=312), symbol:model.layers.7.input_layernorm.weight])[symbol:model.layers.7.input_layernorm.weight]
            tensor.CPU.register () -> (%7715:tensor<[2048, 2048], Float32, CPU>[@model.layers.7.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=313), symbol:model.layers.7.self_attn.q_proj.weight])[symbol:model.layers.7.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%1658:tensor<[1024, 2048], Float32, CPU>[@model.layers.7.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=315), symbol:model.layers.7.self_attn.k_proj.weight])[symbol:model.layers.7.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%5896:tensor<[1024, 2048], Float32, CPU>[@model.layers.7.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=317), symbol:model.layers.7.self_attn.v_proj.weight])[symbol:model.layers.7.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%7733:tensor<[128], Float32, CPU>[@model.layers.7.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=320), symbol:model.layers.7.self_attn.q_norm.weight])[symbol:model.layers.7.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%1643:tensor<[128], Float32, CPU>[@model.layers.7.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=322), symbol:model.layers.7.self_attn.k_norm.weight])[symbol:model.layers.7.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%2968:tensor<[2048, 2048], Float32, CPU>[@model.layers.7.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=335), symbol:model.layers.7.self_attn.o_proj.weight])[symbol:model.layers.7.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%2978:tensor<[2048], Float32, CPU>[@model.layers.7.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=338), symbol:model.layers.7.post_attention_layernorm.weight])[symbol:model.layers.7.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%2994:tensor<[6144, 2048], Float32, CPU>[@model.layers.7.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=339), symbol:model.layers.7.mlp.up_proj.weight])[symbol:model.layers.7.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6231:tensor<[6144, 2048], Float32, CPU>[@model.layers.7.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=341), symbol:model.layers.7.mlp.gate_proj.weight])[symbol:model.layers.7.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%7639:tensor<[2048, 6144], Float32, CPU>[@model.layers.7.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=344), symbol:model.layers.7.mlp.down_proj.weight])[symbol:model.layers.7.mlp.down_proj.weight]
            tensor.CPU.register () -> (%2157:tensor<[2048], Float32, CPU>[@model.layers.8.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=347), symbol:model.layers.8.input_layernorm.weight])[symbol:model.layers.8.input_layernorm.weight]
            tensor.CPU.register () -> (%7895:tensor<[2048, 2048], Float32, CPU>[@model.layers.8.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=348), symbol:model.layers.8.self_attn.q_proj.weight])[symbol:model.layers.8.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%2622:tensor<[1024, 2048], Float32, CPU>[@model.layers.8.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=350), symbol:model.layers.8.self_attn.k_proj.weight])[symbol:model.layers.8.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%5444:tensor<[1024, 2048], Float32, CPU>[@model.layers.8.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=352), symbol:model.layers.8.self_attn.v_proj.weight])[symbol:model.layers.8.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%1167:tensor<[128], Float32, CPU>[@model.layers.8.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=355), symbol:model.layers.8.self_attn.q_norm.weight])[symbol:model.layers.8.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%7773:tensor<[128], Float32, CPU>[@model.layers.8.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=357), symbol:model.layers.8.self_attn.k_norm.weight])[symbol:model.layers.8.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%2063:tensor<[2048, 2048], Float32, CPU>[@model.layers.8.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=370), symbol:model.layers.8.self_attn.o_proj.weight])[symbol:model.layers.8.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%4799:tensor<[2048], Float32, CPU>[@model.layers.8.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=373), symbol:model.layers.8.post_attention_layernorm.weight])[symbol:model.layers.8.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%5512:tensor<[6144, 2048], Float32, CPU>[@model.layers.8.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=374), symbol:model.layers.8.mlp.up_proj.weight])[symbol:model.layers.8.mlp.up_proj.weight]
            tensor.CPU.register () -> (%4801:tensor<[6144, 2048], Float32, CPU>[@model.layers.8.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=376), symbol:model.layers.8.mlp.gate_proj.weight])[symbol:model.layers.8.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%5712:tensor<[2048, 6144], Float32, CPU>[@model.layers.8.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=379), symbol:model.layers.8.mlp.down_proj.weight])[symbol:model.layers.8.mlp.down_proj.weight]
            tensor.CPU.register () -> (%3935:tensor<[2048], Float32, CPU>[@model.layers.9.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=382), symbol:model.layers.9.input_layernorm.weight])[symbol:model.layers.9.input_layernorm.weight]
            tensor.CPU.register () -> (%1754:tensor<[2048, 2048], Float32, CPU>[@model.layers.9.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=383), symbol:model.layers.9.self_attn.q_proj.weight])[symbol:model.layers.9.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%7274:tensor<[1024, 2048], Float32, CPU>[@model.layers.9.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=385), symbol:model.layers.9.self_attn.k_proj.weight])[symbol:model.layers.9.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%4983:tensor<[1024, 2048], Float32, CPU>[@model.layers.9.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=387), symbol:model.layers.9.self_attn.v_proj.weight])[symbol:model.layers.9.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%1127:tensor<[128], Float32, CPU>[@model.layers.9.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=390), symbol:model.layers.9.self_attn.q_norm.weight])[symbol:model.layers.9.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%964:tensor<[128], Float32, CPU>[@model.layers.9.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=392), symbol:model.layers.9.self_attn.k_norm.weight])[symbol:model.layers.9.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%4355:tensor<[2048, 2048], Float32, CPU>[@model.layers.9.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=405), symbol:model.layers.9.self_attn.o_proj.weight])[symbol:model.layers.9.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%4793:tensor<[2048], Float32, CPU>[@model.layers.9.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=408), symbol:model.layers.9.post_attention_layernorm.weight])[symbol:model.layers.9.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%7662:tensor<[6144, 2048], Float32, CPU>[@model.layers.9.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=409), symbol:model.layers.9.mlp.up_proj.weight])[symbol:model.layers.9.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6098:tensor<[6144, 2048], Float32, CPU>[@model.layers.9.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=411), symbol:model.layers.9.mlp.gate_proj.weight])[symbol:model.layers.9.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%333:tensor<[2048, 6144], Float32, CPU>[@model.layers.9.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=414), symbol:model.layers.9.mlp.down_proj.weight])[symbol:model.layers.9.mlp.down_proj.weight]
            tensor.CPU.register () -> (%3044:tensor<[2048], Float32, CPU>[@model.layers.10.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=417), symbol:model.layers.10.input_layernorm.weight])[symbol:model.layers.10.input_layernorm.weight]
            tensor.CPU.register () -> (%208:tensor<[2048, 2048], Float32, CPU>[@model.layers.10.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=418), symbol:model.layers.10.self_attn.q_proj.weight])[symbol:model.layers.10.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%5527:tensor<[1024, 2048], Float32, CPU>[@model.layers.10.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=420), symbol:model.layers.10.self_attn.k_proj.weight])[symbol:model.layers.10.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%2767:tensor<[1024, 2048], Float32, CPU>[@model.layers.10.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=422), symbol:model.layers.10.self_attn.v_proj.weight])[symbol:model.layers.10.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%6433:tensor<[128], Float32, CPU>[@model.layers.10.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=425), symbol:model.layers.10.self_attn.q_norm.weight])[symbol:model.layers.10.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%1215:tensor<[128], Float32, CPU>[@model.layers.10.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=427), symbol:model.layers.10.self_attn.k_norm.weight])[symbol:model.layers.10.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%2136:tensor<[2048, 2048], Float32, CPU>[@model.layers.10.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=440), symbol:model.layers.10.self_attn.o_proj.weight])[symbol:model.layers.10.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%1173:tensor<[2048], Float32, CPU>[@model.layers.10.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=443), symbol:model.layers.10.post_attention_layernorm.weight])[symbol:model.layers.10.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%4087:tensor<[6144, 2048], Float32, CPU>[@model.layers.10.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=444), symbol:model.layers.10.mlp.up_proj.weight])[symbol:model.layers.10.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6334:tensor<[6144, 2048], Float32, CPU>[@model.layers.10.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=446), symbol:model.layers.10.mlp.gate_proj.weight])[symbol:model.layers.10.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%2160:tensor<[2048, 6144], Float32, CPU>[@model.layers.10.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=449), symbol:model.layers.10.mlp.down_proj.weight])[symbol:model.layers.10.mlp.down_proj.weight]
            tensor.CPU.register () -> (%6029:tensor<[2048], Float32, CPU>[@model.layers.11.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=452), symbol:model.layers.11.input_layernorm.weight])[symbol:model.layers.11.input_layernorm.weight]
            tensor.CPU.register () -> (%87:tensor<[2048, 2048], Float32, CPU>[@model.layers.11.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=453), symbol:model.layers.11.self_attn.q_proj.weight])[symbol:model.layers.11.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%6705:tensor<[1024, 2048], Float32, CPU>[@model.layers.11.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=455), symbol:model.layers.11.self_attn.k_proj.weight])[symbol:model.layers.11.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%532:tensor<[1024, 2048], Float32, CPU>[@model.layers.11.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=457), symbol:model.layers.11.self_attn.v_proj.weight])[symbol:model.layers.11.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%2075:tensor<[128], Float32, CPU>[@model.layers.11.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=460), symbol:model.layers.11.self_attn.q_norm.weight])[symbol:model.layers.11.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%5298:tensor<[128], Float32, CPU>[@model.layers.11.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=462), symbol:model.layers.11.self_attn.k_norm.weight])[symbol:model.layers.11.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%6489:tensor<[2048, 2048], Float32, CPU>[@model.layers.11.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=475), symbol:model.layers.11.self_attn.o_proj.weight])[symbol:model.layers.11.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%407:tensor<[2048], Float32, CPU>[@model.layers.11.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=478), symbol:model.layers.11.post_attention_layernorm.weight])[symbol:model.layers.11.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%6171:tensor<[6144, 2048], Float32, CPU>[@model.layers.11.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=479), symbol:model.layers.11.mlp.up_proj.weight])[symbol:model.layers.11.mlp.up_proj.weight]
            tensor.CPU.register () -> (%8146:tensor<[6144, 2048], Float32, CPU>[@model.layers.11.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=481), symbol:model.layers.11.mlp.gate_proj.weight])[symbol:model.layers.11.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%575:tensor<[2048, 6144], Float32, CPU>[@model.layers.11.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=484), symbol:model.layers.11.mlp.down_proj.weight])[symbol:model.layers.11.mlp.down_proj.weight]
            tensor.CPU.register () -> (%861:tensor<[2048], Float32, CPU>[@model.layers.12.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=487), symbol:model.layers.12.input_layernorm.weight])[symbol:model.layers.12.input_layernorm.weight]
            tensor.CPU.register () -> (%1138:tensor<[2048, 2048], Float32, CPU>[@model.layers.12.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=488), symbol:model.layers.12.self_attn.q_proj.weight])[symbol:model.layers.12.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%8178:tensor<[1024, 2048], Float32, CPU>[@model.layers.12.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=490), symbol:model.layers.12.self_attn.k_proj.weight])[symbol:model.layers.12.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%5503:tensor<[1024, 2048], Float32, CPU>[@model.layers.12.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=492), symbol:model.layers.12.self_attn.v_proj.weight])[symbol:model.layers.12.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%5531:tensor<[128], Float32, CPU>[@model.layers.12.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=495), symbol:model.layers.12.self_attn.q_norm.weight])[symbol:model.layers.12.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%7120:tensor<[128], Float32, CPU>[@model.layers.12.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=497), symbol:model.layers.12.self_attn.k_norm.weight])[symbol:model.layers.12.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%3812:tensor<[2048, 2048], Float32, CPU>[@model.layers.12.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=510), symbol:model.layers.12.self_attn.o_proj.weight])[symbol:model.layers.12.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%5701:tensor<[2048], Float32, CPU>[@model.layers.12.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=513), symbol:model.layers.12.post_attention_layernorm.weight])[symbol:model.layers.12.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%1006:tensor<[6144, 2048], Float32, CPU>[@model.layers.12.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=514), symbol:model.layers.12.mlp.up_proj.weight])[symbol:model.layers.12.mlp.up_proj.weight]
            tensor.CPU.register () -> (%4400:tensor<[6144, 2048], Float32, CPU>[@model.layers.12.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=516), symbol:model.layers.12.mlp.gate_proj.weight])[symbol:model.layers.12.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%6759:tensor<[2048, 6144], Float32, CPU>[@model.layers.12.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=519), symbol:model.layers.12.mlp.down_proj.weight])[symbol:model.layers.12.mlp.down_proj.weight]
            tensor.CPU.register () -> (%4069:tensor<[2048], Float32, CPU>[@model.layers.13.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=522), symbol:model.layers.13.input_layernorm.weight])[symbol:model.layers.13.input_layernorm.weight]
            tensor.CPU.register () -> (%6517:tensor<[2048, 2048], Float32, CPU>[@model.layers.13.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=523), symbol:model.layers.13.self_attn.q_proj.weight])[symbol:model.layers.13.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%7247:tensor<[1024, 2048], Float32, CPU>[@model.layers.13.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=525), symbol:model.layers.13.self_attn.k_proj.weight])[symbol:model.layers.13.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%4830:tensor<[1024, 2048], Float32, CPU>[@model.layers.13.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=527), symbol:model.layers.13.self_attn.v_proj.weight])[symbol:model.layers.13.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%7510:tensor<[128], Float32, CPU>[@model.layers.13.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=530), symbol:model.layers.13.self_attn.q_norm.weight])[symbol:model.layers.13.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%1546:tensor<[128], Float32, CPU>[@model.layers.13.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=532), symbol:model.layers.13.self_attn.k_norm.weight])[symbol:model.layers.13.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%4956:tensor<[2048, 2048], Float32, CPU>[@model.layers.13.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=545), symbol:model.layers.13.self_attn.o_proj.weight])[symbol:model.layers.13.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%1863:tensor<[2048], Float32, CPU>[@model.layers.13.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=548), symbol:model.layers.13.post_attention_layernorm.weight])[symbol:model.layers.13.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%4198:tensor<[6144, 2048], Float32, CPU>[@model.layers.13.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=549), symbol:model.layers.13.mlp.up_proj.weight])[symbol:model.layers.13.mlp.up_proj.weight]
            tensor.CPU.register () -> (%3651:tensor<[6144, 2048], Float32, CPU>[@model.layers.13.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=551), symbol:model.layers.13.mlp.gate_proj.weight])[symbol:model.layers.13.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%5457:tensor<[2048, 6144], Float32, CPU>[@model.layers.13.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=554), symbol:model.layers.13.mlp.down_proj.weight])[symbol:model.layers.13.mlp.down_proj.weight]
            tensor.CPU.register () -> (%4807:tensor<[2048], Float32, CPU>[@model.layers.14.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=557), symbol:model.layers.14.input_layernorm.weight])[symbol:model.layers.14.input_layernorm.weight]
            tensor.CPU.register () -> (%2924:tensor<[2048, 2048], Float32, CPU>[@model.layers.14.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=558), symbol:model.layers.14.self_attn.q_proj.weight])[symbol:model.layers.14.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%6136:tensor<[1024, 2048], Float32, CPU>[@model.layers.14.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=560), symbol:model.layers.14.self_attn.k_proj.weight])[symbol:model.layers.14.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%5240:tensor<[1024, 2048], Float32, CPU>[@model.layers.14.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=562), symbol:model.layers.14.self_attn.v_proj.weight])[symbol:model.layers.14.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%3852:tensor<[128], Float32, CPU>[@model.layers.14.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=565), symbol:model.layers.14.self_attn.q_norm.weight])[symbol:model.layers.14.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%5634:tensor<[128], Float32, CPU>[@model.layers.14.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=567), symbol:model.layers.14.self_attn.k_norm.weight])[symbol:model.layers.14.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%331:tensor<[2048, 2048], Float32, CPU>[@model.layers.14.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=580), symbol:model.layers.14.self_attn.o_proj.weight])[symbol:model.layers.14.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%7059:tensor<[2048], Float32, CPU>[@model.layers.14.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=583), symbol:model.layers.14.post_attention_layernorm.weight])[symbol:model.layers.14.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%631:tensor<[6144, 2048], Float32, CPU>[@model.layers.14.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=584), symbol:model.layers.14.mlp.up_proj.weight])[symbol:model.layers.14.mlp.up_proj.weight]
            tensor.CPU.register () -> (%2479:tensor<[6144, 2048], Float32, CPU>[@model.layers.14.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=586), symbol:model.layers.14.mlp.gate_proj.weight])[symbol:model.layers.14.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%4629:tensor<[2048, 6144], Float32, CPU>[@model.layers.14.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=589), symbol:model.layers.14.mlp.down_proj.weight])[symbol:model.layers.14.mlp.down_proj.weight]
            tensor.CPU.register () -> (%1464:tensor<[2048], Float32, CPU>[@model.layers.15.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=592), symbol:model.layers.15.input_layernorm.weight])[symbol:model.layers.15.input_layernorm.weight]
            tensor.CPU.register () -> (%4989:tensor<[2048, 2048], Float32, CPU>[@model.layers.15.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=593), symbol:model.layers.15.self_attn.q_proj.weight])[symbol:model.layers.15.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%2031:tensor<[1024, 2048], Float32, CPU>[@model.layers.15.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=595), symbol:model.layers.15.self_attn.k_proj.weight])[symbol:model.layers.15.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%1922:tensor<[1024, 2048], Float32, CPU>[@model.layers.15.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=597), symbol:model.layers.15.self_attn.v_proj.weight])[symbol:model.layers.15.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%6176:tensor<[128], Float32, CPU>[@model.layers.15.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=600), symbol:model.layers.15.self_attn.q_norm.weight])[symbol:model.layers.15.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%5870:tensor<[128], Float32, CPU>[@model.layers.15.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=602), symbol:model.layers.15.self_attn.k_norm.weight])[symbol:model.layers.15.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%6498:tensor<[2048, 2048], Float32, CPU>[@model.layers.15.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=615), symbol:model.layers.15.self_attn.o_proj.weight])[symbol:model.layers.15.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%7534:tensor<[2048], Float32, CPU>[@model.layers.15.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=618), symbol:model.layers.15.post_attention_layernorm.weight])[symbol:model.layers.15.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%4158:tensor<[6144, 2048], Float32, CPU>[@model.layers.15.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=619), symbol:model.layers.15.mlp.up_proj.weight])[symbol:model.layers.15.mlp.up_proj.weight]
            tensor.CPU.register () -> (%5708:tensor<[6144, 2048], Float32, CPU>[@model.layers.15.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=621), symbol:model.layers.15.mlp.gate_proj.weight])[symbol:model.layers.15.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%6996:tensor<[2048, 6144], Float32, CPU>[@model.layers.15.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=624), symbol:model.layers.15.mlp.down_proj.weight])[symbol:model.layers.15.mlp.down_proj.weight]
            tensor.CPU.register () -> (%5186:tensor<[2048], Float32, CPU>[@model.layers.16.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=627), symbol:model.layers.16.input_layernorm.weight])[symbol:model.layers.16.input_layernorm.weight]
            tensor.CPU.register () -> (%3600:tensor<[2048, 2048], Float32, CPU>[@model.layers.16.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=628), symbol:model.layers.16.self_attn.q_proj.weight])[symbol:model.layers.16.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%7334:tensor<[1024, 2048], Float32, CPU>[@model.layers.16.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=630), symbol:model.layers.16.self_attn.k_proj.weight])[symbol:model.layers.16.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%1736:tensor<[1024, 2048], Float32, CPU>[@model.layers.16.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=632), symbol:model.layers.16.self_attn.v_proj.weight])[symbol:model.layers.16.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%8015:tensor<[128], Float32, CPU>[@model.layers.16.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=635), symbol:model.layers.16.self_attn.q_norm.weight])[symbol:model.layers.16.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%8043:tensor<[128], Float32, CPU>[@model.layers.16.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=637), symbol:model.layers.16.self_attn.k_norm.weight])[symbol:model.layers.16.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%1749:tensor<[2048, 2048], Float32, CPU>[@model.layers.16.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=650), symbol:model.layers.16.self_attn.o_proj.weight])[symbol:model.layers.16.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%3582:tensor<[2048], Float32, CPU>[@model.layers.16.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=653), symbol:model.layers.16.post_attention_layernorm.weight])[symbol:model.layers.16.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%6009:tensor<[6144, 2048], Float32, CPU>[@model.layers.16.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=654), symbol:model.layers.16.mlp.up_proj.weight])[symbol:model.layers.16.mlp.up_proj.weight]
            tensor.CPU.register () -> (%2546:tensor<[6144, 2048], Float32, CPU>[@model.layers.16.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=656), symbol:model.layers.16.mlp.gate_proj.weight])[symbol:model.layers.16.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%3430:tensor<[2048, 6144], Float32, CPU>[@model.layers.16.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=659), symbol:model.layers.16.mlp.down_proj.weight])[symbol:model.layers.16.mlp.down_proj.weight]
            tensor.CPU.register () -> (%4318:tensor<[2048], Float32, CPU>[@model.layers.17.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=662), symbol:model.layers.17.input_layernorm.weight])[symbol:model.layers.17.input_layernorm.weight]
            tensor.CPU.register () -> (%5713:tensor<[2048, 2048], Float32, CPU>[@model.layers.17.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=663), symbol:model.layers.17.self_attn.q_proj.weight])[symbol:model.layers.17.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%5811:tensor<[1024, 2048], Float32, CPU>[@model.layers.17.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=665), symbol:model.layers.17.self_attn.k_proj.weight])[symbol:model.layers.17.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%4106:tensor<[1024, 2048], Float32, CPU>[@model.layers.17.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=667), symbol:model.layers.17.self_attn.v_proj.weight])[symbol:model.layers.17.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%6494:tensor<[128], Float32, CPU>[@model.layers.17.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=670), symbol:model.layers.17.self_attn.q_norm.weight])[symbol:model.layers.17.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%7738:tensor<[128], Float32, CPU>[@model.layers.17.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=672), symbol:model.layers.17.self_attn.k_norm.weight])[symbol:model.layers.17.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%7459:tensor<[2048, 2048], Float32, CPU>[@model.layers.17.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=685), symbol:model.layers.17.self_attn.o_proj.weight])[symbol:model.layers.17.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%855:tensor<[2048], Float32, CPU>[@model.layers.17.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=688), symbol:model.layers.17.post_attention_layernorm.weight])[symbol:model.layers.17.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%8058:tensor<[6144, 2048], Float32, CPU>[@model.layers.17.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=689), symbol:model.layers.17.mlp.up_proj.weight])[symbol:model.layers.17.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6964:tensor<[6144, 2048], Float32, CPU>[@model.layers.17.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=691), symbol:model.layers.17.mlp.gate_proj.weight])[symbol:model.layers.17.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%2577:tensor<[2048, 6144], Float32, CPU>[@model.layers.17.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=694), symbol:model.layers.17.mlp.down_proj.weight])[symbol:model.layers.17.mlp.down_proj.weight]
            tensor.CPU.register () -> (%3926:tensor<[2048], Float32, CPU>[@model.layers.18.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=697), symbol:model.layers.18.input_layernorm.weight])[symbol:model.layers.18.input_layernorm.weight]
            tensor.CPU.register () -> (%1917:tensor<[2048, 2048], Float32, CPU>[@model.layers.18.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=698), symbol:model.layers.18.self_attn.q_proj.weight])[symbol:model.layers.18.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%1580:tensor<[1024, 2048], Float32, CPU>[@model.layers.18.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=700), symbol:model.layers.18.self_attn.k_proj.weight])[symbol:model.layers.18.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%4657:tensor<[1024, 2048], Float32, CPU>[@model.layers.18.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=702), symbol:model.layers.18.self_attn.v_proj.weight])[symbol:model.layers.18.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%5451:tensor<[128], Float32, CPU>[@model.layers.18.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=705), symbol:model.layers.18.self_attn.q_norm.weight])[symbol:model.layers.18.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%3229:tensor<[128], Float32, CPU>[@model.layers.18.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=707), symbol:model.layers.18.self_attn.k_norm.weight])[symbol:model.layers.18.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%1514:tensor<[2048, 2048], Float32, CPU>[@model.layers.18.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=720), symbol:model.layers.18.self_attn.o_proj.weight])[symbol:model.layers.18.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%910:tensor<[2048], Float32, CPU>[@model.layers.18.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=723), symbol:model.layers.18.post_attention_layernorm.weight])[symbol:model.layers.18.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%2694:tensor<[6144, 2048], Float32, CPU>[@model.layers.18.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=724), symbol:model.layers.18.mlp.up_proj.weight])[symbol:model.layers.18.mlp.up_proj.weight]
            tensor.CPU.register () -> (%4440:tensor<[6144, 2048], Float32, CPU>[@model.layers.18.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=726), symbol:model.layers.18.mlp.gate_proj.weight])[symbol:model.layers.18.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%6785:tensor<[2048, 6144], Float32, CPU>[@model.layers.18.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=729), symbol:model.layers.18.mlp.down_proj.weight])[symbol:model.layers.18.mlp.down_proj.weight]
            tensor.CPU.register () -> (%5637:tensor<[2048], Float32, CPU>[@model.layers.19.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=732), symbol:model.layers.19.input_layernorm.weight])[symbol:model.layers.19.input_layernorm.weight]
            tensor.CPU.register () -> (%542:tensor<[2048, 2048], Float32, CPU>[@model.layers.19.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=733), symbol:model.layers.19.self_attn.q_proj.weight])[symbol:model.layers.19.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%6845:tensor<[1024, 2048], Float32, CPU>[@model.layers.19.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=735), symbol:model.layers.19.self_attn.k_proj.weight])[symbol:model.layers.19.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%6082:tensor<[1024, 2048], Float32, CPU>[@model.layers.19.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=737), symbol:model.layers.19.self_attn.v_proj.weight])[symbol:model.layers.19.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%6718:tensor<[128], Float32, CPU>[@model.layers.19.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=740), symbol:model.layers.19.self_attn.q_norm.weight])[symbol:model.layers.19.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%1204:tensor<[128], Float32, CPU>[@model.layers.19.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=742), symbol:model.layers.19.self_attn.k_norm.weight])[symbol:model.layers.19.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%7572:tensor<[2048, 2048], Float32, CPU>[@model.layers.19.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=755), symbol:model.layers.19.self_attn.o_proj.weight])[symbol:model.layers.19.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%3257:tensor<[2048], Float32, CPU>[@model.layers.19.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=758), symbol:model.layers.19.post_attention_layernorm.weight])[symbol:model.layers.19.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%6762:tensor<[6144, 2048], Float32, CPU>[@model.layers.19.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=759), symbol:model.layers.19.mlp.up_proj.weight])[symbol:model.layers.19.mlp.up_proj.weight]
            tensor.CPU.register () -> (%3095:tensor<[6144, 2048], Float32, CPU>[@model.layers.19.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=761), symbol:model.layers.19.mlp.gate_proj.weight])[symbol:model.layers.19.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%3251:tensor<[2048, 6144], Float32, CPU>[@model.layers.19.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=764), symbol:model.layers.19.mlp.down_proj.weight])[symbol:model.layers.19.mlp.down_proj.weight]
            tensor.CPU.register () -> (%2201:tensor<[2048], Float32, CPU>[@model.layers.20.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=767), symbol:model.layers.20.input_layernorm.weight])[symbol:model.layers.20.input_layernorm.weight]
            tensor.CPU.register () -> (%196:tensor<[2048, 2048], Float32, CPU>[@model.layers.20.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=768), symbol:model.layers.20.self_attn.q_proj.weight])[symbol:model.layers.20.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%179:tensor<[1024, 2048], Float32, CPU>[@model.layers.20.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=770), symbol:model.layers.20.self_attn.k_proj.weight])[symbol:model.layers.20.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%3406:tensor<[1024, 2048], Float32, CPU>[@model.layers.20.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=772), symbol:model.layers.20.self_attn.v_proj.weight])[symbol:model.layers.20.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%760:tensor<[128], Float32, CPU>[@model.layers.20.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=775), symbol:model.layers.20.self_attn.q_norm.weight])[symbol:model.layers.20.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%2753:tensor<[128], Float32, CPU>[@model.layers.20.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=777), symbol:model.layers.20.self_attn.k_norm.weight])[symbol:model.layers.20.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%5869:tensor<[2048, 2048], Float32, CPU>[@model.layers.20.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=790), symbol:model.layers.20.self_attn.o_proj.weight])[symbol:model.layers.20.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%771:tensor<[2048], Float32, CPU>[@model.layers.20.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=793), symbol:model.layers.20.post_attention_layernorm.weight])[symbol:model.layers.20.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%2006:tensor<[6144, 2048], Float32, CPU>[@model.layers.20.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=794), symbol:model.layers.20.mlp.up_proj.weight])[symbol:model.layers.20.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6525:tensor<[6144, 2048], Float32, CPU>[@model.layers.20.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=796), symbol:model.layers.20.mlp.gate_proj.weight])[symbol:model.layers.20.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%6967:tensor<[2048, 6144], Float32, CPU>[@model.layers.20.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=799), symbol:model.layers.20.mlp.down_proj.weight])[symbol:model.layers.20.mlp.down_proj.weight]
            tensor.CPU.register () -> (%4395:tensor<[2048], Float32, CPU>[@model.layers.21.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=802), symbol:model.layers.21.input_layernorm.weight])[symbol:model.layers.21.input_layernorm.weight]
            tensor.CPU.register () -> (%4630:tensor<[2048, 2048], Float32, CPU>[@model.layers.21.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=803), symbol:model.layers.21.self_attn.q_proj.weight])[symbol:model.layers.21.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%4948:tensor<[1024, 2048], Float32, CPU>[@model.layers.21.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=805), symbol:model.layers.21.self_attn.k_proj.weight])[symbol:model.layers.21.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%5162:tensor<[1024, 2048], Float32, CPU>[@model.layers.21.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=807), symbol:model.layers.21.self_attn.v_proj.weight])[symbol:model.layers.21.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%7535:tensor<[128], Float32, CPU>[@model.layers.21.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=810), symbol:model.layers.21.self_attn.q_norm.weight])[symbol:model.layers.21.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%1698:tensor<[128], Float32, CPU>[@model.layers.21.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=812), symbol:model.layers.21.self_attn.k_norm.weight])[symbol:model.layers.21.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%4030:tensor<[2048, 2048], Float32, CPU>[@model.layers.21.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=825), symbol:model.layers.21.self_attn.o_proj.weight])[symbol:model.layers.21.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%3010:tensor<[2048], Float32, CPU>[@model.layers.21.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=828), symbol:model.layers.21.post_attention_layernorm.weight])[symbol:model.layers.21.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%5608:tensor<[6144, 2048], Float32, CPU>[@model.layers.21.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=829), symbol:model.layers.21.mlp.up_proj.weight])[symbol:model.layers.21.mlp.up_proj.weight]
            tensor.CPU.register () -> (%4800:tensor<[6144, 2048], Float32, CPU>[@model.layers.21.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=831), symbol:model.layers.21.mlp.gate_proj.weight])[symbol:model.layers.21.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%3518:tensor<[2048, 6144], Float32, CPU>[@model.layers.21.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=834), symbol:model.layers.21.mlp.down_proj.weight])[symbol:model.layers.21.mlp.down_proj.weight]
            tensor.CPU.register () -> (%5381:tensor<[2048], Float32, CPU>[@model.layers.22.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=837), symbol:model.layers.22.input_layernorm.weight])[symbol:model.layers.22.input_layernorm.weight]
            tensor.CPU.register () -> (%956:tensor<[2048, 2048], Float32, CPU>[@model.layers.22.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=838), symbol:model.layers.22.self_attn.q_proj.weight])[symbol:model.layers.22.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%4159:tensor<[1024, 2048], Float32, CPU>[@model.layers.22.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=840), symbol:model.layers.22.self_attn.k_proj.weight])[symbol:model.layers.22.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%6713:tensor<[1024, 2048], Float32, CPU>[@model.layers.22.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=842), symbol:model.layers.22.self_attn.v_proj.weight])[symbol:model.layers.22.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%1181:tensor<[128], Float32, CPU>[@model.layers.22.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=845), symbol:model.layers.22.self_attn.q_norm.weight])[symbol:model.layers.22.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%3001:tensor<[128], Float32, CPU>[@model.layers.22.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=847), symbol:model.layers.22.self_attn.k_norm.weight])[symbol:model.layers.22.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%8084:tensor<[2048, 2048], Float32, CPU>[@model.layers.22.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=860), symbol:model.layers.22.self_attn.o_proj.weight])[symbol:model.layers.22.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%357:tensor<[2048], Float32, CPU>[@model.layers.22.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=863), symbol:model.layers.22.post_attention_layernorm.weight])[symbol:model.layers.22.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%1068:tensor<[6144, 2048], Float32, CPU>[@model.layers.22.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=864), symbol:model.layers.22.mlp.up_proj.weight])[symbol:model.layers.22.mlp.up_proj.weight]
            tensor.CPU.register () -> (%5057:tensor<[6144, 2048], Float32, CPU>[@model.layers.22.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=866), symbol:model.layers.22.mlp.gate_proj.weight])[symbol:model.layers.22.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%698:tensor<[2048, 6144], Float32, CPU>[@model.layers.22.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=869), symbol:model.layers.22.mlp.down_proj.weight])[symbol:model.layers.22.mlp.down_proj.weight]
            tensor.CPU.register () -> (%456:tensor<[2048], Float32, CPU>[@model.layers.23.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=872), symbol:model.layers.23.input_layernorm.weight])[symbol:model.layers.23.input_layernorm.weight]
            tensor.CPU.register () -> (%5941:tensor<[2048, 2048], Float32, CPU>[@model.layers.23.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=873), symbol:model.layers.23.self_attn.q_proj.weight])[symbol:model.layers.23.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%4304:tensor<[1024, 2048], Float32, CPU>[@model.layers.23.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=875), symbol:model.layers.23.self_attn.k_proj.weight])[symbol:model.layers.23.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%3738:tensor<[1024, 2048], Float32, CPU>[@model.layers.23.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=877), symbol:model.layers.23.self_attn.v_proj.weight])[symbol:model.layers.23.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%5237:tensor<[128], Float32, CPU>[@model.layers.23.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=880), symbol:model.layers.23.self_attn.q_norm.weight])[symbol:model.layers.23.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%280:tensor<[128], Float32, CPU>[@model.layers.23.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=882), symbol:model.layers.23.self_attn.k_norm.weight])[symbol:model.layers.23.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%7541:tensor<[2048, 2048], Float32, CPU>[@model.layers.23.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=895), symbol:model.layers.23.self_attn.o_proj.weight])[symbol:model.layers.23.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%2827:tensor<[2048], Float32, CPU>[@model.layers.23.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=898), symbol:model.layers.23.post_attention_layernorm.weight])[symbol:model.layers.23.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%2427:tensor<[6144, 2048], Float32, CPU>[@model.layers.23.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=899), symbol:model.layers.23.mlp.up_proj.weight])[symbol:model.layers.23.mlp.up_proj.weight]
            tensor.CPU.register () -> (%5935:tensor<[6144, 2048], Float32, CPU>[@model.layers.23.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=901), symbol:model.layers.23.mlp.gate_proj.weight])[symbol:model.layers.23.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%11:tensor<[2048, 6144], Float32, CPU>[@model.layers.23.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=904), symbol:model.layers.23.mlp.down_proj.weight])[symbol:model.layers.23.mlp.down_proj.weight]
            tensor.CPU.register () -> (%4063:tensor<[2048], Float32, CPU>[@model.layers.24.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=907), symbol:model.layers.24.input_layernorm.weight])[symbol:model.layers.24.input_layernorm.weight]
            tensor.CPU.register () -> (%1741:tensor<[2048, 2048], Float32, CPU>[@model.layers.24.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=908), symbol:model.layers.24.self_attn.q_proj.weight])[symbol:model.layers.24.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%7443:tensor<[1024, 2048], Float32, CPU>[@model.layers.24.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=910), symbol:model.layers.24.self_attn.k_proj.weight])[symbol:model.layers.24.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%3162:tensor<[1024, 2048], Float32, CPU>[@model.layers.24.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=912), symbol:model.layers.24.self_attn.v_proj.weight])[symbol:model.layers.24.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%5942:tensor<[128], Float32, CPU>[@model.layers.24.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=915), symbol:model.layers.24.self_attn.q_norm.weight])[symbol:model.layers.24.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%1980:tensor<[128], Float32, CPU>[@model.layers.24.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=917), symbol:model.layers.24.self_attn.k_norm.weight])[symbol:model.layers.24.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%5547:tensor<[2048, 2048], Float32, CPU>[@model.layers.24.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=930), symbol:model.layers.24.self_attn.o_proj.weight])[symbol:model.layers.24.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%5937:tensor<[2048], Float32, CPU>[@model.layers.24.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=933), symbol:model.layers.24.post_attention_layernorm.weight])[symbol:model.layers.24.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%6475:tensor<[6144, 2048], Float32, CPU>[@model.layers.24.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=934), symbol:model.layers.24.mlp.up_proj.weight])[symbol:model.layers.24.mlp.up_proj.weight]
            tensor.CPU.register () -> (%7634:tensor<[6144, 2048], Float32, CPU>[@model.layers.24.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=936), symbol:model.layers.24.mlp.gate_proj.weight])[symbol:model.layers.24.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%2837:tensor<[2048, 6144], Float32, CPU>[@model.layers.24.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=939), symbol:model.layers.24.mlp.down_proj.weight])[symbol:model.layers.24.mlp.down_proj.weight]
            tensor.CPU.register () -> (%2698:tensor<[2048], Float32, CPU>[@model.layers.25.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=942), symbol:model.layers.25.input_layernorm.weight])[symbol:model.layers.25.input_layernorm.weight]
            tensor.CPU.register () -> (%7312:tensor<[2048, 2048], Float32, CPU>[@model.layers.25.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=943), symbol:model.layers.25.self_attn.q_proj.weight])[symbol:model.layers.25.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%8046:tensor<[1024, 2048], Float32, CPU>[@model.layers.25.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=945), symbol:model.layers.25.self_attn.k_proj.weight])[symbol:model.layers.25.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%8035:tensor<[1024, 2048], Float32, CPU>[@model.layers.25.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=947), symbol:model.layers.25.self_attn.v_proj.weight])[symbol:model.layers.25.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%5499:tensor<[128], Float32, CPU>[@model.layers.25.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=950), symbol:model.layers.25.self_attn.q_norm.weight])[symbol:model.layers.25.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%3571:tensor<[128], Float32, CPU>[@model.layers.25.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=952), symbol:model.layers.25.self_attn.k_norm.weight])[symbol:model.layers.25.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%6118:tensor<[2048, 2048], Float32, CPU>[@model.layers.25.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=965), symbol:model.layers.25.self_attn.o_proj.weight])[symbol:model.layers.25.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%3125:tensor<[2048], Float32, CPU>[@model.layers.25.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=968), symbol:model.layers.25.post_attention_layernorm.weight])[symbol:model.layers.25.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%1187:tensor<[6144, 2048], Float32, CPU>[@model.layers.25.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=969), symbol:model.layers.25.mlp.up_proj.weight])[symbol:model.layers.25.mlp.up_proj.weight]
            tensor.CPU.register () -> (%327:tensor<[6144, 2048], Float32, CPU>[@model.layers.25.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=971), symbol:model.layers.25.mlp.gate_proj.weight])[symbol:model.layers.25.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%1157:tensor<[2048, 6144], Float32, CPU>[@model.layers.25.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=974), symbol:model.layers.25.mlp.down_proj.weight])[symbol:model.layers.25.mlp.down_proj.weight]
            tensor.CPU.register () -> (%6051:tensor<[2048], Float32, CPU>[@model.layers.26.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=977), symbol:model.layers.26.input_layernorm.weight])[symbol:model.layers.26.input_layernorm.weight]
            tensor.CPU.register () -> (%3763:tensor<[2048, 2048], Float32, CPU>[@model.layers.26.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=978), symbol:model.layers.26.self_attn.q_proj.weight])[symbol:model.layers.26.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%6974:tensor<[1024, 2048], Float32, CPU>[@model.layers.26.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=980), symbol:model.layers.26.self_attn.k_proj.weight])[symbol:model.layers.26.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%3131:tensor<[1024, 2048], Float32, CPU>[@model.layers.26.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=982), symbol:model.layers.26.self_attn.v_proj.weight])[symbol:model.layers.26.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%5543:tensor<[128], Float32, CPU>[@model.layers.26.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=985), symbol:model.layers.26.self_attn.q_norm.weight])[symbol:model.layers.26.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%7751:tensor<[128], Float32, CPU>[@model.layers.26.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=987), symbol:model.layers.26.self_attn.k_norm.weight])[symbol:model.layers.26.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%4475:tensor<[2048, 2048], Float32, CPU>[@model.layers.26.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1000), symbol:model.layers.26.self_attn.o_proj.weight])[symbol:model.layers.26.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%7597:tensor<[2048], Float32, CPU>[@model.layers.26.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1003), symbol:model.layers.26.post_attention_layernorm.weight])[symbol:model.layers.26.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%3458:tensor<[6144, 2048], Float32, CPU>[@model.layers.26.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1004), symbol:model.layers.26.mlp.up_proj.weight])[symbol:model.layers.26.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6097:tensor<[6144, 2048], Float32, CPU>[@model.layers.26.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1006), symbol:model.layers.26.mlp.gate_proj.weight])[symbol:model.layers.26.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%1186:tensor<[2048, 6144], Float32, CPU>[@model.layers.26.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1009), symbol:model.layers.26.mlp.down_proj.weight])[symbol:model.layers.26.mlp.down_proj.weight]
            tensor.CPU.register () -> (%6869:tensor<[2048], Float32, CPU>[@model.layers.27.input_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1012), symbol:model.layers.27.input_layernorm.weight])[symbol:model.layers.27.input_layernorm.weight]
            tensor.CPU.register () -> (%513:tensor<[2048, 2048], Float32, CPU>[@model.layers.27.self_attn.q_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1013), symbol:model.layers.27.self_attn.q_proj.weight])[symbol:model.layers.27.self_attn.q_proj.weight]
            tensor.CPU.register () -> (%49:tensor<[1024, 2048], Float32, CPU>[@model.layers.27.self_attn.k_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1015), symbol:model.layers.27.self_attn.k_proj.weight])[symbol:model.layers.27.self_attn.k_proj.weight]
            tensor.CPU.register () -> (%7169:tensor<[1024, 2048], Float32, CPU>[@model.layers.27.self_attn.v_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1017), symbol:model.layers.27.self_attn.v_proj.weight])[symbol:model.layers.27.self_attn.v_proj.weight]
            tensor.CPU.register () -> (%6403:tensor<[128], Float32, CPU>[@model.layers.27.self_attn.q_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1020), symbol:model.layers.27.self_attn.q_norm.weight])[symbol:model.layers.27.self_attn.q_norm.weight]
            tensor.CPU.register () -> (%3420:tensor<[128], Float32, CPU>[@model.layers.27.self_attn.k_norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1022), symbol:model.layers.27.self_attn.k_norm.weight])[symbol:model.layers.27.self_attn.k_norm.weight]
            tensor.CPU.register () -> (%250:tensor<[2048, 2048], Float32, CPU>[@model.layers.27.self_attn.o_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1035), symbol:model.layers.27.self_attn.o_proj.weight])[symbol:model.layers.27.self_attn.o_proj.weight]
            tensor.CPU.register () -> (%2391:tensor<[2048], Float32, CPU>[@model.layers.27.post_attention_layernorm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1038), symbol:model.layers.27.post_attention_layernorm.weight])[symbol:model.layers.27.post_attention_layernorm.weight]
            tensor.CPU.register () -> (%3707:tensor<[6144, 2048], Float32, CPU>[@model.layers.27.mlp.up_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1039), symbol:model.layers.27.mlp.up_proj.weight])[symbol:model.layers.27.mlp.up_proj.weight]
            tensor.CPU.register () -> (%6283:tensor<[6144, 2048], Float32, CPU>[@model.layers.27.mlp.gate_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1041), symbol:model.layers.27.mlp.gate_proj.weight])[symbol:model.layers.27.mlp.gate_proj.weight]
            tensor.CPU.register () -> (%2073:tensor<[2048, 6144], Float32, CPU>[@model.layers.27.mlp.down_proj.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1044), symbol:model.layers.27.mlp.down_proj.weight])[symbol:model.layers.27.mlp.down_proj.weight]
            tensor.CPU.register () -> (%6469:tensor<[2048], Float32, CPU>[@model.norm.weight][quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1047), symbol:model.norm.weight])[symbol:model.norm.weight]
            tensor.CPU.register () -> (%2672:tensor<[151936, 2048], Float32, CPU>[@lm_head.weight][quant_recipe:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1048), symbol:lm_head.weight])[symbol:lm_head.weight]
        }
    }
    graph.SubGraphOp @deinit <notype> [symbol:deinit] {
        () -> () {
            
        }
    }
    graph.CallGraphOp @model (%8206:tensor<[1, 32], Int32, CPU>[quant_recipe:QuantSpec(Raw(type: Int32), uuid=0)], %8264:tensor<[32], Int32, CPU>[quant_recipe:QuantSpec(Raw(type: Int32), uuid=1)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8208:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)], %8210:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)], %8212:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)], %8214:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)], %8216:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)], %8218:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)], %8220:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)], %8222:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)], %8224:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)], %8226:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)], %8228:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)], %8230:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)], %8232:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)], %8234:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)], %8236:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)], %8238:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)], %8240:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)], %8242:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)], %8244:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)], %8246:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)], %8248:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)], %8250:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)], %8252:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)], %8254:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)], %8256:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)], %8258:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)], %8260:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)], %8262:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)], %8209:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)], %8211:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)], %8213:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)], %8215:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)], %8217:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)], %8219:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)], %8221:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)], %8223:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)], %8225:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)], %8227:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)], %8229:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)], %8231:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)], %8233:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)], %8235:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)], %8237:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)], %8239:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)], %8241:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)], %8243:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)], %8245:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)], %8247:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)], %8249:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)], %8251:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)], %8253:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)], %8255:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)], %8257:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)], %8259:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)], %8261:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)], %8263:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)]) -> (%9726:tensor<[1, 32, 151936], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1049)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)])
    graph.SubGraphOp @model <CPU> [using_qnn:true, symbol:model] {
        (%8206:tensor<[1, 32], Int32, CPU>[quant_recipe:QuantSpec(Raw(type: Int32), uuid=0)], %8264:tensor<[32], Int32, CPU>[quant_recipe:QuantSpec(Raw(type: Int32), uuid=1)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8208:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)], %8210:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)], %8212:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)], %8214:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)], %8216:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)], %8218:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)], %8220:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)], %8222:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)], %8224:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)], %8226:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)], %8228:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)], %8230:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)], %8232:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)], %8234:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)], %8236:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)], %8238:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)], %8240:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)], %8242:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)], %8244:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)], %8246:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)], %8248:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)], %8250:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)], %8252:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)], %8254:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)], %8256:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)], %8258:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)], %8260:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)], %8262:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)], %8209:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)], %8211:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)], %8213:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)], %8215:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)], %8217:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)], %8219:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)], %8221:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)], %8223:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)], %8225:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)], %8227:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)], %8229:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)], %8231:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)], %8233:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)], %8235:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)], %8237:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)], %8239:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)], %8241:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)], %8243:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)], %8245:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)], %8247:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)], %8249:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)], %8251:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)], %8253:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)], %8255:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)], %8257:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)], %8259:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)], %8261:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)], %8263:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)]) -> (%9726:tensor<[1, 32, 151936], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1049)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)]) {
            linalg.CPU.EmbeddingOp <name="model.embed_tokens">(%8206:tensor<[1, 32], Int32, CPU>[quant_recipe:QuantSpec(Raw(type: Int32), uuid=0)]) -> (%8265:tensor<[1, 32, 2048], Float32, CPU>[quant_recipe:QuantSpec(Raw(type: Float32), uuid=59)])
            linalg.CPU.CastTypeOp <name="model.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float32), uuid=59, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), weight_weight:QuantSpec(Raw(type: Float32), uuid=61, solved=0))] (%8265:tensor<[1, 32, 2048], Float32, CPU>[quant_recipe:QuantSpec(Raw(type: Float32), uuid=59)]) -> (%8266:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.IndexOp <name="model.Index.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=62, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8204:tensor<[1024, 5, 128], UInt16PerTensor, CPU>[@rope_sin][quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=62), symbol:rope_sin]) -> (%8267:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.IndexOp <name="model.Index.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=64, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8205:tensor<[1024, 5, 128], UInt16PerTensor, CPU>[@rope_cos][quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=64), symbol:rope_cos]) -> (%8268:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            graph.CallGraphOp @model.layers.0 (%8266:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8208:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)], %8209:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)]) -> (%8320:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)])
            graph.CallGraphOp @model.layers.1 (%8320:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8210:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)], %8211:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)]) -> (%8372:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)])
            graph.CallGraphOp @model.layers.2 (%8372:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8212:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)], %8213:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)]) -> (%8424:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)])
            graph.CallGraphOp @model.layers.3 (%8424:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8214:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)], %8215:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)]) -> (%8476:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)])
            graph.CallGraphOp @model.layers.4 (%8476:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8216:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)], %8217:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)]) -> (%8528:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)])
            graph.CallGraphOp @model.layers.5 (%8528:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8218:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)], %8219:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)]) -> (%8580:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)])
            graph.CallGraphOp @model.layers.6 (%8580:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8220:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)], %8221:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)]) -> (%8632:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)])
            graph.CallGraphOp @model.layers.7 (%8632:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8222:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)], %8223:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)]) -> (%8684:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)])
            graph.CallGraphOp @model.layers.8 (%8684:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8224:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)], %8225:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)]) -> (%8736:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)])
            graph.CallGraphOp @model.layers.9 (%8736:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8226:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)], %8227:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)]) -> (%8788:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)])
            graph.CallGraphOp @model.layers.10 (%8788:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8228:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)], %8229:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)]) -> (%8840:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)])
            graph.CallGraphOp @model.layers.11 (%8840:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8230:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)], %8231:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)]) -> (%8892:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)])
            graph.CallGraphOp @model.layers.12 (%8892:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8232:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)], %8233:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)]) -> (%8944:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)])
            graph.CallGraphOp @model.layers.13 (%8944:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8234:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)], %8235:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)]) -> (%8996:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)])
            graph.CallGraphOp @model.layers.14 (%8996:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8236:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)], %8237:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)]) -> (%9048:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)])
            graph.CallGraphOp @model.layers.15 (%9048:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8238:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)], %8239:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)]) -> (%9100:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)])
            graph.CallGraphOp @model.layers.16 (%9100:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8240:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)], %8241:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)]) -> (%9152:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)])
            graph.CallGraphOp @model.layers.17 (%9152:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8242:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)], %8243:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)]) -> (%9204:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)])
            graph.CallGraphOp @model.layers.18 (%9204:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8244:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)], %8245:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)]) -> (%9256:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)])
            graph.CallGraphOp @model.layers.19 (%9256:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8246:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)], %8247:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)]) -> (%9308:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)])
            graph.CallGraphOp @model.layers.20 (%9308:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8248:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)], %8249:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)]) -> (%9360:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)])
            graph.CallGraphOp @model.layers.21 (%9360:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8250:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)], %8251:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)]) -> (%9412:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)])
            graph.CallGraphOp @model.layers.22 (%9412:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8252:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)], %8253:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)]) -> (%9464:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)])
            graph.CallGraphOp @model.layers.23 (%9464:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8254:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)], %8255:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)]) -> (%9516:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)])
            graph.CallGraphOp @model.layers.24 (%9516:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8256:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)], %8257:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)]) -> (%9568:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)])
            graph.CallGraphOp @model.layers.25 (%9568:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8258:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)], %8259:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)]) -> (%9620:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)])
            graph.CallGraphOp @model.layers.26 (%9620:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8260:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)], %8261:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)]) -> (%9672:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)])
            graph.CallGraphOp @model.layers.27 (%9672:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8262:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)], %8263:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)]) -> (%9724:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)])
            linalg.CPU.RMSNormOp <name="model.norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1046, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1047, solved=0))] (%9724:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9725:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1046)])
            linalg.CPU.LinearOp <name="lm_head"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1046, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1049, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1048, solved=0)), using_qnn:true] (%9725:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1046)]) -> (%9726:tensor<[1, 32, 151936], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1049)])
            cf.ReturnOp (%9726:tensor<[1, 32, 151936], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1049)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.0 <CPU> [using_qnn:true, symbol:model.layers.0] {
        (%8266:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8208:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)], %8209:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)]) -> (%8320:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)]) {
            linalg.CPU.RMSNormOp <name="model.layers.0.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=67, solved=0))] (%8266:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8269:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66)])
            graph.CallGraphOp @model.layers.0.self_attn (%8269:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66)], %8267:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8208:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)], %8209:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)]) -> (%8311:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=91)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)])
            linalg.CPU.AddOp <name="model.layers.0.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=91, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8266:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8311:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=91)]) -> (%8312:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.0.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=92, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=93, solved=0))] (%8312:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8313:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=92)])
            graph.CallGraphOp @model.layers.0.mlp (%8313:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=92)]) -> (%8319:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=100)])
            linalg.CPU.AddOp <name="model.layers.0.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=100, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8312:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8319:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=100)]) -> (%8320:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8320:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.0.self_attn <CPU> [using_qnn:true, symbol:model.layers.0.self_attn] {
        (%8269:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66)], %8267:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8208:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)], %8209:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)]) -> (%8311:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=91)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)]) {
            linalg.CPU.LinearOp <name="model.layers.0.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=68, solved=0))] (%8269:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66)]) -> (%8270:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69)])
            linalg.CPU.LinearOp <name="model.layers.0.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=70, solved=0))] (%8269:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66)]) -> (%8271:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71)])
            linalg.CPU.LinearOp <name="model.layers.0.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=72, solved=0))] (%8269:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=66)]) -> (%8272:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73)])
            linalg.CPU.ViewOp <name="model.layers.0.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69, solved=0), )] (%8270:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69)]) -> (%8270:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69)])
            linalg.CPU.TransposeOp <name="model.layers.0.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69, solved=0), )] (%8270:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69)]) -> (%8273:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69)])
            linalg.CPU.ViewOp <name="model.layers.0.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71, solved=0), )] (%8271:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71)]) -> (%8271:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71)])
            linalg.CPU.TransposeOp <name="model.layers.0.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71, solved=0), )] (%8271:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71)]) -> (%8274:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71)])
            linalg.CPU.ViewOp <name="model.layers.0.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73, solved=0), )] (%8272:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73)]) -> (%8272:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73)])
            linalg.CPU.TransposeOp <name="model.layers.0.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73, solved=0), )] (%8272:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73)]) -> (%8275:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73)])
            linalg.CPU.RMSNormOp <name="model.layers.0.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=75, solved=0))] (%8273:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=69)]) -> (%8276:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)])
            linalg.CPU.RMSNormOp <name="model.layers.0.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=77, solved=0))] (%8274:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=71)]) -> (%8277:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)])
            linalg.CPU.ViewOp <name="model.layers.0.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.0.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.0.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), )] (%8276:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)]) -> (%8276:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)])
            linalg.CPU.SliceOp <name="model.layers.0.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), )] (%8276:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)]) -> (%8276:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)])
            linalg.CPU.NegOp <name="model.layers.0.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), )] (%8276:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)]) -> (%8278:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)])
            linalg.CPU.ConcatOp <name="model.layers.0.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), )] (%8278:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)], %8276:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)]) -> (%8279:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)])
            linalg.CPU.MulOp <name="model.layers.0.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), )] (%8279:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8280:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)])
            linalg.CPU.MulOp <name="model.layers.0.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), )] (%8276:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8281:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)])
            linalg.CPU.AddOp <name="model.layers.0.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), )] (%8281:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)], %8280:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)]) -> (%8282:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)])
            linalg.CPU.SliceOp <name="model.layers.0.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), )] (%8277:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)]) -> (%8277:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)])
            linalg.CPU.SliceOp <name="model.layers.0.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), )] (%8277:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)]) -> (%8277:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)])
            linalg.CPU.NegOp <name="model.layers.0.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), )] (%8277:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)]) -> (%8283:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)])
            linalg.CPU.ConcatOp <name="model.layers.0.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), )] (%8283:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)], %8277:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)]) -> (%8284:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)])
            linalg.CPU.MulOp <name="model.layers.0.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), )] (%8284:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8285:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)])
            linalg.CPU.MulOp <name="model.layers.0.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), )] (%8277:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8286:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)])
            linalg.CPU.AddOp <name="model.layers.0.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), )] (%8286:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)], %8285:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)]) -> (%8287:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)])
            linalg.CPU.CastTypeOp <name="model.layers.0.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=78, solved=0), )] (%8287:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=76)]) -> (%8288:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=78)])
            linalg.CPU.CastTypeOp <name="model.layers.0.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=78, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79, solved=0), )] (%8288:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=78)]) -> (%8289:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)])
            linalg.CPU.TransposeOp <name="model.layers.0.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79, solved=0), )] (%8289:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)]) -> (%8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)])
            linalg.CPU.CastTypeOp <name="model.layers.0.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=80, solved=0), )] (%8275:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=73)]) -> (%8292:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=80)])
            linalg.CPU.CastTypeOp <name="model.layers.0.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=80, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81, solved=0), )] (%8292:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=80)]) -> (%8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)])
            linalg.CPU.ConcatOp <name="model.layers.0.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3, solved=0), )] (%8208:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)]) -> (%8295:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)])
            linalg.CPU.ConcatOp <name="model.layers.0.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31, solved=0), )] (%8209:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)]) -> (%8296:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)])
            linalg.CPU.RepeatOp <name="model.layers.0.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3, solved=0), )] (%8295:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)]) -> (%8297:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)])
            linalg.CPU.RepeatOp <name="model.layers.0.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31, solved=0), )] (%8296:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)]) -> (%8298:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)])
            linalg.CPU.MatMulOp <name="model.layers.0.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82, solved=0), )] (%8282:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=74)], %8297:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=3)]) -> (%8299:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82)])
            linalg.CPU.MulOp <name="model.layers.0.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=83, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82, solved=0), )] (%8299:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82)], %8300:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=83), constant:[0.088388346]]) -> (%8301:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82)])
            linalg.CPU.ReduceMinOp <name="model.layers.0.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84, solved=0), )] (%8301:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82)]) -> (%8302:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84)])
            linalg.CPU.AddOp <name="model.layers.0.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=85, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84, solved=0), )] (%8302:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84)], %8303:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=85), constant:[-20]]) -> (%8304:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84)])
            linalg.CPU.EqualOp <name="model.layers.0.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=86, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=87, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8305:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=86), constant:[0]]) -> (%8306:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=87)])
            linalg.CPU.WhereOp <name="model.layers.0.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=87, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84, solved=0), )] (%8306:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=87)], %8301:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=82)], %8304:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84)]) -> (%8307:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84)])
            linalg.CPU.SoftmaxOp <name="model.layers.0.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=88, solved=0), )] (%8307:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=84)]) -> (%8308:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=88)])
            linalg.CPU.MatMulOp <name="model.layers.0.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=88, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89, solved=0), )] (%8308:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=88)], %8298:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=31)]) -> (%8309:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89)])
            linalg.CPU.TransposeOp <name="model.layers.0.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89, solved=0), )] (%8309:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89)]) -> (%8310:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89)])
            linalg.CPU.ViewOp <name="model.layers.0.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89, solved=0), )] (%8310:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89)]) -> (%8310:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89)])
            linalg.CPU.LinearOp <name="model.layers.0.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=91, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=90, solved=0))] (%8310:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=89)]) -> (%8311:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=91)])
            cf.ReturnOp (%8311:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=91)], %8291:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=79)], %8293:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=81)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.0.mlp <CPU> [using_qnn:true, symbol:model.layers.0.mlp] {
        (%8313:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=92)]) -> (%8319:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=100)]) {
            linalg.CPU.LinearOp <name="model.layers.0.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=92, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=95, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=94, solved=0))] (%8313:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=92)]) -> (%8314:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=95)])
            linalg.CPU.LinearOp <name="model.layers.0.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=92, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=96, solved=0))] (%8313:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=92)]) -> (%8315:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97)])
            linalg.CPU.SigmoidOp <name="model.layers.0.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=98, solved=0), )] (%8315:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97)]) -> (%8316:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=98)])
            linalg.CPU.MulOp <name="model.layers.0.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=98, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97, solved=0), )] (%8315:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97)], %8316:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=98)]) -> (%8317:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97)])
            linalg.CPU.MulOp <name="model.layers.0.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=95, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97, solved=0), )] (%8317:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97)], %8314:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=95)]) -> (%8318:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97)])
            linalg.CPU.LinearOp <name="model.layers.0.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=100, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=99, solved=0))] (%8318:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=97)]) -> (%8319:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=100)])
            cf.ReturnOp (%8319:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=100)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.1 <CPU> [using_qnn:true, symbol:model.layers.1] {
        (%8320:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8210:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)], %8211:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)]) -> (%8372:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)]) {
            linalg.CPU.RMSNormOp <name="model.layers.1.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=102, solved=0))] (%8320:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8321:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101)])
            graph.CallGraphOp @model.layers.1.self_attn (%8321:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8210:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)], %8211:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)]) -> (%8363:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=126)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)])
            linalg.CPU.AddOp <name="model.layers.1.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=126, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8320:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8363:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=126)]) -> (%8364:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.1.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=127, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=128, solved=0))] (%8364:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8365:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=127)])
            graph.CallGraphOp @model.layers.1.mlp (%8365:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=127)]) -> (%8371:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=135)])
            linalg.CPU.AddOp <name="model.layers.1.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=135, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8364:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8371:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=135)]) -> (%8372:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8372:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.1.self_attn <CPU> [using_qnn:true, symbol:model.layers.1.self_attn] {
        (%8321:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8210:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)], %8211:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)]) -> (%8363:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=126)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)]) {
            linalg.CPU.LinearOp <name="model.layers.1.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=103, solved=0))] (%8321:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101)]) -> (%8322:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104)])
            linalg.CPU.LinearOp <name="model.layers.1.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=105, solved=0))] (%8321:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101)]) -> (%8323:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106)])
            linalg.CPU.LinearOp <name="model.layers.1.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=107, solved=0))] (%8321:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=101)]) -> (%8324:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108)])
            linalg.CPU.ViewOp <name="model.layers.1.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104, solved=0), )] (%8322:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104)]) -> (%8322:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104)])
            linalg.CPU.TransposeOp <name="model.layers.1.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104, solved=0), )] (%8322:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104)]) -> (%8325:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104)])
            linalg.CPU.ViewOp <name="model.layers.1.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106, solved=0), )] (%8323:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106)]) -> (%8323:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106)])
            linalg.CPU.TransposeOp <name="model.layers.1.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106, solved=0), )] (%8323:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106)]) -> (%8326:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106)])
            linalg.CPU.ViewOp <name="model.layers.1.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108, solved=0), )] (%8324:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108)]) -> (%8324:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108)])
            linalg.CPU.TransposeOp <name="model.layers.1.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108, solved=0), )] (%8324:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108)]) -> (%8327:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108)])
            linalg.CPU.RMSNormOp <name="model.layers.1.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=110, solved=0))] (%8325:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=104)]) -> (%8328:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)])
            linalg.CPU.RMSNormOp <name="model.layers.1.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=112, solved=0))] (%8326:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=106)]) -> (%8329:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)])
            linalg.CPU.ViewOp <name="model.layers.1.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.1.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.1.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), )] (%8328:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)]) -> (%8328:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)])
            linalg.CPU.SliceOp <name="model.layers.1.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), )] (%8328:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)]) -> (%8328:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)])
            linalg.CPU.NegOp <name="model.layers.1.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), )] (%8328:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)]) -> (%8330:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)])
            linalg.CPU.ConcatOp <name="model.layers.1.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), )] (%8330:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)], %8328:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)]) -> (%8331:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)])
            linalg.CPU.MulOp <name="model.layers.1.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), )] (%8331:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8332:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)])
            linalg.CPU.MulOp <name="model.layers.1.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), )] (%8328:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8333:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)])
            linalg.CPU.AddOp <name="model.layers.1.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), )] (%8333:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)], %8332:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)]) -> (%8334:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)])
            linalg.CPU.SliceOp <name="model.layers.1.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), )] (%8329:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)]) -> (%8329:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)])
            linalg.CPU.SliceOp <name="model.layers.1.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), )] (%8329:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)]) -> (%8329:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)])
            linalg.CPU.NegOp <name="model.layers.1.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), )] (%8329:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)]) -> (%8335:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)])
            linalg.CPU.ConcatOp <name="model.layers.1.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), )] (%8335:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)], %8329:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)]) -> (%8336:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)])
            linalg.CPU.MulOp <name="model.layers.1.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), )] (%8336:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8337:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)])
            linalg.CPU.MulOp <name="model.layers.1.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), )] (%8329:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8338:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)])
            linalg.CPU.AddOp <name="model.layers.1.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), )] (%8338:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)], %8337:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)]) -> (%8339:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)])
            linalg.CPU.CastTypeOp <name="model.layers.1.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=113, solved=0), )] (%8339:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=111)]) -> (%8340:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=113)])
            linalg.CPU.CastTypeOp <name="model.layers.1.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=113, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114, solved=0), )] (%8340:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=113)]) -> (%8341:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)])
            linalg.CPU.TransposeOp <name="model.layers.1.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114, solved=0), )] (%8341:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)]) -> (%8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)])
            linalg.CPU.CastTypeOp <name="model.layers.1.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=115, solved=0), )] (%8327:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=108)]) -> (%8344:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=115)])
            linalg.CPU.CastTypeOp <name="model.layers.1.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=115, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116, solved=0), )] (%8344:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=115)]) -> (%8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)])
            linalg.CPU.ConcatOp <name="model.layers.1.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4, solved=0), )] (%8210:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)]) -> (%8347:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)])
            linalg.CPU.ConcatOp <name="model.layers.1.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32, solved=0), )] (%8211:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)]) -> (%8348:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)])
            linalg.CPU.RepeatOp <name="model.layers.1.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4, solved=0), )] (%8347:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)]) -> (%8349:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)])
            linalg.CPU.RepeatOp <name="model.layers.1.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32, solved=0), )] (%8348:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)]) -> (%8350:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)])
            linalg.CPU.MatMulOp <name="model.layers.1.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117, solved=0), )] (%8334:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=109)], %8349:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=4)]) -> (%8351:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117)])
            linalg.CPU.MulOp <name="model.layers.1.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=118, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117, solved=0), )] (%8351:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117)], %8352:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=118), constant:[0.088388346]]) -> (%8353:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117)])
            linalg.CPU.ReduceMinOp <name="model.layers.1.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119, solved=0), )] (%8353:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117)]) -> (%8354:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119)])
            linalg.CPU.AddOp <name="model.layers.1.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=120, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119, solved=0), )] (%8354:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119)], %8355:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=120), constant:[-20]]) -> (%8356:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119)])
            linalg.CPU.EqualOp <name="model.layers.1.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=121, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=122, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8357:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=121), constant:[0]]) -> (%8358:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=122)])
            linalg.CPU.WhereOp <name="model.layers.1.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=122, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119, solved=0), )] (%8358:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=122)], %8353:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=117)], %8356:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119)]) -> (%8359:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119)])
            linalg.CPU.SoftmaxOp <name="model.layers.1.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=123, solved=0), )] (%8359:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=119)]) -> (%8360:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=123)])
            linalg.CPU.MatMulOp <name="model.layers.1.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=123, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124, solved=0), )] (%8360:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=123)], %8350:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=32)]) -> (%8361:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124)])
            linalg.CPU.TransposeOp <name="model.layers.1.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124, solved=0), )] (%8361:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124)]) -> (%8362:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124)])
            linalg.CPU.ViewOp <name="model.layers.1.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124, solved=0), )] (%8362:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124)]) -> (%8362:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124)])
            linalg.CPU.LinearOp <name="model.layers.1.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=126, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=125, solved=0))] (%8362:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=124)]) -> (%8363:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=126)])
            cf.ReturnOp (%8363:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=126)], %8343:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=114)], %8345:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=116)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.1.mlp <CPU> [using_qnn:true, symbol:model.layers.1.mlp] {
        (%8365:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=127)]) -> (%8371:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=135)]) {
            linalg.CPU.LinearOp <name="model.layers.1.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=127, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=130, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=129, solved=0))] (%8365:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=127)]) -> (%8366:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=130)])
            linalg.CPU.LinearOp <name="model.layers.1.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=127, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=131, solved=0))] (%8365:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=127)]) -> (%8367:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132)])
            linalg.CPU.SigmoidOp <name="model.layers.1.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=133, solved=0), )] (%8367:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132)]) -> (%8368:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=133)])
            linalg.CPU.MulOp <name="model.layers.1.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=133, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132, solved=0), )] (%8367:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132)], %8368:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=133)]) -> (%8369:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132)])
            linalg.CPU.MulOp <name="model.layers.1.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=130, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132, solved=0), )] (%8369:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132)], %8366:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=130)]) -> (%8370:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132)])
            linalg.CPU.LinearOp <name="model.layers.1.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=135, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=134, solved=0))] (%8370:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=132)]) -> (%8371:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=135)])
            cf.ReturnOp (%8371:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=135)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.2 <CPU> [using_qnn:true, symbol:model.layers.2] {
        (%8372:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8212:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)], %8213:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)]) -> (%8424:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)]) {
            linalg.CPU.RMSNormOp <name="model.layers.2.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=137, solved=0))] (%8372:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8373:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136)])
            graph.CallGraphOp @model.layers.2.self_attn (%8373:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8212:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)], %8213:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)]) -> (%8415:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=161)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)])
            linalg.CPU.AddOp <name="model.layers.2.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=161, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8372:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8415:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=161)]) -> (%8416:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.2.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=162, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=163, solved=0))] (%8416:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8417:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=162)])
            graph.CallGraphOp @model.layers.2.mlp (%8417:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=162)]) -> (%8423:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=170)])
            linalg.CPU.AddOp <name="model.layers.2.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=170, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8416:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8423:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=170)]) -> (%8424:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8424:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.2.self_attn <CPU> [using_qnn:true, symbol:model.layers.2.self_attn] {
        (%8373:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8212:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)], %8213:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)]) -> (%8415:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=161)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)]) {
            linalg.CPU.LinearOp <name="model.layers.2.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=138, solved=0))] (%8373:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136)]) -> (%8374:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139)])
            linalg.CPU.LinearOp <name="model.layers.2.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=140, solved=0))] (%8373:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136)]) -> (%8375:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141)])
            linalg.CPU.LinearOp <name="model.layers.2.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=142, solved=0))] (%8373:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=136)]) -> (%8376:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143)])
            linalg.CPU.ViewOp <name="model.layers.2.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139, solved=0), )] (%8374:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139)]) -> (%8374:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139)])
            linalg.CPU.TransposeOp <name="model.layers.2.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139, solved=0), )] (%8374:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139)]) -> (%8377:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139)])
            linalg.CPU.ViewOp <name="model.layers.2.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141, solved=0), )] (%8375:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141)]) -> (%8375:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141)])
            linalg.CPU.TransposeOp <name="model.layers.2.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141, solved=0), )] (%8375:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141)]) -> (%8378:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141)])
            linalg.CPU.ViewOp <name="model.layers.2.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143, solved=0), )] (%8376:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143)]) -> (%8376:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143)])
            linalg.CPU.TransposeOp <name="model.layers.2.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143, solved=0), )] (%8376:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143)]) -> (%8379:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143)])
            linalg.CPU.RMSNormOp <name="model.layers.2.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=145, solved=0))] (%8377:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=139)]) -> (%8380:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)])
            linalg.CPU.RMSNormOp <name="model.layers.2.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=147, solved=0))] (%8378:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=141)]) -> (%8381:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)])
            linalg.CPU.ViewOp <name="model.layers.2.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.2.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.2.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), )] (%8380:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)]) -> (%8380:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)])
            linalg.CPU.SliceOp <name="model.layers.2.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), )] (%8380:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)]) -> (%8380:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)])
            linalg.CPU.NegOp <name="model.layers.2.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), )] (%8380:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)]) -> (%8382:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)])
            linalg.CPU.ConcatOp <name="model.layers.2.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), )] (%8382:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)], %8380:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)]) -> (%8383:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)])
            linalg.CPU.MulOp <name="model.layers.2.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), )] (%8383:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8384:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)])
            linalg.CPU.MulOp <name="model.layers.2.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), )] (%8380:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8385:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)])
            linalg.CPU.AddOp <name="model.layers.2.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), )] (%8385:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)], %8384:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)]) -> (%8386:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)])
            linalg.CPU.SliceOp <name="model.layers.2.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), )] (%8381:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)]) -> (%8381:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)])
            linalg.CPU.SliceOp <name="model.layers.2.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), )] (%8381:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)]) -> (%8381:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)])
            linalg.CPU.NegOp <name="model.layers.2.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), )] (%8381:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)]) -> (%8387:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)])
            linalg.CPU.ConcatOp <name="model.layers.2.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), )] (%8387:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)], %8381:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)]) -> (%8388:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)])
            linalg.CPU.MulOp <name="model.layers.2.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), )] (%8388:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8389:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)])
            linalg.CPU.MulOp <name="model.layers.2.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), )] (%8381:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8390:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)])
            linalg.CPU.AddOp <name="model.layers.2.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), )] (%8390:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)], %8389:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)]) -> (%8391:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)])
            linalg.CPU.CastTypeOp <name="model.layers.2.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=148, solved=0), )] (%8391:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=146)]) -> (%8392:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=148)])
            linalg.CPU.CastTypeOp <name="model.layers.2.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=148, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149, solved=0), )] (%8392:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=148)]) -> (%8393:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)])
            linalg.CPU.TransposeOp <name="model.layers.2.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149, solved=0), )] (%8393:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)]) -> (%8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)])
            linalg.CPU.CastTypeOp <name="model.layers.2.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=150, solved=0), )] (%8379:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=143)]) -> (%8396:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=150)])
            linalg.CPU.CastTypeOp <name="model.layers.2.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=150, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151, solved=0), )] (%8396:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=150)]) -> (%8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)])
            linalg.CPU.ConcatOp <name="model.layers.2.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5, solved=0), )] (%8212:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)]) -> (%8399:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)])
            linalg.CPU.ConcatOp <name="model.layers.2.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33, solved=0), )] (%8213:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)]) -> (%8400:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)])
            linalg.CPU.RepeatOp <name="model.layers.2.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5, solved=0), )] (%8399:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)]) -> (%8401:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)])
            linalg.CPU.RepeatOp <name="model.layers.2.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33, solved=0), )] (%8400:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)]) -> (%8402:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)])
            linalg.CPU.MatMulOp <name="model.layers.2.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152, solved=0), )] (%8386:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=144)], %8401:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=5)]) -> (%8403:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152)])
            linalg.CPU.MulOp <name="model.layers.2.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=153, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152, solved=0), )] (%8403:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152)], %8404:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=153), constant:[0.088388346]]) -> (%8405:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152)])
            linalg.CPU.ReduceMinOp <name="model.layers.2.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154, solved=0), )] (%8405:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152)]) -> (%8406:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154)])
            linalg.CPU.AddOp <name="model.layers.2.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=155, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154, solved=0), )] (%8406:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154)], %8407:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=155), constant:[-20]]) -> (%8408:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154)])
            linalg.CPU.EqualOp <name="model.layers.2.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=156, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=157, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8409:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=156), constant:[0]]) -> (%8410:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=157)])
            linalg.CPU.WhereOp <name="model.layers.2.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=157, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154, solved=0), )] (%8410:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=157)], %8405:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=152)], %8408:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154)]) -> (%8411:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154)])
            linalg.CPU.SoftmaxOp <name="model.layers.2.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=158, solved=0), )] (%8411:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=154)]) -> (%8412:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=158)])
            linalg.CPU.MatMulOp <name="model.layers.2.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=158, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159, solved=0), )] (%8412:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=158)], %8402:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=33)]) -> (%8413:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159)])
            linalg.CPU.TransposeOp <name="model.layers.2.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159, solved=0), )] (%8413:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159)]) -> (%8414:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159)])
            linalg.CPU.ViewOp <name="model.layers.2.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159, solved=0), )] (%8414:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159)]) -> (%8414:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159)])
            linalg.CPU.LinearOp <name="model.layers.2.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=161, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=160, solved=0))] (%8414:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=159)]) -> (%8415:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=161)])
            cf.ReturnOp (%8415:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=161)], %8395:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=149)], %8397:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=151)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.2.mlp <CPU> [using_qnn:true, symbol:model.layers.2.mlp] {
        (%8417:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=162)]) -> (%8423:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=170)]) {
            linalg.CPU.LinearOp <name="model.layers.2.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=162, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=165, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=164, solved=0))] (%8417:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=162)]) -> (%8418:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=165)])
            linalg.CPU.LinearOp <name="model.layers.2.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=162, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=166, solved=0))] (%8417:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=162)]) -> (%8419:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167)])
            linalg.CPU.SigmoidOp <name="model.layers.2.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=168, solved=0), )] (%8419:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167)]) -> (%8420:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=168)])
            linalg.CPU.MulOp <name="model.layers.2.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=168, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167, solved=0), )] (%8419:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167)], %8420:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=168)]) -> (%8421:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167)])
            linalg.CPU.MulOp <name="model.layers.2.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=165, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167, solved=0), )] (%8421:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167)], %8418:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=165)]) -> (%8422:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167)])
            linalg.CPU.LinearOp <name="model.layers.2.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=170, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=169, solved=0))] (%8422:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=167)]) -> (%8423:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=170)])
            cf.ReturnOp (%8423:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=170)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.3 <CPU> [using_qnn:true, symbol:model.layers.3] {
        (%8424:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8214:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)], %8215:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)]) -> (%8476:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)]) {
            linalg.CPU.RMSNormOp <name="model.layers.3.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=172, solved=0))] (%8424:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8425:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171)])
            graph.CallGraphOp @model.layers.3.self_attn (%8425:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8214:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)], %8215:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)]) -> (%8467:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=196)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)])
            linalg.CPU.AddOp <name="model.layers.3.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=196, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8424:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8467:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=196)]) -> (%8468:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.3.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=197, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=198, solved=0))] (%8468:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8469:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=197)])
            graph.CallGraphOp @model.layers.3.mlp (%8469:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=197)]) -> (%8475:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=205)])
            linalg.CPU.AddOp <name="model.layers.3.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=205, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8468:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8475:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=205)]) -> (%8476:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8476:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.3.self_attn <CPU> [using_qnn:true, symbol:model.layers.3.self_attn] {
        (%8425:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8214:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)], %8215:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)]) -> (%8467:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=196)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)]) {
            linalg.CPU.LinearOp <name="model.layers.3.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=173, solved=0))] (%8425:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171)]) -> (%8426:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174)])
            linalg.CPU.LinearOp <name="model.layers.3.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=175, solved=0))] (%8425:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171)]) -> (%8427:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176)])
            linalg.CPU.LinearOp <name="model.layers.3.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=177, solved=0))] (%8425:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=171)]) -> (%8428:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178)])
            linalg.CPU.ViewOp <name="model.layers.3.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174, solved=0), )] (%8426:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174)]) -> (%8426:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174)])
            linalg.CPU.TransposeOp <name="model.layers.3.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174, solved=0), )] (%8426:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174)]) -> (%8429:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174)])
            linalg.CPU.ViewOp <name="model.layers.3.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176, solved=0), )] (%8427:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176)]) -> (%8427:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176)])
            linalg.CPU.TransposeOp <name="model.layers.3.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176, solved=0), )] (%8427:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176)]) -> (%8430:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176)])
            linalg.CPU.ViewOp <name="model.layers.3.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178, solved=0), )] (%8428:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178)]) -> (%8428:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178)])
            linalg.CPU.TransposeOp <name="model.layers.3.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178, solved=0), )] (%8428:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178)]) -> (%8431:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178)])
            linalg.CPU.RMSNormOp <name="model.layers.3.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=180, solved=0))] (%8429:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=174)]) -> (%8432:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)])
            linalg.CPU.RMSNormOp <name="model.layers.3.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=182, solved=0))] (%8430:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=176)]) -> (%8433:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)])
            linalg.CPU.ViewOp <name="model.layers.3.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.3.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.3.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), )] (%8432:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)]) -> (%8432:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)])
            linalg.CPU.SliceOp <name="model.layers.3.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), )] (%8432:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)]) -> (%8432:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)])
            linalg.CPU.NegOp <name="model.layers.3.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), )] (%8432:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)]) -> (%8434:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)])
            linalg.CPU.ConcatOp <name="model.layers.3.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), )] (%8434:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)], %8432:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)]) -> (%8435:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)])
            linalg.CPU.MulOp <name="model.layers.3.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), )] (%8435:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8436:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)])
            linalg.CPU.MulOp <name="model.layers.3.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), )] (%8432:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8437:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)])
            linalg.CPU.AddOp <name="model.layers.3.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), )] (%8437:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)], %8436:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)]) -> (%8438:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)])
            linalg.CPU.SliceOp <name="model.layers.3.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), )] (%8433:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)]) -> (%8433:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)])
            linalg.CPU.SliceOp <name="model.layers.3.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), )] (%8433:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)]) -> (%8433:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)])
            linalg.CPU.NegOp <name="model.layers.3.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), )] (%8433:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)]) -> (%8439:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)])
            linalg.CPU.ConcatOp <name="model.layers.3.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), )] (%8439:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)], %8433:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)]) -> (%8440:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)])
            linalg.CPU.MulOp <name="model.layers.3.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), )] (%8440:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8441:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)])
            linalg.CPU.MulOp <name="model.layers.3.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), )] (%8433:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8442:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)])
            linalg.CPU.AddOp <name="model.layers.3.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), )] (%8442:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)], %8441:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)]) -> (%8443:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)])
            linalg.CPU.CastTypeOp <name="model.layers.3.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=183, solved=0), )] (%8443:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=181)]) -> (%8444:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=183)])
            linalg.CPU.CastTypeOp <name="model.layers.3.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=183, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184, solved=0), )] (%8444:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=183)]) -> (%8445:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)])
            linalg.CPU.TransposeOp <name="model.layers.3.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184, solved=0), )] (%8445:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)]) -> (%8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)])
            linalg.CPU.CastTypeOp <name="model.layers.3.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=185, solved=0), )] (%8431:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=178)]) -> (%8448:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=185)])
            linalg.CPU.CastTypeOp <name="model.layers.3.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=185, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186, solved=0), )] (%8448:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=185)]) -> (%8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)])
            linalg.CPU.ConcatOp <name="model.layers.3.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6, solved=0), )] (%8214:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)]) -> (%8451:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)])
            linalg.CPU.ConcatOp <name="model.layers.3.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34, solved=0), )] (%8215:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)]) -> (%8452:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)])
            linalg.CPU.RepeatOp <name="model.layers.3.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6, solved=0), )] (%8451:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)]) -> (%8453:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)])
            linalg.CPU.RepeatOp <name="model.layers.3.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34, solved=0), )] (%8452:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)]) -> (%8454:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)])
            linalg.CPU.MatMulOp <name="model.layers.3.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187, solved=0), )] (%8438:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=179)], %8453:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=6)]) -> (%8455:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187)])
            linalg.CPU.MulOp <name="model.layers.3.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=188, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187, solved=0), )] (%8455:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187)], %8456:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=188), constant:[0.088388346]]) -> (%8457:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187)])
            linalg.CPU.ReduceMinOp <name="model.layers.3.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189, solved=0), )] (%8457:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187)]) -> (%8458:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189)])
            linalg.CPU.AddOp <name="model.layers.3.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=190, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189, solved=0), )] (%8458:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189)], %8459:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=190), constant:[-20]]) -> (%8460:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189)])
            linalg.CPU.EqualOp <name="model.layers.3.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=191, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=192, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8461:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=191), constant:[0]]) -> (%8462:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=192)])
            linalg.CPU.WhereOp <name="model.layers.3.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=192, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189, solved=0), )] (%8462:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=192)], %8457:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=187)], %8460:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189)]) -> (%8463:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189)])
            linalg.CPU.SoftmaxOp <name="model.layers.3.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=193, solved=0), )] (%8463:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=189)]) -> (%8464:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=193)])
            linalg.CPU.MatMulOp <name="model.layers.3.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=193, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194, solved=0), )] (%8464:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=193)], %8454:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=34)]) -> (%8465:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194)])
            linalg.CPU.TransposeOp <name="model.layers.3.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194, solved=0), )] (%8465:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194)]) -> (%8466:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194)])
            linalg.CPU.ViewOp <name="model.layers.3.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194, solved=0), )] (%8466:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194)]) -> (%8466:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194)])
            linalg.CPU.LinearOp <name="model.layers.3.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=196, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=195, solved=0))] (%8466:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=194)]) -> (%8467:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=196)])
            cf.ReturnOp (%8467:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=196)], %8447:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=184)], %8449:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=186)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.3.mlp <CPU> [using_qnn:true, symbol:model.layers.3.mlp] {
        (%8469:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=197)]) -> (%8475:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=205)]) {
            linalg.CPU.LinearOp <name="model.layers.3.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=197, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=200, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=199, solved=0))] (%8469:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=197)]) -> (%8470:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=200)])
            linalg.CPU.LinearOp <name="model.layers.3.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=197, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=201, solved=0))] (%8469:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=197)]) -> (%8471:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202)])
            linalg.CPU.SigmoidOp <name="model.layers.3.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=203, solved=0), )] (%8471:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202)]) -> (%8472:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=203)])
            linalg.CPU.MulOp <name="model.layers.3.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=203, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202, solved=0), )] (%8471:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202)], %8472:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=203)]) -> (%8473:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202)])
            linalg.CPU.MulOp <name="model.layers.3.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=200, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202, solved=0), )] (%8473:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202)], %8470:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=200)]) -> (%8474:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202)])
            linalg.CPU.LinearOp <name="model.layers.3.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=205, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=204, solved=0))] (%8474:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=202)]) -> (%8475:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=205)])
            cf.ReturnOp (%8475:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=205)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.4 <CPU> [using_qnn:true, symbol:model.layers.4] {
        (%8476:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8216:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)], %8217:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)]) -> (%8528:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)]) {
            linalg.CPU.RMSNormOp <name="model.layers.4.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=207, solved=0))] (%8476:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8477:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206)])
            graph.CallGraphOp @model.layers.4.self_attn (%8477:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8216:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)], %8217:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)]) -> (%8519:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=231)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)])
            linalg.CPU.AddOp <name="model.layers.4.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=231, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8476:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8519:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=231)]) -> (%8520:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.4.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=232, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=233, solved=0))] (%8520:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8521:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=232)])
            graph.CallGraphOp @model.layers.4.mlp (%8521:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=232)]) -> (%8527:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=240)])
            linalg.CPU.AddOp <name="model.layers.4.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=240, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8520:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8527:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=240)]) -> (%8528:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8528:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.4.self_attn <CPU> [using_qnn:true, symbol:model.layers.4.self_attn] {
        (%8477:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8216:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)], %8217:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)]) -> (%8519:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=231)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)]) {
            linalg.CPU.LinearOp <name="model.layers.4.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=208, solved=0))] (%8477:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206)]) -> (%8478:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209)])
            linalg.CPU.LinearOp <name="model.layers.4.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=210, solved=0))] (%8477:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206)]) -> (%8479:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211)])
            linalg.CPU.LinearOp <name="model.layers.4.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=212, solved=0))] (%8477:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=206)]) -> (%8480:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213)])
            linalg.CPU.ViewOp <name="model.layers.4.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209, solved=0), )] (%8478:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209)]) -> (%8478:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209)])
            linalg.CPU.TransposeOp <name="model.layers.4.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209, solved=0), )] (%8478:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209)]) -> (%8481:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209)])
            linalg.CPU.ViewOp <name="model.layers.4.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211, solved=0), )] (%8479:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211)]) -> (%8479:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211)])
            linalg.CPU.TransposeOp <name="model.layers.4.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211, solved=0), )] (%8479:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211)]) -> (%8482:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211)])
            linalg.CPU.ViewOp <name="model.layers.4.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213, solved=0), )] (%8480:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213)]) -> (%8480:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213)])
            linalg.CPU.TransposeOp <name="model.layers.4.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213, solved=0), )] (%8480:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213)]) -> (%8483:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213)])
            linalg.CPU.RMSNormOp <name="model.layers.4.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=215, solved=0))] (%8481:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=209)]) -> (%8484:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)])
            linalg.CPU.RMSNormOp <name="model.layers.4.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=217, solved=0))] (%8482:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=211)]) -> (%8485:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)])
            linalg.CPU.ViewOp <name="model.layers.4.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.4.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.4.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), )] (%8484:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)]) -> (%8484:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)])
            linalg.CPU.SliceOp <name="model.layers.4.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), )] (%8484:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)]) -> (%8484:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)])
            linalg.CPU.NegOp <name="model.layers.4.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), )] (%8484:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)]) -> (%8486:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)])
            linalg.CPU.ConcatOp <name="model.layers.4.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), )] (%8486:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)], %8484:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)]) -> (%8487:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)])
            linalg.CPU.MulOp <name="model.layers.4.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), )] (%8487:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8488:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)])
            linalg.CPU.MulOp <name="model.layers.4.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), )] (%8484:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8489:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)])
            linalg.CPU.AddOp <name="model.layers.4.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), )] (%8489:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)], %8488:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)]) -> (%8490:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)])
            linalg.CPU.SliceOp <name="model.layers.4.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), )] (%8485:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)]) -> (%8485:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)])
            linalg.CPU.SliceOp <name="model.layers.4.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), )] (%8485:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)]) -> (%8485:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)])
            linalg.CPU.NegOp <name="model.layers.4.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), )] (%8485:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)]) -> (%8491:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)])
            linalg.CPU.ConcatOp <name="model.layers.4.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), )] (%8491:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)], %8485:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)]) -> (%8492:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)])
            linalg.CPU.MulOp <name="model.layers.4.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), )] (%8492:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8493:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)])
            linalg.CPU.MulOp <name="model.layers.4.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), )] (%8485:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8494:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)])
            linalg.CPU.AddOp <name="model.layers.4.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), )] (%8494:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)], %8493:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)]) -> (%8495:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)])
            linalg.CPU.CastTypeOp <name="model.layers.4.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=218, solved=0), )] (%8495:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=216)]) -> (%8496:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=218)])
            linalg.CPU.CastTypeOp <name="model.layers.4.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=218, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219, solved=0), )] (%8496:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=218)]) -> (%8497:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)])
            linalg.CPU.TransposeOp <name="model.layers.4.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219, solved=0), )] (%8497:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)]) -> (%8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)])
            linalg.CPU.CastTypeOp <name="model.layers.4.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=220, solved=0), )] (%8483:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=213)]) -> (%8500:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=220)])
            linalg.CPU.CastTypeOp <name="model.layers.4.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=220, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221, solved=0), )] (%8500:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=220)]) -> (%8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)])
            linalg.CPU.ConcatOp <name="model.layers.4.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7, solved=0), )] (%8216:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)]) -> (%8503:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)])
            linalg.CPU.ConcatOp <name="model.layers.4.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35, solved=0), )] (%8217:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)]) -> (%8504:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)])
            linalg.CPU.RepeatOp <name="model.layers.4.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7, solved=0), )] (%8503:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)]) -> (%8505:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)])
            linalg.CPU.RepeatOp <name="model.layers.4.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35, solved=0), )] (%8504:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)]) -> (%8506:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)])
            linalg.CPU.MatMulOp <name="model.layers.4.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222, solved=0), )] (%8490:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=214)], %8505:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=7)]) -> (%8507:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222)])
            linalg.CPU.MulOp <name="model.layers.4.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=223, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222, solved=0), )] (%8507:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222)], %8508:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=223), constant:[0.088388346]]) -> (%8509:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222)])
            linalg.CPU.ReduceMinOp <name="model.layers.4.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224, solved=0), )] (%8509:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222)]) -> (%8510:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224)])
            linalg.CPU.AddOp <name="model.layers.4.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=225, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224, solved=0), )] (%8510:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224)], %8511:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=225), constant:[-20]]) -> (%8512:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224)])
            linalg.CPU.EqualOp <name="model.layers.4.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=226, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=227, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8513:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=226), constant:[0]]) -> (%8514:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=227)])
            linalg.CPU.WhereOp <name="model.layers.4.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=227, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224, solved=0), )] (%8514:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=227)], %8509:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=222)], %8512:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224)]) -> (%8515:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224)])
            linalg.CPU.SoftmaxOp <name="model.layers.4.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=228, solved=0), )] (%8515:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=224)]) -> (%8516:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=228)])
            linalg.CPU.MatMulOp <name="model.layers.4.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=228, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229, solved=0), )] (%8516:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=228)], %8506:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=35)]) -> (%8517:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229)])
            linalg.CPU.TransposeOp <name="model.layers.4.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229, solved=0), )] (%8517:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229)]) -> (%8518:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229)])
            linalg.CPU.ViewOp <name="model.layers.4.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229, solved=0), )] (%8518:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229)]) -> (%8518:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229)])
            linalg.CPU.LinearOp <name="model.layers.4.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=231, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=230, solved=0))] (%8518:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=229)]) -> (%8519:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=231)])
            cf.ReturnOp (%8519:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=231)], %8499:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=219)], %8501:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=221)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.4.mlp <CPU> [using_qnn:true, symbol:model.layers.4.mlp] {
        (%8521:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=232)]) -> (%8527:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=240)]) {
            linalg.CPU.LinearOp <name="model.layers.4.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=232, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=235, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=234, solved=0))] (%8521:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=232)]) -> (%8522:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=235)])
            linalg.CPU.LinearOp <name="model.layers.4.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=232, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=236, solved=0))] (%8521:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=232)]) -> (%8523:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237)])
            linalg.CPU.SigmoidOp <name="model.layers.4.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=238, solved=0), )] (%8523:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237)]) -> (%8524:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=238)])
            linalg.CPU.MulOp <name="model.layers.4.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=238, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237, solved=0), )] (%8523:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237)], %8524:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=238)]) -> (%8525:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237)])
            linalg.CPU.MulOp <name="model.layers.4.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=235, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237, solved=0), )] (%8525:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237)], %8522:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=235)]) -> (%8526:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237)])
            linalg.CPU.LinearOp <name="model.layers.4.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=240, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=239, solved=0))] (%8526:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=237)]) -> (%8527:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=240)])
            cf.ReturnOp (%8527:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=240)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.5 <CPU> [using_qnn:true, symbol:model.layers.5] {
        (%8528:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8218:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)], %8219:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)]) -> (%8580:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)]) {
            linalg.CPU.RMSNormOp <name="model.layers.5.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=242, solved=0))] (%8528:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8529:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241)])
            graph.CallGraphOp @model.layers.5.self_attn (%8529:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8218:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)], %8219:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)]) -> (%8571:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=266)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)])
            linalg.CPU.AddOp <name="model.layers.5.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=266, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8528:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8571:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=266)]) -> (%8572:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.5.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=267, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=268, solved=0))] (%8572:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8573:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=267)])
            graph.CallGraphOp @model.layers.5.mlp (%8573:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=267)]) -> (%8579:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=275)])
            linalg.CPU.AddOp <name="model.layers.5.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=275, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8572:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8579:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=275)]) -> (%8580:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8580:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.5.self_attn <CPU> [using_qnn:true, symbol:model.layers.5.self_attn] {
        (%8529:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8218:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)], %8219:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)]) -> (%8571:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=266)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)]) {
            linalg.CPU.LinearOp <name="model.layers.5.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=243, solved=0))] (%8529:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241)]) -> (%8530:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244)])
            linalg.CPU.LinearOp <name="model.layers.5.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=245, solved=0))] (%8529:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241)]) -> (%8531:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246)])
            linalg.CPU.LinearOp <name="model.layers.5.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=247, solved=0))] (%8529:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=241)]) -> (%8532:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248)])
            linalg.CPU.ViewOp <name="model.layers.5.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244, solved=0), )] (%8530:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244)]) -> (%8530:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244)])
            linalg.CPU.TransposeOp <name="model.layers.5.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244, solved=0), )] (%8530:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244)]) -> (%8533:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244)])
            linalg.CPU.ViewOp <name="model.layers.5.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246, solved=0), )] (%8531:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246)]) -> (%8531:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246)])
            linalg.CPU.TransposeOp <name="model.layers.5.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246, solved=0), )] (%8531:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246)]) -> (%8534:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246)])
            linalg.CPU.ViewOp <name="model.layers.5.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248, solved=0), )] (%8532:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248)]) -> (%8532:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248)])
            linalg.CPU.TransposeOp <name="model.layers.5.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248, solved=0), )] (%8532:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248)]) -> (%8535:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248)])
            linalg.CPU.RMSNormOp <name="model.layers.5.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=250, solved=0))] (%8533:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=244)]) -> (%8536:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)])
            linalg.CPU.RMSNormOp <name="model.layers.5.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=252, solved=0))] (%8534:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=246)]) -> (%8537:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)])
            linalg.CPU.ViewOp <name="model.layers.5.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.5.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.5.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), )] (%8536:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)]) -> (%8536:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)])
            linalg.CPU.SliceOp <name="model.layers.5.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), )] (%8536:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)]) -> (%8536:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)])
            linalg.CPU.NegOp <name="model.layers.5.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), )] (%8536:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)]) -> (%8538:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)])
            linalg.CPU.ConcatOp <name="model.layers.5.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), )] (%8538:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)], %8536:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)]) -> (%8539:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)])
            linalg.CPU.MulOp <name="model.layers.5.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), )] (%8539:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8540:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)])
            linalg.CPU.MulOp <name="model.layers.5.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), )] (%8536:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8541:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)])
            linalg.CPU.AddOp <name="model.layers.5.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), )] (%8541:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)], %8540:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)]) -> (%8542:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)])
            linalg.CPU.SliceOp <name="model.layers.5.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), )] (%8537:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)]) -> (%8537:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)])
            linalg.CPU.SliceOp <name="model.layers.5.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), )] (%8537:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)]) -> (%8537:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)])
            linalg.CPU.NegOp <name="model.layers.5.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), )] (%8537:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)]) -> (%8543:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)])
            linalg.CPU.ConcatOp <name="model.layers.5.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), )] (%8543:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)], %8537:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)]) -> (%8544:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)])
            linalg.CPU.MulOp <name="model.layers.5.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), )] (%8544:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8545:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)])
            linalg.CPU.MulOp <name="model.layers.5.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), )] (%8537:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8546:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)])
            linalg.CPU.AddOp <name="model.layers.5.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), )] (%8546:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)], %8545:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)]) -> (%8547:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)])
            linalg.CPU.CastTypeOp <name="model.layers.5.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=253, solved=0), )] (%8547:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=251)]) -> (%8548:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=253)])
            linalg.CPU.CastTypeOp <name="model.layers.5.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=253, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254, solved=0), )] (%8548:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=253)]) -> (%8549:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)])
            linalg.CPU.TransposeOp <name="model.layers.5.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254, solved=0), )] (%8549:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)]) -> (%8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)])
            linalg.CPU.CastTypeOp <name="model.layers.5.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=255, solved=0), )] (%8535:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=248)]) -> (%8552:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=255)])
            linalg.CPU.CastTypeOp <name="model.layers.5.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=255, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256, solved=0), )] (%8552:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=255)]) -> (%8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)])
            linalg.CPU.ConcatOp <name="model.layers.5.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8, solved=0), )] (%8218:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)]) -> (%8555:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)])
            linalg.CPU.ConcatOp <name="model.layers.5.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36, solved=0), )] (%8219:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)]) -> (%8556:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)])
            linalg.CPU.RepeatOp <name="model.layers.5.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8, solved=0), )] (%8555:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)]) -> (%8557:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)])
            linalg.CPU.RepeatOp <name="model.layers.5.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36, solved=0), )] (%8556:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)]) -> (%8558:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)])
            linalg.CPU.MatMulOp <name="model.layers.5.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257, solved=0), )] (%8542:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=249)], %8557:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=8)]) -> (%8559:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257)])
            linalg.CPU.MulOp <name="model.layers.5.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=258, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257, solved=0), )] (%8559:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257)], %8560:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=258), constant:[0.088388346]]) -> (%8561:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257)])
            linalg.CPU.ReduceMinOp <name="model.layers.5.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259, solved=0), )] (%8561:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257)]) -> (%8562:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259)])
            linalg.CPU.AddOp <name="model.layers.5.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=260, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259, solved=0), )] (%8562:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259)], %8563:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=260), constant:[-20]]) -> (%8564:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259)])
            linalg.CPU.EqualOp <name="model.layers.5.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=261, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=262, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8565:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=261), constant:[0]]) -> (%8566:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=262)])
            linalg.CPU.WhereOp <name="model.layers.5.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=262, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259, solved=0), )] (%8566:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=262)], %8561:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=257)], %8564:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259)]) -> (%8567:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259)])
            linalg.CPU.SoftmaxOp <name="model.layers.5.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=263, solved=0), )] (%8567:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=259)]) -> (%8568:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=263)])
            linalg.CPU.MatMulOp <name="model.layers.5.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=263, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264, solved=0), )] (%8568:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=263)], %8558:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=36)]) -> (%8569:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264)])
            linalg.CPU.TransposeOp <name="model.layers.5.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264, solved=0), )] (%8569:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264)]) -> (%8570:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264)])
            linalg.CPU.ViewOp <name="model.layers.5.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264, solved=0), )] (%8570:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264)]) -> (%8570:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264)])
            linalg.CPU.LinearOp <name="model.layers.5.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=266, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=265, solved=0))] (%8570:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=264)]) -> (%8571:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=266)])
            cf.ReturnOp (%8571:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=266)], %8551:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=254)], %8553:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=256)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.5.mlp <CPU> [using_qnn:true, symbol:model.layers.5.mlp] {
        (%8573:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=267)]) -> (%8579:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=275)]) {
            linalg.CPU.LinearOp <name="model.layers.5.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=267, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=270, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=269, solved=0))] (%8573:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=267)]) -> (%8574:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=270)])
            linalg.CPU.LinearOp <name="model.layers.5.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=267, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=271, solved=0))] (%8573:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=267)]) -> (%8575:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272)])
            linalg.CPU.SigmoidOp <name="model.layers.5.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=273, solved=0), )] (%8575:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272)]) -> (%8576:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=273)])
            linalg.CPU.MulOp <name="model.layers.5.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=273, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272, solved=0), )] (%8575:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272)], %8576:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=273)]) -> (%8577:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272)])
            linalg.CPU.MulOp <name="model.layers.5.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=270, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272, solved=0), )] (%8577:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272)], %8574:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=270)]) -> (%8578:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272)])
            linalg.CPU.LinearOp <name="model.layers.5.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=275, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=274, solved=0))] (%8578:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=272)]) -> (%8579:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=275)])
            cf.ReturnOp (%8579:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=275)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.6 <CPU> [using_qnn:true, symbol:model.layers.6] {
        (%8580:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8220:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)], %8221:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)]) -> (%8632:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)]) {
            linalg.CPU.RMSNormOp <name="model.layers.6.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=277, solved=0))] (%8580:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8581:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276)])
            graph.CallGraphOp @model.layers.6.self_attn (%8581:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8220:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)], %8221:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)]) -> (%8623:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=301)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)])
            linalg.CPU.AddOp <name="model.layers.6.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=301, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8580:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8623:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=301)]) -> (%8624:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.6.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=302, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=303, solved=0))] (%8624:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8625:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=302)])
            graph.CallGraphOp @model.layers.6.mlp (%8625:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=302)]) -> (%8631:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=310)])
            linalg.CPU.AddOp <name="model.layers.6.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=310, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8624:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8631:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=310)]) -> (%8632:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8632:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.6.self_attn <CPU> [using_qnn:true, symbol:model.layers.6.self_attn] {
        (%8581:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8220:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)], %8221:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)]) -> (%8623:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=301)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)]) {
            linalg.CPU.LinearOp <name="model.layers.6.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=278, solved=0))] (%8581:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276)]) -> (%8582:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279)])
            linalg.CPU.LinearOp <name="model.layers.6.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=280, solved=0))] (%8581:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276)]) -> (%8583:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281)])
            linalg.CPU.LinearOp <name="model.layers.6.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=282, solved=0))] (%8581:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=276)]) -> (%8584:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283)])
            linalg.CPU.ViewOp <name="model.layers.6.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279, solved=0), )] (%8582:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279)]) -> (%8582:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279)])
            linalg.CPU.TransposeOp <name="model.layers.6.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279, solved=0), )] (%8582:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279)]) -> (%8585:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279)])
            linalg.CPU.ViewOp <name="model.layers.6.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281, solved=0), )] (%8583:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281)]) -> (%8583:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281)])
            linalg.CPU.TransposeOp <name="model.layers.6.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281, solved=0), )] (%8583:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281)]) -> (%8586:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281)])
            linalg.CPU.ViewOp <name="model.layers.6.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283, solved=0), )] (%8584:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283)]) -> (%8584:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283)])
            linalg.CPU.TransposeOp <name="model.layers.6.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283, solved=0), )] (%8584:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283)]) -> (%8587:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283)])
            linalg.CPU.RMSNormOp <name="model.layers.6.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=285, solved=0))] (%8585:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=279)]) -> (%8588:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)])
            linalg.CPU.RMSNormOp <name="model.layers.6.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=287, solved=0))] (%8586:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=281)]) -> (%8589:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)])
            linalg.CPU.ViewOp <name="model.layers.6.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.6.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.6.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), )] (%8588:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)]) -> (%8588:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)])
            linalg.CPU.SliceOp <name="model.layers.6.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), )] (%8588:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)]) -> (%8588:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)])
            linalg.CPU.NegOp <name="model.layers.6.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), )] (%8588:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)]) -> (%8590:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)])
            linalg.CPU.ConcatOp <name="model.layers.6.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), )] (%8590:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)], %8588:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)]) -> (%8591:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)])
            linalg.CPU.MulOp <name="model.layers.6.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), )] (%8591:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8592:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)])
            linalg.CPU.MulOp <name="model.layers.6.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), )] (%8588:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8593:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)])
            linalg.CPU.AddOp <name="model.layers.6.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), )] (%8593:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)], %8592:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)]) -> (%8594:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)])
            linalg.CPU.SliceOp <name="model.layers.6.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), )] (%8589:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)]) -> (%8589:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)])
            linalg.CPU.SliceOp <name="model.layers.6.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), )] (%8589:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)]) -> (%8589:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)])
            linalg.CPU.NegOp <name="model.layers.6.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), )] (%8589:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)]) -> (%8595:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)])
            linalg.CPU.ConcatOp <name="model.layers.6.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), )] (%8595:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)], %8589:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)]) -> (%8596:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)])
            linalg.CPU.MulOp <name="model.layers.6.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), )] (%8596:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8597:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)])
            linalg.CPU.MulOp <name="model.layers.6.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), )] (%8589:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8598:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)])
            linalg.CPU.AddOp <name="model.layers.6.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), )] (%8598:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)], %8597:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)]) -> (%8599:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)])
            linalg.CPU.CastTypeOp <name="model.layers.6.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=288, solved=0), )] (%8599:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=286)]) -> (%8600:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=288)])
            linalg.CPU.CastTypeOp <name="model.layers.6.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=288, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289, solved=0), )] (%8600:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=288)]) -> (%8601:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)])
            linalg.CPU.TransposeOp <name="model.layers.6.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289, solved=0), )] (%8601:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)]) -> (%8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)])
            linalg.CPU.CastTypeOp <name="model.layers.6.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=290, solved=0), )] (%8587:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=283)]) -> (%8604:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=290)])
            linalg.CPU.CastTypeOp <name="model.layers.6.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=290, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291, solved=0), )] (%8604:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=290)]) -> (%8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)])
            linalg.CPU.ConcatOp <name="model.layers.6.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9, solved=0), )] (%8220:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)]) -> (%8607:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)])
            linalg.CPU.ConcatOp <name="model.layers.6.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37, solved=0), )] (%8221:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)]) -> (%8608:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)])
            linalg.CPU.RepeatOp <name="model.layers.6.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9, solved=0), )] (%8607:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)]) -> (%8609:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)])
            linalg.CPU.RepeatOp <name="model.layers.6.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37, solved=0), )] (%8608:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)]) -> (%8610:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)])
            linalg.CPU.MatMulOp <name="model.layers.6.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292, solved=0), )] (%8594:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=284)], %8609:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=9)]) -> (%8611:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292)])
            linalg.CPU.MulOp <name="model.layers.6.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=293, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292, solved=0), )] (%8611:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292)], %8612:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=293), constant:[0.088388346]]) -> (%8613:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292)])
            linalg.CPU.ReduceMinOp <name="model.layers.6.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294, solved=0), )] (%8613:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292)]) -> (%8614:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294)])
            linalg.CPU.AddOp <name="model.layers.6.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=295, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294, solved=0), )] (%8614:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294)], %8615:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=295), constant:[-20]]) -> (%8616:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294)])
            linalg.CPU.EqualOp <name="model.layers.6.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=296, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=297, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8617:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=296), constant:[0]]) -> (%8618:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=297)])
            linalg.CPU.WhereOp <name="model.layers.6.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=297, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294, solved=0), )] (%8618:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=297)], %8613:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=292)], %8616:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294)]) -> (%8619:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294)])
            linalg.CPU.SoftmaxOp <name="model.layers.6.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=298, solved=0), )] (%8619:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=294)]) -> (%8620:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=298)])
            linalg.CPU.MatMulOp <name="model.layers.6.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=298, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299, solved=0), )] (%8620:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=298)], %8610:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=37)]) -> (%8621:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299)])
            linalg.CPU.TransposeOp <name="model.layers.6.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299, solved=0), )] (%8621:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299)]) -> (%8622:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299)])
            linalg.CPU.ViewOp <name="model.layers.6.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299, solved=0), )] (%8622:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299)]) -> (%8622:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299)])
            linalg.CPU.LinearOp <name="model.layers.6.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=301, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=300, solved=0))] (%8622:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=299)]) -> (%8623:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=301)])
            cf.ReturnOp (%8623:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=301)], %8603:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=289)], %8605:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=291)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.6.mlp <CPU> [using_qnn:true, symbol:model.layers.6.mlp] {
        (%8625:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=302)]) -> (%8631:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=310)]) {
            linalg.CPU.LinearOp <name="model.layers.6.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=302, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=305, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=304, solved=0))] (%8625:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=302)]) -> (%8626:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=305)])
            linalg.CPU.LinearOp <name="model.layers.6.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=302, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=306, solved=0))] (%8625:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=302)]) -> (%8627:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307)])
            linalg.CPU.SigmoidOp <name="model.layers.6.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=308, solved=0), )] (%8627:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307)]) -> (%8628:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=308)])
            linalg.CPU.MulOp <name="model.layers.6.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=308, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307, solved=0), )] (%8627:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307)], %8628:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=308)]) -> (%8629:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307)])
            linalg.CPU.MulOp <name="model.layers.6.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=305, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307, solved=0), )] (%8629:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307)], %8626:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=305)]) -> (%8630:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307)])
            linalg.CPU.LinearOp <name="model.layers.6.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=310, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=309, solved=0))] (%8630:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=307)]) -> (%8631:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=310)])
            cf.ReturnOp (%8631:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=310)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.7 <CPU> [using_qnn:true, symbol:model.layers.7] {
        (%8632:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8222:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)], %8223:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)]) -> (%8684:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)]) {
            linalg.CPU.RMSNormOp <name="model.layers.7.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=312, solved=0))] (%8632:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8633:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311)])
            graph.CallGraphOp @model.layers.7.self_attn (%8633:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8222:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)], %8223:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)]) -> (%8675:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=336)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)])
            linalg.CPU.AddOp <name="model.layers.7.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=336, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8632:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8675:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=336)]) -> (%8676:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.7.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=337, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=338, solved=0))] (%8676:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8677:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=337)])
            graph.CallGraphOp @model.layers.7.mlp (%8677:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=337)]) -> (%8683:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=345)])
            linalg.CPU.AddOp <name="model.layers.7.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=345, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8676:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8683:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=345)]) -> (%8684:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8684:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.7.self_attn <CPU> [using_qnn:true, symbol:model.layers.7.self_attn] {
        (%8633:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8222:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)], %8223:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)]) -> (%8675:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=336)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)]) {
            linalg.CPU.LinearOp <name="model.layers.7.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=313, solved=0))] (%8633:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311)]) -> (%8634:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314)])
            linalg.CPU.LinearOp <name="model.layers.7.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=315, solved=0))] (%8633:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311)]) -> (%8635:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316)])
            linalg.CPU.LinearOp <name="model.layers.7.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=317, solved=0))] (%8633:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=311)]) -> (%8636:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318)])
            linalg.CPU.ViewOp <name="model.layers.7.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314, solved=0), )] (%8634:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314)]) -> (%8634:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314)])
            linalg.CPU.TransposeOp <name="model.layers.7.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314, solved=0), )] (%8634:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314)]) -> (%8637:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314)])
            linalg.CPU.ViewOp <name="model.layers.7.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316, solved=0), )] (%8635:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316)]) -> (%8635:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316)])
            linalg.CPU.TransposeOp <name="model.layers.7.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316, solved=0), )] (%8635:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316)]) -> (%8638:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316)])
            linalg.CPU.ViewOp <name="model.layers.7.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318, solved=0), )] (%8636:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318)]) -> (%8636:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318)])
            linalg.CPU.TransposeOp <name="model.layers.7.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318, solved=0), )] (%8636:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318)]) -> (%8639:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318)])
            linalg.CPU.RMSNormOp <name="model.layers.7.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=320, solved=0))] (%8637:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=314)]) -> (%8640:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)])
            linalg.CPU.RMSNormOp <name="model.layers.7.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=322, solved=0))] (%8638:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=316)]) -> (%8641:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)])
            linalg.CPU.ViewOp <name="model.layers.7.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.7.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.7.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), )] (%8640:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)]) -> (%8640:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)])
            linalg.CPU.SliceOp <name="model.layers.7.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), )] (%8640:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)]) -> (%8640:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)])
            linalg.CPU.NegOp <name="model.layers.7.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), )] (%8640:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)]) -> (%8642:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)])
            linalg.CPU.ConcatOp <name="model.layers.7.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), )] (%8642:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)], %8640:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)]) -> (%8643:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)])
            linalg.CPU.MulOp <name="model.layers.7.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), )] (%8643:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8644:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)])
            linalg.CPU.MulOp <name="model.layers.7.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), )] (%8640:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8645:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)])
            linalg.CPU.AddOp <name="model.layers.7.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), )] (%8645:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)], %8644:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)]) -> (%8646:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)])
            linalg.CPU.SliceOp <name="model.layers.7.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), )] (%8641:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)]) -> (%8641:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)])
            linalg.CPU.SliceOp <name="model.layers.7.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), )] (%8641:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)]) -> (%8641:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)])
            linalg.CPU.NegOp <name="model.layers.7.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), )] (%8641:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)]) -> (%8647:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)])
            linalg.CPU.ConcatOp <name="model.layers.7.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), )] (%8647:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)], %8641:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)]) -> (%8648:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)])
            linalg.CPU.MulOp <name="model.layers.7.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), )] (%8648:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8649:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)])
            linalg.CPU.MulOp <name="model.layers.7.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), )] (%8641:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8650:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)])
            linalg.CPU.AddOp <name="model.layers.7.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), )] (%8650:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)], %8649:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)]) -> (%8651:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)])
            linalg.CPU.CastTypeOp <name="model.layers.7.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=323, solved=0), )] (%8651:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=321)]) -> (%8652:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=323)])
            linalg.CPU.CastTypeOp <name="model.layers.7.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=323, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324, solved=0), )] (%8652:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=323)]) -> (%8653:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)])
            linalg.CPU.TransposeOp <name="model.layers.7.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324, solved=0), )] (%8653:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)]) -> (%8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)])
            linalg.CPU.CastTypeOp <name="model.layers.7.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=325, solved=0), )] (%8639:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=318)]) -> (%8656:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=325)])
            linalg.CPU.CastTypeOp <name="model.layers.7.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=325, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326, solved=0), )] (%8656:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=325)]) -> (%8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)])
            linalg.CPU.ConcatOp <name="model.layers.7.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10, solved=0), )] (%8222:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)]) -> (%8659:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)])
            linalg.CPU.ConcatOp <name="model.layers.7.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38, solved=0), )] (%8223:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)]) -> (%8660:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)])
            linalg.CPU.RepeatOp <name="model.layers.7.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10, solved=0), )] (%8659:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)]) -> (%8661:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)])
            linalg.CPU.RepeatOp <name="model.layers.7.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38, solved=0), )] (%8660:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)]) -> (%8662:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)])
            linalg.CPU.MatMulOp <name="model.layers.7.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327, solved=0), )] (%8646:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=319)], %8661:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=10)]) -> (%8663:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327)])
            linalg.CPU.MulOp <name="model.layers.7.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=328, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327, solved=0), )] (%8663:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327)], %8664:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=328), constant:[0.088388346]]) -> (%8665:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327)])
            linalg.CPU.ReduceMinOp <name="model.layers.7.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329, solved=0), )] (%8665:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327)]) -> (%8666:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329)])
            linalg.CPU.AddOp <name="model.layers.7.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=330, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329, solved=0), )] (%8666:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329)], %8667:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=330), constant:[-20]]) -> (%8668:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329)])
            linalg.CPU.EqualOp <name="model.layers.7.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=331, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=332, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8669:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=331), constant:[0]]) -> (%8670:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=332)])
            linalg.CPU.WhereOp <name="model.layers.7.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=332, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329, solved=0), )] (%8670:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=332)], %8665:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=327)], %8668:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329)]) -> (%8671:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329)])
            linalg.CPU.SoftmaxOp <name="model.layers.7.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=333, solved=0), )] (%8671:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=329)]) -> (%8672:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=333)])
            linalg.CPU.MatMulOp <name="model.layers.7.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=333, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334, solved=0), )] (%8672:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=333)], %8662:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=38)]) -> (%8673:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334)])
            linalg.CPU.TransposeOp <name="model.layers.7.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334, solved=0), )] (%8673:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334)]) -> (%8674:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334)])
            linalg.CPU.ViewOp <name="model.layers.7.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334, solved=0), )] (%8674:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334)]) -> (%8674:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334)])
            linalg.CPU.LinearOp <name="model.layers.7.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=336, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=335, solved=0))] (%8674:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=334)]) -> (%8675:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=336)])
            cf.ReturnOp (%8675:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=336)], %8655:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=324)], %8657:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=326)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.7.mlp <CPU> [using_qnn:true, symbol:model.layers.7.mlp] {
        (%8677:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=337)]) -> (%8683:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=345)]) {
            linalg.CPU.LinearOp <name="model.layers.7.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=337, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=340, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=339, solved=0))] (%8677:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=337)]) -> (%8678:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=340)])
            linalg.CPU.LinearOp <name="model.layers.7.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=337, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=341, solved=0))] (%8677:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=337)]) -> (%8679:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342)])
            linalg.CPU.SigmoidOp <name="model.layers.7.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=343, solved=0), )] (%8679:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342)]) -> (%8680:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=343)])
            linalg.CPU.MulOp <name="model.layers.7.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=343, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342, solved=0), )] (%8679:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342)], %8680:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=343)]) -> (%8681:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342)])
            linalg.CPU.MulOp <name="model.layers.7.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=340, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342, solved=0), )] (%8681:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342)], %8678:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=340)]) -> (%8682:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342)])
            linalg.CPU.LinearOp <name="model.layers.7.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=345, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=344, solved=0))] (%8682:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=342)]) -> (%8683:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=345)])
            cf.ReturnOp (%8683:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=345)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.8 <CPU> [using_qnn:true, symbol:model.layers.8] {
        (%8684:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8224:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)], %8225:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)]) -> (%8736:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)]) {
            linalg.CPU.RMSNormOp <name="model.layers.8.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=347, solved=0))] (%8684:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8685:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346)])
            graph.CallGraphOp @model.layers.8.self_attn (%8685:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8224:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)], %8225:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)]) -> (%8727:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=371)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)])
            linalg.CPU.AddOp <name="model.layers.8.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=371, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8684:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8727:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=371)]) -> (%8728:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.8.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=372, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=373, solved=0))] (%8728:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8729:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=372)])
            graph.CallGraphOp @model.layers.8.mlp (%8729:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=372)]) -> (%8735:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=380)])
            linalg.CPU.AddOp <name="model.layers.8.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=380, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8728:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8735:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=380)]) -> (%8736:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8736:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.8.self_attn <CPU> [using_qnn:true, symbol:model.layers.8.self_attn] {
        (%8685:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8224:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)], %8225:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)]) -> (%8727:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=371)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)]) {
            linalg.CPU.LinearOp <name="model.layers.8.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=348, solved=0))] (%8685:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346)]) -> (%8686:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349)])
            linalg.CPU.LinearOp <name="model.layers.8.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=350, solved=0))] (%8685:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346)]) -> (%8687:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351)])
            linalg.CPU.LinearOp <name="model.layers.8.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=352, solved=0))] (%8685:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=346)]) -> (%8688:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353)])
            linalg.CPU.ViewOp <name="model.layers.8.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349, solved=0), )] (%8686:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349)]) -> (%8686:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349)])
            linalg.CPU.TransposeOp <name="model.layers.8.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349, solved=0), )] (%8686:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349)]) -> (%8689:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349)])
            linalg.CPU.ViewOp <name="model.layers.8.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351, solved=0), )] (%8687:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351)]) -> (%8687:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351)])
            linalg.CPU.TransposeOp <name="model.layers.8.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351, solved=0), )] (%8687:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351)]) -> (%8690:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351)])
            linalg.CPU.ViewOp <name="model.layers.8.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353, solved=0), )] (%8688:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353)]) -> (%8688:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353)])
            linalg.CPU.TransposeOp <name="model.layers.8.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353, solved=0), )] (%8688:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353)]) -> (%8691:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353)])
            linalg.CPU.RMSNormOp <name="model.layers.8.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=355, solved=0))] (%8689:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=349)]) -> (%8692:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)])
            linalg.CPU.RMSNormOp <name="model.layers.8.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=357, solved=0))] (%8690:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=351)]) -> (%8693:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)])
            linalg.CPU.ViewOp <name="model.layers.8.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.8.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.8.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), )] (%8692:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)]) -> (%8692:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)])
            linalg.CPU.SliceOp <name="model.layers.8.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), )] (%8692:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)]) -> (%8692:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)])
            linalg.CPU.NegOp <name="model.layers.8.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), )] (%8692:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)]) -> (%8694:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)])
            linalg.CPU.ConcatOp <name="model.layers.8.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), )] (%8694:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)], %8692:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)]) -> (%8695:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)])
            linalg.CPU.MulOp <name="model.layers.8.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), )] (%8695:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8696:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)])
            linalg.CPU.MulOp <name="model.layers.8.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), )] (%8692:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8697:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)])
            linalg.CPU.AddOp <name="model.layers.8.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), )] (%8697:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)], %8696:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)]) -> (%8698:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)])
            linalg.CPU.SliceOp <name="model.layers.8.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), )] (%8693:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)]) -> (%8693:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)])
            linalg.CPU.SliceOp <name="model.layers.8.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), )] (%8693:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)]) -> (%8693:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)])
            linalg.CPU.NegOp <name="model.layers.8.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), )] (%8693:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)]) -> (%8699:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)])
            linalg.CPU.ConcatOp <name="model.layers.8.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), )] (%8699:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)], %8693:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)]) -> (%8700:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)])
            linalg.CPU.MulOp <name="model.layers.8.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), )] (%8700:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8701:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)])
            linalg.CPU.MulOp <name="model.layers.8.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), )] (%8693:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8702:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)])
            linalg.CPU.AddOp <name="model.layers.8.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), )] (%8702:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)], %8701:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)]) -> (%8703:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)])
            linalg.CPU.CastTypeOp <name="model.layers.8.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=358, solved=0), )] (%8703:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=356)]) -> (%8704:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=358)])
            linalg.CPU.CastTypeOp <name="model.layers.8.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=358, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359, solved=0), )] (%8704:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=358)]) -> (%8705:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)])
            linalg.CPU.TransposeOp <name="model.layers.8.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359, solved=0), )] (%8705:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)]) -> (%8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)])
            linalg.CPU.CastTypeOp <name="model.layers.8.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=360, solved=0), )] (%8691:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=353)]) -> (%8708:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=360)])
            linalg.CPU.CastTypeOp <name="model.layers.8.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=360, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361, solved=0), )] (%8708:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=360)]) -> (%8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)])
            linalg.CPU.ConcatOp <name="model.layers.8.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11, solved=0), )] (%8224:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)]) -> (%8711:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)])
            linalg.CPU.ConcatOp <name="model.layers.8.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39, solved=0), )] (%8225:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)]) -> (%8712:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)])
            linalg.CPU.RepeatOp <name="model.layers.8.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11, solved=0), )] (%8711:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)]) -> (%8713:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)])
            linalg.CPU.RepeatOp <name="model.layers.8.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39, solved=0), )] (%8712:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)]) -> (%8714:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)])
            linalg.CPU.MatMulOp <name="model.layers.8.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362, solved=0), )] (%8698:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=354)], %8713:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=11)]) -> (%8715:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362)])
            linalg.CPU.MulOp <name="model.layers.8.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=363, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362, solved=0), )] (%8715:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362)], %8716:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=363), constant:[0.088388346]]) -> (%8717:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362)])
            linalg.CPU.ReduceMinOp <name="model.layers.8.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364, solved=0), )] (%8717:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362)]) -> (%8718:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364)])
            linalg.CPU.AddOp <name="model.layers.8.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=365, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364, solved=0), )] (%8718:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364)], %8719:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=365), constant:[-20]]) -> (%8720:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364)])
            linalg.CPU.EqualOp <name="model.layers.8.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=366, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=367, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8721:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=366), constant:[0]]) -> (%8722:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=367)])
            linalg.CPU.WhereOp <name="model.layers.8.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=367, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364, solved=0), )] (%8722:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=367)], %8717:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=362)], %8720:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364)]) -> (%8723:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364)])
            linalg.CPU.SoftmaxOp <name="model.layers.8.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=368, solved=0), )] (%8723:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=364)]) -> (%8724:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=368)])
            linalg.CPU.MatMulOp <name="model.layers.8.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=368, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369, solved=0), )] (%8724:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=368)], %8714:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=39)]) -> (%8725:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369)])
            linalg.CPU.TransposeOp <name="model.layers.8.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369, solved=0), )] (%8725:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369)]) -> (%8726:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369)])
            linalg.CPU.ViewOp <name="model.layers.8.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369, solved=0), )] (%8726:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369)]) -> (%8726:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369)])
            linalg.CPU.LinearOp <name="model.layers.8.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=371, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=370, solved=0))] (%8726:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=369)]) -> (%8727:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=371)])
            cf.ReturnOp (%8727:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=371)], %8707:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=359)], %8709:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=361)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.8.mlp <CPU> [using_qnn:true, symbol:model.layers.8.mlp] {
        (%8729:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=372)]) -> (%8735:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=380)]) {
            linalg.CPU.LinearOp <name="model.layers.8.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=372, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=375, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=374, solved=0))] (%8729:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=372)]) -> (%8730:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=375)])
            linalg.CPU.LinearOp <name="model.layers.8.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=372, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=376, solved=0))] (%8729:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=372)]) -> (%8731:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377)])
            linalg.CPU.SigmoidOp <name="model.layers.8.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=378, solved=0), )] (%8731:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377)]) -> (%8732:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=378)])
            linalg.CPU.MulOp <name="model.layers.8.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=378, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377, solved=0), )] (%8731:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377)], %8732:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=378)]) -> (%8733:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377)])
            linalg.CPU.MulOp <name="model.layers.8.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=375, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377, solved=0), )] (%8733:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377)], %8730:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=375)]) -> (%8734:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377)])
            linalg.CPU.LinearOp <name="model.layers.8.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=380, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=379, solved=0))] (%8734:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=377)]) -> (%8735:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=380)])
            cf.ReturnOp (%8735:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=380)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.9 <CPU> [using_qnn:true, symbol:model.layers.9] {
        (%8736:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8226:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)], %8227:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)]) -> (%8788:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)]) {
            linalg.CPU.RMSNormOp <name="model.layers.9.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=382, solved=0))] (%8736:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8737:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381)])
            graph.CallGraphOp @model.layers.9.self_attn (%8737:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8226:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)], %8227:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)]) -> (%8779:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=406)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)])
            linalg.CPU.AddOp <name="model.layers.9.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=406, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8736:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8779:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=406)]) -> (%8780:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.9.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=407, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=408, solved=0))] (%8780:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8781:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=407)])
            graph.CallGraphOp @model.layers.9.mlp (%8781:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=407)]) -> (%8787:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=415)])
            linalg.CPU.AddOp <name="model.layers.9.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=415, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8780:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8787:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=415)]) -> (%8788:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8788:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.9.self_attn <CPU> [using_qnn:true, symbol:model.layers.9.self_attn] {
        (%8737:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8226:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)], %8227:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)]) -> (%8779:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=406)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)]) {
            linalg.CPU.LinearOp <name="model.layers.9.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=383, solved=0))] (%8737:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381)]) -> (%8738:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384)])
            linalg.CPU.LinearOp <name="model.layers.9.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=385, solved=0))] (%8737:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381)]) -> (%8739:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386)])
            linalg.CPU.LinearOp <name="model.layers.9.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=387, solved=0))] (%8737:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=381)]) -> (%8740:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388)])
            linalg.CPU.ViewOp <name="model.layers.9.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384, solved=0), )] (%8738:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384)]) -> (%8738:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384)])
            linalg.CPU.TransposeOp <name="model.layers.9.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384, solved=0), )] (%8738:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384)]) -> (%8741:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384)])
            linalg.CPU.ViewOp <name="model.layers.9.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386, solved=0), )] (%8739:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386)]) -> (%8739:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386)])
            linalg.CPU.TransposeOp <name="model.layers.9.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386, solved=0), )] (%8739:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386)]) -> (%8742:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386)])
            linalg.CPU.ViewOp <name="model.layers.9.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388, solved=0), )] (%8740:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388)]) -> (%8740:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388)])
            linalg.CPU.TransposeOp <name="model.layers.9.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388, solved=0), )] (%8740:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388)]) -> (%8743:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388)])
            linalg.CPU.RMSNormOp <name="model.layers.9.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=390, solved=0))] (%8741:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=384)]) -> (%8744:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)])
            linalg.CPU.RMSNormOp <name="model.layers.9.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=392, solved=0))] (%8742:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=386)]) -> (%8745:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)])
            linalg.CPU.ViewOp <name="model.layers.9.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.9.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.9.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), )] (%8744:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)]) -> (%8744:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)])
            linalg.CPU.SliceOp <name="model.layers.9.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), )] (%8744:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)]) -> (%8744:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)])
            linalg.CPU.NegOp <name="model.layers.9.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), )] (%8744:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)]) -> (%8746:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)])
            linalg.CPU.ConcatOp <name="model.layers.9.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), )] (%8746:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)], %8744:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)]) -> (%8747:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)])
            linalg.CPU.MulOp <name="model.layers.9.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), )] (%8747:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8748:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)])
            linalg.CPU.MulOp <name="model.layers.9.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), )] (%8744:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8749:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)])
            linalg.CPU.AddOp <name="model.layers.9.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), )] (%8749:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)], %8748:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)]) -> (%8750:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)])
            linalg.CPU.SliceOp <name="model.layers.9.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), )] (%8745:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)]) -> (%8745:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)])
            linalg.CPU.SliceOp <name="model.layers.9.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), )] (%8745:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)]) -> (%8745:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)])
            linalg.CPU.NegOp <name="model.layers.9.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), )] (%8745:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)]) -> (%8751:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)])
            linalg.CPU.ConcatOp <name="model.layers.9.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), )] (%8751:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)], %8745:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)]) -> (%8752:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)])
            linalg.CPU.MulOp <name="model.layers.9.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), )] (%8752:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8753:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)])
            linalg.CPU.MulOp <name="model.layers.9.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), )] (%8745:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8754:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)])
            linalg.CPU.AddOp <name="model.layers.9.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), )] (%8754:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)], %8753:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)]) -> (%8755:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)])
            linalg.CPU.CastTypeOp <name="model.layers.9.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=393, solved=0), )] (%8755:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=391)]) -> (%8756:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=393)])
            linalg.CPU.CastTypeOp <name="model.layers.9.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=393, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394, solved=0), )] (%8756:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=393)]) -> (%8757:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)])
            linalg.CPU.TransposeOp <name="model.layers.9.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394, solved=0), )] (%8757:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)]) -> (%8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)])
            linalg.CPU.CastTypeOp <name="model.layers.9.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=395, solved=0), )] (%8743:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=388)]) -> (%8760:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=395)])
            linalg.CPU.CastTypeOp <name="model.layers.9.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=395, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396, solved=0), )] (%8760:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=395)]) -> (%8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)])
            linalg.CPU.ConcatOp <name="model.layers.9.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12, solved=0), )] (%8226:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)]) -> (%8763:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)])
            linalg.CPU.ConcatOp <name="model.layers.9.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40, solved=0), )] (%8227:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)]) -> (%8764:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)])
            linalg.CPU.RepeatOp <name="model.layers.9.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12, solved=0), )] (%8763:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)]) -> (%8765:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)])
            linalg.CPU.RepeatOp <name="model.layers.9.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40, solved=0), )] (%8764:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)]) -> (%8766:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)])
            linalg.CPU.MatMulOp <name="model.layers.9.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397, solved=0), )] (%8750:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=389)], %8765:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=12)]) -> (%8767:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397)])
            linalg.CPU.MulOp <name="model.layers.9.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=398, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397, solved=0), )] (%8767:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397)], %8768:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=398), constant:[0.088388346]]) -> (%8769:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397)])
            linalg.CPU.ReduceMinOp <name="model.layers.9.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399, solved=0), )] (%8769:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397)]) -> (%8770:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399)])
            linalg.CPU.AddOp <name="model.layers.9.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=400, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399, solved=0), )] (%8770:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399)], %8771:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=400), constant:[-20]]) -> (%8772:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399)])
            linalg.CPU.EqualOp <name="model.layers.9.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=401, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=402, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8773:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=401), constant:[0]]) -> (%8774:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=402)])
            linalg.CPU.WhereOp <name="model.layers.9.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=402, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399, solved=0), )] (%8774:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=402)], %8769:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=397)], %8772:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399)]) -> (%8775:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399)])
            linalg.CPU.SoftmaxOp <name="model.layers.9.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=403, solved=0), )] (%8775:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=399)]) -> (%8776:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=403)])
            linalg.CPU.MatMulOp <name="model.layers.9.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=403, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404, solved=0), )] (%8776:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=403)], %8766:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=40)]) -> (%8777:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404)])
            linalg.CPU.TransposeOp <name="model.layers.9.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404, solved=0), )] (%8777:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404)]) -> (%8778:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404)])
            linalg.CPU.ViewOp <name="model.layers.9.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404, solved=0), )] (%8778:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404)]) -> (%8778:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404)])
            linalg.CPU.LinearOp <name="model.layers.9.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=406, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=405, solved=0))] (%8778:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=404)]) -> (%8779:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=406)])
            cf.ReturnOp (%8779:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=406)], %8759:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=394)], %8761:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=396)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.9.mlp <CPU> [using_qnn:true, symbol:model.layers.9.mlp] {
        (%8781:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=407)]) -> (%8787:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=415)]) {
            linalg.CPU.LinearOp <name="model.layers.9.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=407, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=410, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=409, solved=0))] (%8781:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=407)]) -> (%8782:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=410)])
            linalg.CPU.LinearOp <name="model.layers.9.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=407, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=411, solved=0))] (%8781:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=407)]) -> (%8783:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412)])
            linalg.CPU.SigmoidOp <name="model.layers.9.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=413, solved=0), )] (%8783:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412)]) -> (%8784:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=413)])
            linalg.CPU.MulOp <name="model.layers.9.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=413, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412, solved=0), )] (%8783:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412)], %8784:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=413)]) -> (%8785:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412)])
            linalg.CPU.MulOp <name="model.layers.9.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=410, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412, solved=0), )] (%8785:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412)], %8782:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=410)]) -> (%8786:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412)])
            linalg.CPU.LinearOp <name="model.layers.9.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=415, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=414, solved=0))] (%8786:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=412)]) -> (%8787:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=415)])
            cf.ReturnOp (%8787:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=415)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.10 <CPU> [using_qnn:true, symbol:model.layers.10] {
        (%8788:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8228:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)], %8229:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)]) -> (%8840:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)]) {
            linalg.CPU.RMSNormOp <name="model.layers.10.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=417, solved=0))] (%8788:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8789:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416)])
            graph.CallGraphOp @model.layers.10.self_attn (%8789:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8228:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)], %8229:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)]) -> (%8831:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=441)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)])
            linalg.CPU.AddOp <name="model.layers.10.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=441, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8788:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8831:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=441)]) -> (%8832:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.10.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=442, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=443, solved=0))] (%8832:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8833:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=442)])
            graph.CallGraphOp @model.layers.10.mlp (%8833:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=442)]) -> (%8839:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=450)])
            linalg.CPU.AddOp <name="model.layers.10.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=450, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8832:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8839:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=450)]) -> (%8840:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8840:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.10.self_attn <CPU> [using_qnn:true, symbol:model.layers.10.self_attn] {
        (%8789:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8228:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)], %8229:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)]) -> (%8831:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=441)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)]) {
            linalg.CPU.LinearOp <name="model.layers.10.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=418, solved=0))] (%8789:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416)]) -> (%8790:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419)])
            linalg.CPU.LinearOp <name="model.layers.10.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=420, solved=0))] (%8789:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416)]) -> (%8791:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421)])
            linalg.CPU.LinearOp <name="model.layers.10.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=422, solved=0))] (%8789:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=416)]) -> (%8792:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423)])
            linalg.CPU.ViewOp <name="model.layers.10.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419, solved=0), )] (%8790:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419)]) -> (%8790:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419)])
            linalg.CPU.TransposeOp <name="model.layers.10.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419, solved=0), )] (%8790:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419)]) -> (%8793:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419)])
            linalg.CPU.ViewOp <name="model.layers.10.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421, solved=0), )] (%8791:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421)]) -> (%8791:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421)])
            linalg.CPU.TransposeOp <name="model.layers.10.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421, solved=0), )] (%8791:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421)]) -> (%8794:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421)])
            linalg.CPU.ViewOp <name="model.layers.10.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423, solved=0), )] (%8792:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423)]) -> (%8792:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423)])
            linalg.CPU.TransposeOp <name="model.layers.10.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423, solved=0), )] (%8792:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423)]) -> (%8795:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423)])
            linalg.CPU.RMSNormOp <name="model.layers.10.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=425, solved=0))] (%8793:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=419)]) -> (%8796:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)])
            linalg.CPU.RMSNormOp <name="model.layers.10.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=427, solved=0))] (%8794:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=421)]) -> (%8797:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)])
            linalg.CPU.ViewOp <name="model.layers.10.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.10.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.10.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), )] (%8796:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)]) -> (%8796:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)])
            linalg.CPU.SliceOp <name="model.layers.10.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), )] (%8796:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)]) -> (%8796:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)])
            linalg.CPU.NegOp <name="model.layers.10.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), )] (%8796:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)]) -> (%8798:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)])
            linalg.CPU.ConcatOp <name="model.layers.10.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), )] (%8798:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)], %8796:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)]) -> (%8799:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)])
            linalg.CPU.MulOp <name="model.layers.10.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), )] (%8799:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8800:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)])
            linalg.CPU.MulOp <name="model.layers.10.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), )] (%8796:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8801:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)])
            linalg.CPU.AddOp <name="model.layers.10.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), )] (%8801:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)], %8800:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)]) -> (%8802:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)])
            linalg.CPU.SliceOp <name="model.layers.10.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), )] (%8797:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)]) -> (%8797:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)])
            linalg.CPU.SliceOp <name="model.layers.10.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), )] (%8797:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)]) -> (%8797:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)])
            linalg.CPU.NegOp <name="model.layers.10.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), )] (%8797:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)]) -> (%8803:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)])
            linalg.CPU.ConcatOp <name="model.layers.10.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), )] (%8803:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)], %8797:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)]) -> (%8804:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)])
            linalg.CPU.MulOp <name="model.layers.10.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), )] (%8804:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8805:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)])
            linalg.CPU.MulOp <name="model.layers.10.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), )] (%8797:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8806:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)])
            linalg.CPU.AddOp <name="model.layers.10.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), )] (%8806:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)], %8805:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)]) -> (%8807:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)])
            linalg.CPU.CastTypeOp <name="model.layers.10.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=428, solved=0), )] (%8807:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=426)]) -> (%8808:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=428)])
            linalg.CPU.CastTypeOp <name="model.layers.10.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=428, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429, solved=0), )] (%8808:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=428)]) -> (%8809:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)])
            linalg.CPU.TransposeOp <name="model.layers.10.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429, solved=0), )] (%8809:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)]) -> (%8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)])
            linalg.CPU.CastTypeOp <name="model.layers.10.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=430, solved=0), )] (%8795:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=423)]) -> (%8812:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=430)])
            linalg.CPU.CastTypeOp <name="model.layers.10.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=430, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431, solved=0), )] (%8812:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=430)]) -> (%8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)])
            linalg.CPU.ConcatOp <name="model.layers.10.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13, solved=0), )] (%8228:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)]) -> (%8815:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)])
            linalg.CPU.ConcatOp <name="model.layers.10.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41, solved=0), )] (%8229:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)]) -> (%8816:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)])
            linalg.CPU.RepeatOp <name="model.layers.10.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13, solved=0), )] (%8815:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)]) -> (%8817:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)])
            linalg.CPU.RepeatOp <name="model.layers.10.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41, solved=0), )] (%8816:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)]) -> (%8818:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)])
            linalg.CPU.MatMulOp <name="model.layers.10.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432, solved=0), )] (%8802:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=424)], %8817:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=13)]) -> (%8819:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432)])
            linalg.CPU.MulOp <name="model.layers.10.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=433, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432, solved=0), )] (%8819:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432)], %8820:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=433), constant:[0.088388346]]) -> (%8821:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432)])
            linalg.CPU.ReduceMinOp <name="model.layers.10.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434, solved=0), )] (%8821:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432)]) -> (%8822:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434)])
            linalg.CPU.AddOp <name="model.layers.10.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=435, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434, solved=0), )] (%8822:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434)], %8823:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=435), constant:[-20]]) -> (%8824:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434)])
            linalg.CPU.EqualOp <name="model.layers.10.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=436, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=437, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8825:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=436), constant:[0]]) -> (%8826:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=437)])
            linalg.CPU.WhereOp <name="model.layers.10.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=437, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434, solved=0), )] (%8826:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=437)], %8821:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=432)], %8824:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434)]) -> (%8827:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434)])
            linalg.CPU.SoftmaxOp <name="model.layers.10.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=438, solved=0), )] (%8827:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=434)]) -> (%8828:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=438)])
            linalg.CPU.MatMulOp <name="model.layers.10.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=438, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439, solved=0), )] (%8828:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=438)], %8818:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=41)]) -> (%8829:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439)])
            linalg.CPU.TransposeOp <name="model.layers.10.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439, solved=0), )] (%8829:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439)]) -> (%8830:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439)])
            linalg.CPU.ViewOp <name="model.layers.10.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439, solved=0), )] (%8830:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439)]) -> (%8830:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439)])
            linalg.CPU.LinearOp <name="model.layers.10.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=441, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=440, solved=0))] (%8830:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=439)]) -> (%8831:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=441)])
            cf.ReturnOp (%8831:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=441)], %8811:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=429)], %8813:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=431)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.10.mlp <CPU> [using_qnn:true, symbol:model.layers.10.mlp] {
        (%8833:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=442)]) -> (%8839:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=450)]) {
            linalg.CPU.LinearOp <name="model.layers.10.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=442, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=445, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=444, solved=0))] (%8833:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=442)]) -> (%8834:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=445)])
            linalg.CPU.LinearOp <name="model.layers.10.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=442, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=446, solved=0))] (%8833:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=442)]) -> (%8835:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447)])
            linalg.CPU.SigmoidOp <name="model.layers.10.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=448, solved=0), )] (%8835:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447)]) -> (%8836:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=448)])
            linalg.CPU.MulOp <name="model.layers.10.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=448, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447, solved=0), )] (%8835:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447)], %8836:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=448)]) -> (%8837:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447)])
            linalg.CPU.MulOp <name="model.layers.10.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=445, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447, solved=0), )] (%8837:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447)], %8834:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=445)]) -> (%8838:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447)])
            linalg.CPU.LinearOp <name="model.layers.10.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=450, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=449, solved=0))] (%8838:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=447)]) -> (%8839:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=450)])
            cf.ReturnOp (%8839:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=450)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.11 <CPU> [using_qnn:true, symbol:model.layers.11] {
        (%8840:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8230:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)], %8231:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)]) -> (%8892:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)]) {
            linalg.CPU.RMSNormOp <name="model.layers.11.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=452, solved=0))] (%8840:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8841:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451)])
            graph.CallGraphOp @model.layers.11.self_attn (%8841:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8230:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)], %8231:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)]) -> (%8883:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=476)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)])
            linalg.CPU.AddOp <name="model.layers.11.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=476, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8840:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8883:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=476)]) -> (%8884:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.11.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=477, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=478, solved=0))] (%8884:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8885:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=477)])
            graph.CallGraphOp @model.layers.11.mlp (%8885:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=477)]) -> (%8891:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=485)])
            linalg.CPU.AddOp <name="model.layers.11.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=485, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8884:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8891:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=485)]) -> (%8892:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8892:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.11.self_attn <CPU> [using_qnn:true, symbol:model.layers.11.self_attn] {
        (%8841:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8230:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)], %8231:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)]) -> (%8883:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=476)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)]) {
            linalg.CPU.LinearOp <name="model.layers.11.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=453, solved=0))] (%8841:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451)]) -> (%8842:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454)])
            linalg.CPU.LinearOp <name="model.layers.11.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=455, solved=0))] (%8841:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451)]) -> (%8843:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456)])
            linalg.CPU.LinearOp <name="model.layers.11.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=457, solved=0))] (%8841:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=451)]) -> (%8844:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458)])
            linalg.CPU.ViewOp <name="model.layers.11.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454, solved=0), )] (%8842:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454)]) -> (%8842:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454)])
            linalg.CPU.TransposeOp <name="model.layers.11.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454, solved=0), )] (%8842:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454)]) -> (%8845:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454)])
            linalg.CPU.ViewOp <name="model.layers.11.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456, solved=0), )] (%8843:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456)]) -> (%8843:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456)])
            linalg.CPU.TransposeOp <name="model.layers.11.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456, solved=0), )] (%8843:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456)]) -> (%8846:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456)])
            linalg.CPU.ViewOp <name="model.layers.11.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458, solved=0), )] (%8844:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458)]) -> (%8844:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458)])
            linalg.CPU.TransposeOp <name="model.layers.11.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458, solved=0), )] (%8844:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458)]) -> (%8847:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458)])
            linalg.CPU.RMSNormOp <name="model.layers.11.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=460, solved=0))] (%8845:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=454)]) -> (%8848:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)])
            linalg.CPU.RMSNormOp <name="model.layers.11.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=462, solved=0))] (%8846:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=456)]) -> (%8849:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)])
            linalg.CPU.ViewOp <name="model.layers.11.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.11.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.11.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), )] (%8848:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)]) -> (%8848:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)])
            linalg.CPU.SliceOp <name="model.layers.11.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), )] (%8848:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)]) -> (%8848:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)])
            linalg.CPU.NegOp <name="model.layers.11.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), )] (%8848:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)]) -> (%8850:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)])
            linalg.CPU.ConcatOp <name="model.layers.11.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), )] (%8850:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)], %8848:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)]) -> (%8851:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)])
            linalg.CPU.MulOp <name="model.layers.11.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), )] (%8851:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8852:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)])
            linalg.CPU.MulOp <name="model.layers.11.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), )] (%8848:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8853:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)])
            linalg.CPU.AddOp <name="model.layers.11.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), )] (%8853:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)], %8852:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)]) -> (%8854:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)])
            linalg.CPU.SliceOp <name="model.layers.11.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), )] (%8849:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)]) -> (%8849:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)])
            linalg.CPU.SliceOp <name="model.layers.11.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), )] (%8849:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)]) -> (%8849:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)])
            linalg.CPU.NegOp <name="model.layers.11.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), )] (%8849:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)]) -> (%8855:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)])
            linalg.CPU.ConcatOp <name="model.layers.11.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), )] (%8855:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)], %8849:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)]) -> (%8856:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)])
            linalg.CPU.MulOp <name="model.layers.11.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), )] (%8856:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8857:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)])
            linalg.CPU.MulOp <name="model.layers.11.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), )] (%8849:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8858:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)])
            linalg.CPU.AddOp <name="model.layers.11.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), )] (%8858:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)], %8857:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)]) -> (%8859:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)])
            linalg.CPU.CastTypeOp <name="model.layers.11.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=463, solved=0), )] (%8859:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=461)]) -> (%8860:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=463)])
            linalg.CPU.CastTypeOp <name="model.layers.11.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=463, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464, solved=0), )] (%8860:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=463)]) -> (%8861:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)])
            linalg.CPU.TransposeOp <name="model.layers.11.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464, solved=0), )] (%8861:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)]) -> (%8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)])
            linalg.CPU.CastTypeOp <name="model.layers.11.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=465, solved=0), )] (%8847:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=458)]) -> (%8864:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=465)])
            linalg.CPU.CastTypeOp <name="model.layers.11.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=465, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466, solved=0), )] (%8864:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=465)]) -> (%8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)])
            linalg.CPU.ConcatOp <name="model.layers.11.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14, solved=0), )] (%8230:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)]) -> (%8867:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)])
            linalg.CPU.ConcatOp <name="model.layers.11.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42, solved=0), )] (%8231:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)]) -> (%8868:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)])
            linalg.CPU.RepeatOp <name="model.layers.11.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14, solved=0), )] (%8867:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)]) -> (%8869:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)])
            linalg.CPU.RepeatOp <name="model.layers.11.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42, solved=0), )] (%8868:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)]) -> (%8870:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)])
            linalg.CPU.MatMulOp <name="model.layers.11.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467, solved=0), )] (%8854:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=459)], %8869:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=14)]) -> (%8871:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467)])
            linalg.CPU.MulOp <name="model.layers.11.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=468, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467, solved=0), )] (%8871:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467)], %8872:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=468), constant:[0.088388346]]) -> (%8873:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467)])
            linalg.CPU.ReduceMinOp <name="model.layers.11.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469, solved=0), )] (%8873:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467)]) -> (%8874:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469)])
            linalg.CPU.AddOp <name="model.layers.11.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=470, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469, solved=0), )] (%8874:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469)], %8875:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=470), constant:[-20]]) -> (%8876:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469)])
            linalg.CPU.EqualOp <name="model.layers.11.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=471, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=472, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8877:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=471), constant:[0]]) -> (%8878:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=472)])
            linalg.CPU.WhereOp <name="model.layers.11.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=472, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469, solved=0), )] (%8878:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=472)], %8873:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=467)], %8876:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469)]) -> (%8879:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469)])
            linalg.CPU.SoftmaxOp <name="model.layers.11.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=473, solved=0), )] (%8879:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=469)]) -> (%8880:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=473)])
            linalg.CPU.MatMulOp <name="model.layers.11.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=473, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474, solved=0), )] (%8880:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=473)], %8870:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=42)]) -> (%8881:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474)])
            linalg.CPU.TransposeOp <name="model.layers.11.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474, solved=0), )] (%8881:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474)]) -> (%8882:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474)])
            linalg.CPU.ViewOp <name="model.layers.11.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474, solved=0), )] (%8882:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474)]) -> (%8882:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474)])
            linalg.CPU.LinearOp <name="model.layers.11.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=476, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=475, solved=0))] (%8882:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=474)]) -> (%8883:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=476)])
            cf.ReturnOp (%8883:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=476)], %8863:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=464)], %8865:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=466)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.11.mlp <CPU> [using_qnn:true, symbol:model.layers.11.mlp] {
        (%8885:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=477)]) -> (%8891:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=485)]) {
            linalg.CPU.LinearOp <name="model.layers.11.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=477, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=480, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=479, solved=0))] (%8885:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=477)]) -> (%8886:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=480)])
            linalg.CPU.LinearOp <name="model.layers.11.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=477, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=481, solved=0))] (%8885:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=477)]) -> (%8887:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482)])
            linalg.CPU.SigmoidOp <name="model.layers.11.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=483, solved=0), )] (%8887:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482)]) -> (%8888:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=483)])
            linalg.CPU.MulOp <name="model.layers.11.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=483, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482, solved=0), )] (%8887:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482)], %8888:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=483)]) -> (%8889:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482)])
            linalg.CPU.MulOp <name="model.layers.11.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=480, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482, solved=0), )] (%8889:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482)], %8886:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=480)]) -> (%8890:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482)])
            linalg.CPU.LinearOp <name="model.layers.11.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=485, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=484, solved=0))] (%8890:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=482)]) -> (%8891:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=485)])
            cf.ReturnOp (%8891:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=485)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.12 <CPU> [using_qnn:true, symbol:model.layers.12] {
        (%8892:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8232:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)], %8233:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)]) -> (%8944:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)]) {
            linalg.CPU.RMSNormOp <name="model.layers.12.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=487, solved=0))] (%8892:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8893:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486)])
            graph.CallGraphOp @model.layers.12.self_attn (%8893:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8232:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)], %8233:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)]) -> (%8935:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=511)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)])
            linalg.CPU.AddOp <name="model.layers.12.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=511, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8892:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8935:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=511)]) -> (%8936:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.12.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=512, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=513, solved=0))] (%8936:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8937:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=512)])
            graph.CallGraphOp @model.layers.12.mlp (%8937:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=512)]) -> (%8943:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=520)])
            linalg.CPU.AddOp <name="model.layers.12.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=520, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8936:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8943:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=520)]) -> (%8944:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8944:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.12.self_attn <CPU> [using_qnn:true, symbol:model.layers.12.self_attn] {
        (%8893:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8232:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)], %8233:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)]) -> (%8935:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=511)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)]) {
            linalg.CPU.LinearOp <name="model.layers.12.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=488, solved=0))] (%8893:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486)]) -> (%8894:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489)])
            linalg.CPU.LinearOp <name="model.layers.12.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=490, solved=0))] (%8893:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486)]) -> (%8895:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491)])
            linalg.CPU.LinearOp <name="model.layers.12.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=492, solved=0))] (%8893:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=486)]) -> (%8896:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493)])
            linalg.CPU.ViewOp <name="model.layers.12.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489, solved=0), )] (%8894:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489)]) -> (%8894:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489)])
            linalg.CPU.TransposeOp <name="model.layers.12.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489, solved=0), )] (%8894:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489)]) -> (%8897:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489)])
            linalg.CPU.ViewOp <name="model.layers.12.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491, solved=0), )] (%8895:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491)]) -> (%8895:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491)])
            linalg.CPU.TransposeOp <name="model.layers.12.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491, solved=0), )] (%8895:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491)]) -> (%8898:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491)])
            linalg.CPU.ViewOp <name="model.layers.12.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493, solved=0), )] (%8896:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493)]) -> (%8896:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493)])
            linalg.CPU.TransposeOp <name="model.layers.12.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493, solved=0), )] (%8896:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493)]) -> (%8899:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493)])
            linalg.CPU.RMSNormOp <name="model.layers.12.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=495, solved=0))] (%8897:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=489)]) -> (%8900:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)])
            linalg.CPU.RMSNormOp <name="model.layers.12.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=497, solved=0))] (%8898:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=491)]) -> (%8901:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)])
            linalg.CPU.ViewOp <name="model.layers.12.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.12.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.12.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), )] (%8900:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)]) -> (%8900:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)])
            linalg.CPU.SliceOp <name="model.layers.12.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), )] (%8900:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)]) -> (%8900:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)])
            linalg.CPU.NegOp <name="model.layers.12.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), )] (%8900:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)]) -> (%8902:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)])
            linalg.CPU.ConcatOp <name="model.layers.12.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), )] (%8902:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)], %8900:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)]) -> (%8903:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)])
            linalg.CPU.MulOp <name="model.layers.12.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), )] (%8903:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8904:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)])
            linalg.CPU.MulOp <name="model.layers.12.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), )] (%8900:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8905:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)])
            linalg.CPU.AddOp <name="model.layers.12.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), )] (%8905:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)], %8904:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)]) -> (%8906:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)])
            linalg.CPU.SliceOp <name="model.layers.12.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), )] (%8901:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)]) -> (%8901:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)])
            linalg.CPU.SliceOp <name="model.layers.12.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), )] (%8901:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)]) -> (%8901:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)])
            linalg.CPU.NegOp <name="model.layers.12.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), )] (%8901:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)]) -> (%8907:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)])
            linalg.CPU.ConcatOp <name="model.layers.12.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), )] (%8907:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)], %8901:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)]) -> (%8908:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)])
            linalg.CPU.MulOp <name="model.layers.12.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), )] (%8908:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8909:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)])
            linalg.CPU.MulOp <name="model.layers.12.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), )] (%8901:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8910:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)])
            linalg.CPU.AddOp <name="model.layers.12.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), )] (%8910:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)], %8909:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)]) -> (%8911:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)])
            linalg.CPU.CastTypeOp <name="model.layers.12.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=498, solved=0), )] (%8911:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=496)]) -> (%8912:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=498)])
            linalg.CPU.CastTypeOp <name="model.layers.12.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=498, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499, solved=0), )] (%8912:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=498)]) -> (%8913:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)])
            linalg.CPU.TransposeOp <name="model.layers.12.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499, solved=0), )] (%8913:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)]) -> (%8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)])
            linalg.CPU.CastTypeOp <name="model.layers.12.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=500, solved=0), )] (%8899:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=493)]) -> (%8916:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=500)])
            linalg.CPU.CastTypeOp <name="model.layers.12.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=500, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501, solved=0), )] (%8916:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=500)]) -> (%8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)])
            linalg.CPU.ConcatOp <name="model.layers.12.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15, solved=0), )] (%8232:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)]) -> (%8919:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)])
            linalg.CPU.ConcatOp <name="model.layers.12.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43, solved=0), )] (%8233:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)]) -> (%8920:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)])
            linalg.CPU.RepeatOp <name="model.layers.12.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15, solved=0), )] (%8919:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)]) -> (%8921:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)])
            linalg.CPU.RepeatOp <name="model.layers.12.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43, solved=0), )] (%8920:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)]) -> (%8922:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)])
            linalg.CPU.MatMulOp <name="model.layers.12.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502, solved=0), )] (%8906:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=494)], %8921:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=15)]) -> (%8923:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502)])
            linalg.CPU.MulOp <name="model.layers.12.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=503, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502, solved=0), )] (%8923:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502)], %8924:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=503), constant:[0.088388346]]) -> (%8925:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502)])
            linalg.CPU.ReduceMinOp <name="model.layers.12.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504, solved=0), )] (%8925:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502)]) -> (%8926:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504)])
            linalg.CPU.AddOp <name="model.layers.12.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=505, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504, solved=0), )] (%8926:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504)], %8927:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=505), constant:[-20]]) -> (%8928:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504)])
            linalg.CPU.EqualOp <name="model.layers.12.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=506, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=507, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8929:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=506), constant:[0]]) -> (%8930:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=507)])
            linalg.CPU.WhereOp <name="model.layers.12.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=507, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504, solved=0), )] (%8930:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=507)], %8925:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=502)], %8928:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504)]) -> (%8931:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504)])
            linalg.CPU.SoftmaxOp <name="model.layers.12.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=508, solved=0), )] (%8931:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=504)]) -> (%8932:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=508)])
            linalg.CPU.MatMulOp <name="model.layers.12.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=508, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509, solved=0), )] (%8932:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=508)], %8922:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=43)]) -> (%8933:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509)])
            linalg.CPU.TransposeOp <name="model.layers.12.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509, solved=0), )] (%8933:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509)]) -> (%8934:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509)])
            linalg.CPU.ViewOp <name="model.layers.12.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509, solved=0), )] (%8934:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509)]) -> (%8934:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509)])
            linalg.CPU.LinearOp <name="model.layers.12.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=511, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=510, solved=0))] (%8934:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=509)]) -> (%8935:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=511)])
            cf.ReturnOp (%8935:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=511)], %8915:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=499)], %8917:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=501)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.12.mlp <CPU> [using_qnn:true, symbol:model.layers.12.mlp] {
        (%8937:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=512)]) -> (%8943:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=520)]) {
            linalg.CPU.LinearOp <name="model.layers.12.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=512, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=515, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=514, solved=0))] (%8937:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=512)]) -> (%8938:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=515)])
            linalg.CPU.LinearOp <name="model.layers.12.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=512, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=516, solved=0))] (%8937:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=512)]) -> (%8939:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517)])
            linalg.CPU.SigmoidOp <name="model.layers.12.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=518, solved=0), )] (%8939:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517)]) -> (%8940:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=518)])
            linalg.CPU.MulOp <name="model.layers.12.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=518, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517, solved=0), )] (%8939:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517)], %8940:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=518)]) -> (%8941:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517)])
            linalg.CPU.MulOp <name="model.layers.12.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=515, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517, solved=0), )] (%8941:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517)], %8938:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=515)]) -> (%8942:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517)])
            linalg.CPU.LinearOp <name="model.layers.12.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=520, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=519, solved=0))] (%8942:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=517)]) -> (%8943:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=520)])
            cf.ReturnOp (%8943:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=520)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.13 <CPU> [using_qnn:true, symbol:model.layers.13] {
        (%8944:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8234:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)], %8235:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)]) -> (%8996:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)]) {
            linalg.CPU.RMSNormOp <name="model.layers.13.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=522, solved=0))] (%8944:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8945:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521)])
            graph.CallGraphOp @model.layers.13.self_attn (%8945:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8234:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)], %8235:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)]) -> (%8987:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=546)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)])
            linalg.CPU.AddOp <name="model.layers.13.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=546, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8944:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8987:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=546)]) -> (%8988:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.13.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=547, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=548, solved=0))] (%8988:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8989:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=547)])
            graph.CallGraphOp @model.layers.13.mlp (%8989:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=547)]) -> (%8995:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=555)])
            linalg.CPU.AddOp <name="model.layers.13.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=555, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8988:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8995:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=555)]) -> (%8996:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%8996:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.13.self_attn <CPU> [using_qnn:true, symbol:model.layers.13.self_attn] {
        (%8945:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8234:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)], %8235:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)]) -> (%8987:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=546)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)]) {
            linalg.CPU.LinearOp <name="model.layers.13.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=523, solved=0))] (%8945:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521)]) -> (%8946:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524)])
            linalg.CPU.LinearOp <name="model.layers.13.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=525, solved=0))] (%8945:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521)]) -> (%8947:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526)])
            linalg.CPU.LinearOp <name="model.layers.13.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=527, solved=0))] (%8945:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=521)]) -> (%8948:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528)])
            linalg.CPU.ViewOp <name="model.layers.13.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524, solved=0), )] (%8946:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524)]) -> (%8946:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524)])
            linalg.CPU.TransposeOp <name="model.layers.13.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524, solved=0), )] (%8946:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524)]) -> (%8949:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524)])
            linalg.CPU.ViewOp <name="model.layers.13.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526, solved=0), )] (%8947:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526)]) -> (%8947:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526)])
            linalg.CPU.TransposeOp <name="model.layers.13.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526, solved=0), )] (%8947:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526)]) -> (%8950:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526)])
            linalg.CPU.ViewOp <name="model.layers.13.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528, solved=0), )] (%8948:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528)]) -> (%8948:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528)])
            linalg.CPU.TransposeOp <name="model.layers.13.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528, solved=0), )] (%8948:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528)]) -> (%8951:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528)])
            linalg.CPU.RMSNormOp <name="model.layers.13.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=530, solved=0))] (%8949:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=524)]) -> (%8952:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)])
            linalg.CPU.RMSNormOp <name="model.layers.13.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=532, solved=0))] (%8950:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=526)]) -> (%8953:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)])
            linalg.CPU.ViewOp <name="model.layers.13.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.13.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.13.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), )] (%8952:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)]) -> (%8952:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)])
            linalg.CPU.SliceOp <name="model.layers.13.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), )] (%8952:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)]) -> (%8952:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)])
            linalg.CPU.NegOp <name="model.layers.13.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), )] (%8952:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)]) -> (%8954:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)])
            linalg.CPU.ConcatOp <name="model.layers.13.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), )] (%8954:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)], %8952:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)]) -> (%8955:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)])
            linalg.CPU.MulOp <name="model.layers.13.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), )] (%8955:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8956:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)])
            linalg.CPU.MulOp <name="model.layers.13.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), )] (%8952:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8957:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)])
            linalg.CPU.AddOp <name="model.layers.13.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), )] (%8957:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)], %8956:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)]) -> (%8958:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)])
            linalg.CPU.SliceOp <name="model.layers.13.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), )] (%8953:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)]) -> (%8953:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)])
            linalg.CPU.SliceOp <name="model.layers.13.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), )] (%8953:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)]) -> (%8953:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)])
            linalg.CPU.NegOp <name="model.layers.13.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), )] (%8953:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)]) -> (%8959:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)])
            linalg.CPU.ConcatOp <name="model.layers.13.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), )] (%8959:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)], %8953:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)]) -> (%8960:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)])
            linalg.CPU.MulOp <name="model.layers.13.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), )] (%8960:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8961:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)])
            linalg.CPU.MulOp <name="model.layers.13.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), )] (%8953:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8962:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)])
            linalg.CPU.AddOp <name="model.layers.13.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), )] (%8962:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)], %8961:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)]) -> (%8963:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)])
            linalg.CPU.CastTypeOp <name="model.layers.13.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=533, solved=0), )] (%8963:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=531)]) -> (%8964:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=533)])
            linalg.CPU.CastTypeOp <name="model.layers.13.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=533, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534, solved=0), )] (%8964:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=533)]) -> (%8965:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)])
            linalg.CPU.TransposeOp <name="model.layers.13.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534, solved=0), )] (%8965:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)]) -> (%8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)])
            linalg.CPU.CastTypeOp <name="model.layers.13.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=535, solved=0), )] (%8951:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=528)]) -> (%8968:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=535)])
            linalg.CPU.CastTypeOp <name="model.layers.13.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=535, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536, solved=0), )] (%8968:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=535)]) -> (%8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)])
            linalg.CPU.ConcatOp <name="model.layers.13.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16, solved=0), )] (%8234:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)]) -> (%8971:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)])
            linalg.CPU.ConcatOp <name="model.layers.13.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44, solved=0), )] (%8235:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)]) -> (%8972:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)])
            linalg.CPU.RepeatOp <name="model.layers.13.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16, solved=0), )] (%8971:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)]) -> (%8973:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)])
            linalg.CPU.RepeatOp <name="model.layers.13.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44, solved=0), )] (%8972:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)]) -> (%8974:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)])
            linalg.CPU.MatMulOp <name="model.layers.13.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537, solved=0), )] (%8958:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=529)], %8973:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=16)]) -> (%8975:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537)])
            linalg.CPU.MulOp <name="model.layers.13.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=538, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537, solved=0), )] (%8975:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537)], %8976:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=538), constant:[0.088388346]]) -> (%8977:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537)])
            linalg.CPU.ReduceMinOp <name="model.layers.13.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539, solved=0), )] (%8977:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537)]) -> (%8978:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539)])
            linalg.CPU.AddOp <name="model.layers.13.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=540, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539, solved=0), )] (%8978:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539)], %8979:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=540), constant:[-20]]) -> (%8980:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539)])
            linalg.CPU.EqualOp <name="model.layers.13.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=541, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=542, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8981:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=541), constant:[0]]) -> (%8982:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=542)])
            linalg.CPU.WhereOp <name="model.layers.13.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=542, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539, solved=0), )] (%8982:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=542)], %8977:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=537)], %8980:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539)]) -> (%8983:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539)])
            linalg.CPU.SoftmaxOp <name="model.layers.13.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=543, solved=0), )] (%8983:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=539)]) -> (%8984:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=543)])
            linalg.CPU.MatMulOp <name="model.layers.13.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=543, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544, solved=0), )] (%8984:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=543)], %8974:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=44)]) -> (%8985:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544)])
            linalg.CPU.TransposeOp <name="model.layers.13.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544, solved=0), )] (%8985:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544)]) -> (%8986:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544)])
            linalg.CPU.ViewOp <name="model.layers.13.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544, solved=0), )] (%8986:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544)]) -> (%8986:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544)])
            linalg.CPU.LinearOp <name="model.layers.13.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=546, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=545, solved=0))] (%8986:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=544)]) -> (%8987:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=546)])
            cf.ReturnOp (%8987:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=546)], %8967:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=534)], %8969:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=536)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.13.mlp <CPU> [using_qnn:true, symbol:model.layers.13.mlp] {
        (%8989:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=547)]) -> (%8995:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=555)]) {
            linalg.CPU.LinearOp <name="model.layers.13.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=547, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=550, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=549, solved=0))] (%8989:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=547)]) -> (%8990:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=550)])
            linalg.CPU.LinearOp <name="model.layers.13.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=547, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=551, solved=0))] (%8989:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=547)]) -> (%8991:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552)])
            linalg.CPU.SigmoidOp <name="model.layers.13.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=553, solved=0), )] (%8991:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552)]) -> (%8992:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=553)])
            linalg.CPU.MulOp <name="model.layers.13.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=553, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552, solved=0), )] (%8991:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552)], %8992:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=553)]) -> (%8993:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552)])
            linalg.CPU.MulOp <name="model.layers.13.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=550, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552, solved=0), )] (%8993:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552)], %8990:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=550)]) -> (%8994:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552)])
            linalg.CPU.LinearOp <name="model.layers.13.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=555, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=554, solved=0))] (%8994:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=552)]) -> (%8995:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=555)])
            cf.ReturnOp (%8995:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=555)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.14 <CPU> [using_qnn:true, symbol:model.layers.14] {
        (%8996:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8236:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)], %8237:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)]) -> (%9048:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)]) {
            linalg.CPU.RMSNormOp <name="model.layers.14.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=557, solved=0))] (%8996:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%8997:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556)])
            graph.CallGraphOp @model.layers.14.self_attn (%8997:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8236:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)], %8237:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)]) -> (%9039:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=581)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)])
            linalg.CPU.AddOp <name="model.layers.14.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=581, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%8996:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9039:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=581)]) -> (%9040:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.14.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=582, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=583, solved=0))] (%9040:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9041:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=582)])
            graph.CallGraphOp @model.layers.14.mlp (%9041:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=582)]) -> (%9047:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=590)])
            linalg.CPU.AddOp <name="model.layers.14.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=590, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9040:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9047:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=590)]) -> (%9048:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9048:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.14.self_attn <CPU> [using_qnn:true, symbol:model.layers.14.self_attn] {
        (%8997:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8236:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)], %8237:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)]) -> (%9039:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=581)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)]) {
            linalg.CPU.LinearOp <name="model.layers.14.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=558, solved=0))] (%8997:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556)]) -> (%8998:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559)])
            linalg.CPU.LinearOp <name="model.layers.14.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=560, solved=0))] (%8997:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556)]) -> (%8999:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561)])
            linalg.CPU.LinearOp <name="model.layers.14.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=562, solved=0))] (%8997:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=556)]) -> (%9000:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563)])
            linalg.CPU.ViewOp <name="model.layers.14.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559, solved=0), )] (%8998:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559)]) -> (%8998:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559)])
            linalg.CPU.TransposeOp <name="model.layers.14.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559, solved=0), )] (%8998:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559)]) -> (%9001:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559)])
            linalg.CPU.ViewOp <name="model.layers.14.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561, solved=0), )] (%8999:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561)]) -> (%8999:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561)])
            linalg.CPU.TransposeOp <name="model.layers.14.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561, solved=0), )] (%8999:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561)]) -> (%9002:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561)])
            linalg.CPU.ViewOp <name="model.layers.14.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563, solved=0), )] (%9000:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563)]) -> (%9000:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563)])
            linalg.CPU.TransposeOp <name="model.layers.14.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563, solved=0), )] (%9000:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563)]) -> (%9003:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563)])
            linalg.CPU.RMSNormOp <name="model.layers.14.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=565, solved=0))] (%9001:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=559)]) -> (%9004:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)])
            linalg.CPU.RMSNormOp <name="model.layers.14.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=567, solved=0))] (%9002:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=561)]) -> (%9005:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)])
            linalg.CPU.ViewOp <name="model.layers.14.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.14.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.14.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), )] (%9004:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)]) -> (%9004:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)])
            linalg.CPU.SliceOp <name="model.layers.14.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), )] (%9004:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)]) -> (%9004:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)])
            linalg.CPU.NegOp <name="model.layers.14.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), )] (%9004:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)]) -> (%9006:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)])
            linalg.CPU.ConcatOp <name="model.layers.14.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), )] (%9006:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)], %9004:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)]) -> (%9007:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)])
            linalg.CPU.MulOp <name="model.layers.14.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), )] (%9007:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9008:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)])
            linalg.CPU.MulOp <name="model.layers.14.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), )] (%9004:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9009:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)])
            linalg.CPU.AddOp <name="model.layers.14.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), )] (%9009:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)], %9008:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)]) -> (%9010:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)])
            linalg.CPU.SliceOp <name="model.layers.14.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), )] (%9005:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)]) -> (%9005:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)])
            linalg.CPU.SliceOp <name="model.layers.14.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), )] (%9005:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)]) -> (%9005:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)])
            linalg.CPU.NegOp <name="model.layers.14.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), )] (%9005:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)]) -> (%9011:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)])
            linalg.CPU.ConcatOp <name="model.layers.14.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), )] (%9011:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)], %9005:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)]) -> (%9012:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)])
            linalg.CPU.MulOp <name="model.layers.14.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), )] (%9012:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9013:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)])
            linalg.CPU.MulOp <name="model.layers.14.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), )] (%9005:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9014:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)])
            linalg.CPU.AddOp <name="model.layers.14.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), )] (%9014:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)], %9013:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)]) -> (%9015:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)])
            linalg.CPU.CastTypeOp <name="model.layers.14.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=568, solved=0), )] (%9015:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=566)]) -> (%9016:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=568)])
            linalg.CPU.CastTypeOp <name="model.layers.14.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=568, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569, solved=0), )] (%9016:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=568)]) -> (%9017:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)])
            linalg.CPU.TransposeOp <name="model.layers.14.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569, solved=0), )] (%9017:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)]) -> (%9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)])
            linalg.CPU.CastTypeOp <name="model.layers.14.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=570, solved=0), )] (%9003:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=563)]) -> (%9020:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=570)])
            linalg.CPU.CastTypeOp <name="model.layers.14.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=570, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571, solved=0), )] (%9020:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=570)]) -> (%9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)])
            linalg.CPU.ConcatOp <name="model.layers.14.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17, solved=0), )] (%8236:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)]) -> (%9023:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)])
            linalg.CPU.ConcatOp <name="model.layers.14.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45, solved=0), )] (%8237:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)]) -> (%9024:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)])
            linalg.CPU.RepeatOp <name="model.layers.14.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17, solved=0), )] (%9023:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)]) -> (%9025:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)])
            linalg.CPU.RepeatOp <name="model.layers.14.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45, solved=0), )] (%9024:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)]) -> (%9026:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)])
            linalg.CPU.MatMulOp <name="model.layers.14.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572, solved=0), )] (%9010:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=564)], %9025:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=17)]) -> (%9027:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572)])
            linalg.CPU.MulOp <name="model.layers.14.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=573, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572, solved=0), )] (%9027:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572)], %9028:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=573), constant:[0.088388346]]) -> (%9029:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572)])
            linalg.CPU.ReduceMinOp <name="model.layers.14.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574, solved=0), )] (%9029:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572)]) -> (%9030:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574)])
            linalg.CPU.AddOp <name="model.layers.14.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=575, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574, solved=0), )] (%9030:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574)], %9031:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=575), constant:[-20]]) -> (%9032:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574)])
            linalg.CPU.EqualOp <name="model.layers.14.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=576, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=577, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9033:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=576), constant:[0]]) -> (%9034:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=577)])
            linalg.CPU.WhereOp <name="model.layers.14.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=577, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574, solved=0), )] (%9034:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=577)], %9029:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=572)], %9032:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574)]) -> (%9035:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574)])
            linalg.CPU.SoftmaxOp <name="model.layers.14.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=578, solved=0), )] (%9035:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=574)]) -> (%9036:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=578)])
            linalg.CPU.MatMulOp <name="model.layers.14.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=578, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579, solved=0), )] (%9036:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=578)], %9026:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=45)]) -> (%9037:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579)])
            linalg.CPU.TransposeOp <name="model.layers.14.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579, solved=0), )] (%9037:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579)]) -> (%9038:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579)])
            linalg.CPU.ViewOp <name="model.layers.14.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579, solved=0), )] (%9038:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579)]) -> (%9038:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579)])
            linalg.CPU.LinearOp <name="model.layers.14.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=581, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=580, solved=0))] (%9038:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=579)]) -> (%9039:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=581)])
            cf.ReturnOp (%9039:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=581)], %9019:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=569)], %9021:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=571)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.14.mlp <CPU> [using_qnn:true, symbol:model.layers.14.mlp] {
        (%9041:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=582)]) -> (%9047:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=590)]) {
            linalg.CPU.LinearOp <name="model.layers.14.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=582, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=585, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=584, solved=0))] (%9041:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=582)]) -> (%9042:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=585)])
            linalg.CPU.LinearOp <name="model.layers.14.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=582, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=586, solved=0))] (%9041:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=582)]) -> (%9043:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587)])
            linalg.CPU.SigmoidOp <name="model.layers.14.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=588, solved=0), )] (%9043:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587)]) -> (%9044:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=588)])
            linalg.CPU.MulOp <name="model.layers.14.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=588, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587, solved=0), )] (%9043:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587)], %9044:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=588)]) -> (%9045:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587)])
            linalg.CPU.MulOp <name="model.layers.14.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=585, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587, solved=0), )] (%9045:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587)], %9042:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=585)]) -> (%9046:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587)])
            linalg.CPU.LinearOp <name="model.layers.14.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=590, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=589, solved=0))] (%9046:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=587)]) -> (%9047:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=590)])
            cf.ReturnOp (%9047:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=590)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.15 <CPU> [using_qnn:true, symbol:model.layers.15] {
        (%9048:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8238:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)], %8239:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)]) -> (%9100:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)]) {
            linalg.CPU.RMSNormOp <name="model.layers.15.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=592, solved=0))] (%9048:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9049:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591)])
            graph.CallGraphOp @model.layers.15.self_attn (%9049:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8238:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)], %8239:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)]) -> (%9091:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=616)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)])
            linalg.CPU.AddOp <name="model.layers.15.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=616, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9048:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9091:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=616)]) -> (%9092:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.15.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=617, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=618, solved=0))] (%9092:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9093:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=617)])
            graph.CallGraphOp @model.layers.15.mlp (%9093:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=617)]) -> (%9099:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=625)])
            linalg.CPU.AddOp <name="model.layers.15.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=625, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9092:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9099:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=625)]) -> (%9100:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9100:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.15.self_attn <CPU> [using_qnn:true, symbol:model.layers.15.self_attn] {
        (%9049:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8238:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)], %8239:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)]) -> (%9091:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=616)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)]) {
            linalg.CPU.LinearOp <name="model.layers.15.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=593, solved=0))] (%9049:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591)]) -> (%9050:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594)])
            linalg.CPU.LinearOp <name="model.layers.15.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=595, solved=0))] (%9049:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591)]) -> (%9051:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596)])
            linalg.CPU.LinearOp <name="model.layers.15.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=597, solved=0))] (%9049:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=591)]) -> (%9052:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598)])
            linalg.CPU.ViewOp <name="model.layers.15.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594, solved=0), )] (%9050:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594)]) -> (%9050:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594)])
            linalg.CPU.TransposeOp <name="model.layers.15.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594, solved=0), )] (%9050:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594)]) -> (%9053:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594)])
            linalg.CPU.ViewOp <name="model.layers.15.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596, solved=0), )] (%9051:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596)]) -> (%9051:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596)])
            linalg.CPU.TransposeOp <name="model.layers.15.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596, solved=0), )] (%9051:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596)]) -> (%9054:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596)])
            linalg.CPU.ViewOp <name="model.layers.15.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598, solved=0), )] (%9052:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598)]) -> (%9052:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598)])
            linalg.CPU.TransposeOp <name="model.layers.15.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598, solved=0), )] (%9052:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598)]) -> (%9055:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598)])
            linalg.CPU.RMSNormOp <name="model.layers.15.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=600, solved=0))] (%9053:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=594)]) -> (%9056:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)])
            linalg.CPU.RMSNormOp <name="model.layers.15.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=602, solved=0))] (%9054:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=596)]) -> (%9057:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)])
            linalg.CPU.ViewOp <name="model.layers.15.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.15.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.15.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), )] (%9056:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)]) -> (%9056:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)])
            linalg.CPU.SliceOp <name="model.layers.15.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), )] (%9056:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)]) -> (%9056:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)])
            linalg.CPU.NegOp <name="model.layers.15.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), )] (%9056:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)]) -> (%9058:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)])
            linalg.CPU.ConcatOp <name="model.layers.15.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), )] (%9058:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)], %9056:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)]) -> (%9059:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)])
            linalg.CPU.MulOp <name="model.layers.15.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), )] (%9059:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9060:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)])
            linalg.CPU.MulOp <name="model.layers.15.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), )] (%9056:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9061:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)])
            linalg.CPU.AddOp <name="model.layers.15.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), )] (%9061:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)], %9060:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)]) -> (%9062:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)])
            linalg.CPU.SliceOp <name="model.layers.15.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), )] (%9057:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)]) -> (%9057:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)])
            linalg.CPU.SliceOp <name="model.layers.15.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), )] (%9057:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)]) -> (%9057:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)])
            linalg.CPU.NegOp <name="model.layers.15.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), )] (%9057:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)]) -> (%9063:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)])
            linalg.CPU.ConcatOp <name="model.layers.15.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), )] (%9063:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)], %9057:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)]) -> (%9064:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)])
            linalg.CPU.MulOp <name="model.layers.15.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), )] (%9064:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9065:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)])
            linalg.CPU.MulOp <name="model.layers.15.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), )] (%9057:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9066:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)])
            linalg.CPU.AddOp <name="model.layers.15.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), )] (%9066:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)], %9065:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)]) -> (%9067:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)])
            linalg.CPU.CastTypeOp <name="model.layers.15.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=603, solved=0), )] (%9067:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=601)]) -> (%9068:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=603)])
            linalg.CPU.CastTypeOp <name="model.layers.15.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=603, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604, solved=0), )] (%9068:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=603)]) -> (%9069:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)])
            linalg.CPU.TransposeOp <name="model.layers.15.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604, solved=0), )] (%9069:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)]) -> (%9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)])
            linalg.CPU.CastTypeOp <name="model.layers.15.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=605, solved=0), )] (%9055:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=598)]) -> (%9072:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=605)])
            linalg.CPU.CastTypeOp <name="model.layers.15.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=605, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606, solved=0), )] (%9072:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=605)]) -> (%9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)])
            linalg.CPU.ConcatOp <name="model.layers.15.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18, solved=0), )] (%8238:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)]) -> (%9075:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)])
            linalg.CPU.ConcatOp <name="model.layers.15.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46, solved=0), )] (%8239:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)]) -> (%9076:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)])
            linalg.CPU.RepeatOp <name="model.layers.15.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18, solved=0), )] (%9075:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)]) -> (%9077:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)])
            linalg.CPU.RepeatOp <name="model.layers.15.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46, solved=0), )] (%9076:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)]) -> (%9078:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)])
            linalg.CPU.MatMulOp <name="model.layers.15.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607, solved=0), )] (%9062:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=599)], %9077:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=18)]) -> (%9079:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607)])
            linalg.CPU.MulOp <name="model.layers.15.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=608, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607, solved=0), )] (%9079:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607)], %9080:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=608), constant:[0.088388346]]) -> (%9081:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607)])
            linalg.CPU.ReduceMinOp <name="model.layers.15.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609, solved=0), )] (%9081:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607)]) -> (%9082:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609)])
            linalg.CPU.AddOp <name="model.layers.15.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=610, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609, solved=0), )] (%9082:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609)], %9083:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=610), constant:[-20]]) -> (%9084:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609)])
            linalg.CPU.EqualOp <name="model.layers.15.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=611, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=612, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9085:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=611), constant:[0]]) -> (%9086:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=612)])
            linalg.CPU.WhereOp <name="model.layers.15.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=612, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609, solved=0), )] (%9086:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=612)], %9081:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=607)], %9084:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609)]) -> (%9087:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609)])
            linalg.CPU.SoftmaxOp <name="model.layers.15.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=613, solved=0), )] (%9087:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=609)]) -> (%9088:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=613)])
            linalg.CPU.MatMulOp <name="model.layers.15.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=613, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614, solved=0), )] (%9088:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=613)], %9078:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=46)]) -> (%9089:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614)])
            linalg.CPU.TransposeOp <name="model.layers.15.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614, solved=0), )] (%9089:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614)]) -> (%9090:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614)])
            linalg.CPU.ViewOp <name="model.layers.15.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614, solved=0), )] (%9090:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614)]) -> (%9090:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614)])
            linalg.CPU.LinearOp <name="model.layers.15.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=616, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=615, solved=0))] (%9090:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=614)]) -> (%9091:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=616)])
            cf.ReturnOp (%9091:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=616)], %9071:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=604)], %9073:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=606)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.15.mlp <CPU> [using_qnn:true, symbol:model.layers.15.mlp] {
        (%9093:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=617)]) -> (%9099:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=625)]) {
            linalg.CPU.LinearOp <name="model.layers.15.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=617, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=620, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=619, solved=0))] (%9093:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=617)]) -> (%9094:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=620)])
            linalg.CPU.LinearOp <name="model.layers.15.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=617, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=621, solved=0))] (%9093:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=617)]) -> (%9095:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622)])
            linalg.CPU.SigmoidOp <name="model.layers.15.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=623, solved=0), )] (%9095:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622)]) -> (%9096:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=623)])
            linalg.CPU.MulOp <name="model.layers.15.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=623, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622, solved=0), )] (%9095:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622)], %9096:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=623)]) -> (%9097:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622)])
            linalg.CPU.MulOp <name="model.layers.15.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=620, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622, solved=0), )] (%9097:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622)], %9094:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=620)]) -> (%9098:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622)])
            linalg.CPU.LinearOp <name="model.layers.15.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=625, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=624, solved=0))] (%9098:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=622)]) -> (%9099:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=625)])
            cf.ReturnOp (%9099:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=625)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.16 <CPU> [using_qnn:true, symbol:model.layers.16] {
        (%9100:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8240:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)], %8241:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)]) -> (%9152:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)]) {
            linalg.CPU.RMSNormOp <name="model.layers.16.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=627, solved=0))] (%9100:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9101:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626)])
            graph.CallGraphOp @model.layers.16.self_attn (%9101:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8240:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)], %8241:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)]) -> (%9143:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=651)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)])
            linalg.CPU.AddOp <name="model.layers.16.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=651, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9100:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9143:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=651)]) -> (%9144:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.16.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=652, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=653, solved=0))] (%9144:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9145:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=652)])
            graph.CallGraphOp @model.layers.16.mlp (%9145:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=652)]) -> (%9151:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=660)])
            linalg.CPU.AddOp <name="model.layers.16.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=660, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9144:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9151:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=660)]) -> (%9152:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9152:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.16.self_attn <CPU> [using_qnn:true, symbol:model.layers.16.self_attn] {
        (%9101:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8240:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)], %8241:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)]) -> (%9143:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=651)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)]) {
            linalg.CPU.LinearOp <name="model.layers.16.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=628, solved=0))] (%9101:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626)]) -> (%9102:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629)])
            linalg.CPU.LinearOp <name="model.layers.16.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=630, solved=0))] (%9101:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626)]) -> (%9103:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631)])
            linalg.CPU.LinearOp <name="model.layers.16.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=632, solved=0))] (%9101:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=626)]) -> (%9104:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633)])
            linalg.CPU.ViewOp <name="model.layers.16.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629, solved=0), )] (%9102:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629)]) -> (%9102:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629)])
            linalg.CPU.TransposeOp <name="model.layers.16.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629, solved=0), )] (%9102:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629)]) -> (%9105:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629)])
            linalg.CPU.ViewOp <name="model.layers.16.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631, solved=0), )] (%9103:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631)]) -> (%9103:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631)])
            linalg.CPU.TransposeOp <name="model.layers.16.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631, solved=0), )] (%9103:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631)]) -> (%9106:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631)])
            linalg.CPU.ViewOp <name="model.layers.16.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633, solved=0), )] (%9104:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633)]) -> (%9104:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633)])
            linalg.CPU.TransposeOp <name="model.layers.16.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633, solved=0), )] (%9104:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633)]) -> (%9107:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633)])
            linalg.CPU.RMSNormOp <name="model.layers.16.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=635, solved=0))] (%9105:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=629)]) -> (%9108:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)])
            linalg.CPU.RMSNormOp <name="model.layers.16.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=637, solved=0))] (%9106:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=631)]) -> (%9109:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)])
            linalg.CPU.ViewOp <name="model.layers.16.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.16.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.16.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), )] (%9108:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)]) -> (%9108:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)])
            linalg.CPU.SliceOp <name="model.layers.16.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), )] (%9108:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)]) -> (%9108:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)])
            linalg.CPU.NegOp <name="model.layers.16.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), )] (%9108:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)]) -> (%9110:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)])
            linalg.CPU.ConcatOp <name="model.layers.16.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), )] (%9110:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)], %9108:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)]) -> (%9111:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)])
            linalg.CPU.MulOp <name="model.layers.16.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), )] (%9111:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9112:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)])
            linalg.CPU.MulOp <name="model.layers.16.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), )] (%9108:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9113:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)])
            linalg.CPU.AddOp <name="model.layers.16.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), )] (%9113:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)], %9112:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)]) -> (%9114:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)])
            linalg.CPU.SliceOp <name="model.layers.16.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), )] (%9109:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)]) -> (%9109:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)])
            linalg.CPU.SliceOp <name="model.layers.16.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), )] (%9109:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)]) -> (%9109:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)])
            linalg.CPU.NegOp <name="model.layers.16.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), )] (%9109:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)]) -> (%9115:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)])
            linalg.CPU.ConcatOp <name="model.layers.16.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), )] (%9115:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)], %9109:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)]) -> (%9116:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)])
            linalg.CPU.MulOp <name="model.layers.16.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), )] (%9116:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9117:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)])
            linalg.CPU.MulOp <name="model.layers.16.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), )] (%9109:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9118:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)])
            linalg.CPU.AddOp <name="model.layers.16.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), )] (%9118:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)], %9117:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)]) -> (%9119:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)])
            linalg.CPU.CastTypeOp <name="model.layers.16.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=638, solved=0), )] (%9119:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=636)]) -> (%9120:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=638)])
            linalg.CPU.CastTypeOp <name="model.layers.16.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=638, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639, solved=0), )] (%9120:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=638)]) -> (%9121:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)])
            linalg.CPU.TransposeOp <name="model.layers.16.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639, solved=0), )] (%9121:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)]) -> (%9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)])
            linalg.CPU.CastTypeOp <name="model.layers.16.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=640, solved=0), )] (%9107:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=633)]) -> (%9124:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=640)])
            linalg.CPU.CastTypeOp <name="model.layers.16.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=640, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641, solved=0), )] (%9124:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=640)]) -> (%9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)])
            linalg.CPU.ConcatOp <name="model.layers.16.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19, solved=0), )] (%8240:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)]) -> (%9127:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)])
            linalg.CPU.ConcatOp <name="model.layers.16.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47, solved=0), )] (%8241:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)]) -> (%9128:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)])
            linalg.CPU.RepeatOp <name="model.layers.16.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19, solved=0), )] (%9127:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)]) -> (%9129:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)])
            linalg.CPU.RepeatOp <name="model.layers.16.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47, solved=0), )] (%9128:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)]) -> (%9130:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)])
            linalg.CPU.MatMulOp <name="model.layers.16.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642, solved=0), )] (%9114:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=634)], %9129:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=19)]) -> (%9131:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642)])
            linalg.CPU.MulOp <name="model.layers.16.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=643, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642, solved=0), )] (%9131:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642)], %9132:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=643), constant:[0.088388346]]) -> (%9133:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642)])
            linalg.CPU.ReduceMinOp <name="model.layers.16.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644, solved=0), )] (%9133:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642)]) -> (%9134:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644)])
            linalg.CPU.AddOp <name="model.layers.16.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=645, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644, solved=0), )] (%9134:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644)], %9135:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=645), constant:[-20]]) -> (%9136:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644)])
            linalg.CPU.EqualOp <name="model.layers.16.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=646, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=647, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9137:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=646), constant:[0]]) -> (%9138:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=647)])
            linalg.CPU.WhereOp <name="model.layers.16.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=647, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644, solved=0), )] (%9138:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=647)], %9133:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=642)], %9136:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644)]) -> (%9139:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644)])
            linalg.CPU.SoftmaxOp <name="model.layers.16.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=648, solved=0), )] (%9139:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=644)]) -> (%9140:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=648)])
            linalg.CPU.MatMulOp <name="model.layers.16.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=648, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649, solved=0), )] (%9140:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=648)], %9130:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=47)]) -> (%9141:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649)])
            linalg.CPU.TransposeOp <name="model.layers.16.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649, solved=0), )] (%9141:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649)]) -> (%9142:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649)])
            linalg.CPU.ViewOp <name="model.layers.16.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649, solved=0), )] (%9142:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649)]) -> (%9142:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649)])
            linalg.CPU.LinearOp <name="model.layers.16.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=651, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=650, solved=0))] (%9142:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=649)]) -> (%9143:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=651)])
            cf.ReturnOp (%9143:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=651)], %9123:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=639)], %9125:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=641)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.16.mlp <CPU> [using_qnn:true, symbol:model.layers.16.mlp] {
        (%9145:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=652)]) -> (%9151:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=660)]) {
            linalg.CPU.LinearOp <name="model.layers.16.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=652, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=655, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=654, solved=0))] (%9145:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=652)]) -> (%9146:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=655)])
            linalg.CPU.LinearOp <name="model.layers.16.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=652, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=656, solved=0))] (%9145:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=652)]) -> (%9147:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657)])
            linalg.CPU.SigmoidOp <name="model.layers.16.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=658, solved=0), )] (%9147:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657)]) -> (%9148:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=658)])
            linalg.CPU.MulOp <name="model.layers.16.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=658, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657, solved=0), )] (%9147:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657)], %9148:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=658)]) -> (%9149:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657)])
            linalg.CPU.MulOp <name="model.layers.16.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=655, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657, solved=0), )] (%9149:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657)], %9146:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=655)]) -> (%9150:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657)])
            linalg.CPU.LinearOp <name="model.layers.16.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=660, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=659, solved=0))] (%9150:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=657)]) -> (%9151:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=660)])
            cf.ReturnOp (%9151:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=660)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.17 <CPU> [using_qnn:true, symbol:model.layers.17] {
        (%9152:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8242:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)], %8243:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)]) -> (%9204:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)]) {
            linalg.CPU.RMSNormOp <name="model.layers.17.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=662, solved=0))] (%9152:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9153:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661)])
            graph.CallGraphOp @model.layers.17.self_attn (%9153:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8242:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)], %8243:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)]) -> (%9195:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=686)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)])
            linalg.CPU.AddOp <name="model.layers.17.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=686, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9152:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9195:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=686)]) -> (%9196:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.17.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=687, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=688, solved=0))] (%9196:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9197:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=687)])
            graph.CallGraphOp @model.layers.17.mlp (%9197:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=687)]) -> (%9203:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=695)])
            linalg.CPU.AddOp <name="model.layers.17.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=695, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9196:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9203:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=695)]) -> (%9204:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9204:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.17.self_attn <CPU> [using_qnn:true, symbol:model.layers.17.self_attn] {
        (%9153:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8242:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)], %8243:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)]) -> (%9195:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=686)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)]) {
            linalg.CPU.LinearOp <name="model.layers.17.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=663, solved=0))] (%9153:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661)]) -> (%9154:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664)])
            linalg.CPU.LinearOp <name="model.layers.17.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=665, solved=0))] (%9153:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661)]) -> (%9155:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666)])
            linalg.CPU.LinearOp <name="model.layers.17.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=667, solved=0))] (%9153:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=661)]) -> (%9156:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668)])
            linalg.CPU.ViewOp <name="model.layers.17.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664, solved=0), )] (%9154:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664)]) -> (%9154:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664)])
            linalg.CPU.TransposeOp <name="model.layers.17.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664, solved=0), )] (%9154:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664)]) -> (%9157:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664)])
            linalg.CPU.ViewOp <name="model.layers.17.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666, solved=0), )] (%9155:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666)]) -> (%9155:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666)])
            linalg.CPU.TransposeOp <name="model.layers.17.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666, solved=0), )] (%9155:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666)]) -> (%9158:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666)])
            linalg.CPU.ViewOp <name="model.layers.17.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668, solved=0), )] (%9156:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668)]) -> (%9156:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668)])
            linalg.CPU.TransposeOp <name="model.layers.17.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668, solved=0), )] (%9156:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668)]) -> (%9159:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668)])
            linalg.CPU.RMSNormOp <name="model.layers.17.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=670, solved=0))] (%9157:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=664)]) -> (%9160:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)])
            linalg.CPU.RMSNormOp <name="model.layers.17.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=672, solved=0))] (%9158:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=666)]) -> (%9161:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)])
            linalg.CPU.ViewOp <name="model.layers.17.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.17.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.17.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), )] (%9160:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)]) -> (%9160:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)])
            linalg.CPU.SliceOp <name="model.layers.17.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), )] (%9160:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)]) -> (%9160:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)])
            linalg.CPU.NegOp <name="model.layers.17.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), )] (%9160:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)]) -> (%9162:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)])
            linalg.CPU.ConcatOp <name="model.layers.17.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), )] (%9162:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)], %9160:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)]) -> (%9163:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)])
            linalg.CPU.MulOp <name="model.layers.17.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), )] (%9163:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9164:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)])
            linalg.CPU.MulOp <name="model.layers.17.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), )] (%9160:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9165:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)])
            linalg.CPU.AddOp <name="model.layers.17.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), )] (%9165:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)], %9164:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)]) -> (%9166:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)])
            linalg.CPU.SliceOp <name="model.layers.17.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), )] (%9161:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)]) -> (%9161:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)])
            linalg.CPU.SliceOp <name="model.layers.17.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), )] (%9161:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)]) -> (%9161:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)])
            linalg.CPU.NegOp <name="model.layers.17.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), )] (%9161:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)]) -> (%9167:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)])
            linalg.CPU.ConcatOp <name="model.layers.17.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), )] (%9167:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)], %9161:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)]) -> (%9168:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)])
            linalg.CPU.MulOp <name="model.layers.17.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), )] (%9168:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9169:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)])
            linalg.CPU.MulOp <name="model.layers.17.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), )] (%9161:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9170:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)])
            linalg.CPU.AddOp <name="model.layers.17.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), )] (%9170:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)], %9169:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)]) -> (%9171:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)])
            linalg.CPU.CastTypeOp <name="model.layers.17.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=673, solved=0), )] (%9171:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=671)]) -> (%9172:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=673)])
            linalg.CPU.CastTypeOp <name="model.layers.17.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=673, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674, solved=0), )] (%9172:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=673)]) -> (%9173:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)])
            linalg.CPU.TransposeOp <name="model.layers.17.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674, solved=0), )] (%9173:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)]) -> (%9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)])
            linalg.CPU.CastTypeOp <name="model.layers.17.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=675, solved=0), )] (%9159:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=668)]) -> (%9176:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=675)])
            linalg.CPU.CastTypeOp <name="model.layers.17.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=675, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676, solved=0), )] (%9176:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=675)]) -> (%9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)])
            linalg.CPU.ConcatOp <name="model.layers.17.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20, solved=0), )] (%8242:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)]) -> (%9179:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)])
            linalg.CPU.ConcatOp <name="model.layers.17.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48, solved=0), )] (%8243:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)]) -> (%9180:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)])
            linalg.CPU.RepeatOp <name="model.layers.17.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20, solved=0), )] (%9179:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)]) -> (%9181:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)])
            linalg.CPU.RepeatOp <name="model.layers.17.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48, solved=0), )] (%9180:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)]) -> (%9182:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)])
            linalg.CPU.MatMulOp <name="model.layers.17.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677, solved=0), )] (%9166:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=669)], %9181:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=20)]) -> (%9183:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677)])
            linalg.CPU.MulOp <name="model.layers.17.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=678, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677, solved=0), )] (%9183:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677)], %9184:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=678), constant:[0.088388346]]) -> (%9185:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677)])
            linalg.CPU.ReduceMinOp <name="model.layers.17.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679, solved=0), )] (%9185:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677)]) -> (%9186:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679)])
            linalg.CPU.AddOp <name="model.layers.17.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=680, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679, solved=0), )] (%9186:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679)], %9187:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=680), constant:[-20]]) -> (%9188:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679)])
            linalg.CPU.EqualOp <name="model.layers.17.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=681, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=682, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9189:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=681), constant:[0]]) -> (%9190:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=682)])
            linalg.CPU.WhereOp <name="model.layers.17.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=682, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679, solved=0), )] (%9190:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=682)], %9185:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=677)], %9188:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679)]) -> (%9191:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679)])
            linalg.CPU.SoftmaxOp <name="model.layers.17.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=683, solved=0), )] (%9191:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=679)]) -> (%9192:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=683)])
            linalg.CPU.MatMulOp <name="model.layers.17.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=683, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684, solved=0), )] (%9192:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=683)], %9182:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=48)]) -> (%9193:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684)])
            linalg.CPU.TransposeOp <name="model.layers.17.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684, solved=0), )] (%9193:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684)]) -> (%9194:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684)])
            linalg.CPU.ViewOp <name="model.layers.17.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684, solved=0), )] (%9194:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684)]) -> (%9194:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684)])
            linalg.CPU.LinearOp <name="model.layers.17.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=686, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=685, solved=0))] (%9194:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=684)]) -> (%9195:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=686)])
            cf.ReturnOp (%9195:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=686)], %9175:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=674)], %9177:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=676)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.17.mlp <CPU> [using_qnn:true, symbol:model.layers.17.mlp] {
        (%9197:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=687)]) -> (%9203:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=695)]) {
            linalg.CPU.LinearOp <name="model.layers.17.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=687, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=690, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=689, solved=0))] (%9197:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=687)]) -> (%9198:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=690)])
            linalg.CPU.LinearOp <name="model.layers.17.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=687, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=691, solved=0))] (%9197:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=687)]) -> (%9199:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692)])
            linalg.CPU.SigmoidOp <name="model.layers.17.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=693, solved=0), )] (%9199:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692)]) -> (%9200:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=693)])
            linalg.CPU.MulOp <name="model.layers.17.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=693, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692, solved=0), )] (%9199:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692)], %9200:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=693)]) -> (%9201:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692)])
            linalg.CPU.MulOp <name="model.layers.17.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=690, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692, solved=0), )] (%9201:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692)], %9198:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=690)]) -> (%9202:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692)])
            linalg.CPU.LinearOp <name="model.layers.17.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=695, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=694, solved=0))] (%9202:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=692)]) -> (%9203:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=695)])
            cf.ReturnOp (%9203:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=695)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.18 <CPU> [using_qnn:true, symbol:model.layers.18] {
        (%9204:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8244:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)], %8245:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)]) -> (%9256:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)]) {
            linalg.CPU.RMSNormOp <name="model.layers.18.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=697, solved=0))] (%9204:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9205:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696)])
            graph.CallGraphOp @model.layers.18.self_attn (%9205:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8244:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)], %8245:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)]) -> (%9247:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=721)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)])
            linalg.CPU.AddOp <name="model.layers.18.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=721, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9204:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9247:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=721)]) -> (%9248:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.18.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=722, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=723, solved=0))] (%9248:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9249:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=722)])
            graph.CallGraphOp @model.layers.18.mlp (%9249:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=722)]) -> (%9255:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=730)])
            linalg.CPU.AddOp <name="model.layers.18.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=730, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9248:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9255:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=730)]) -> (%9256:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9256:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.18.self_attn <CPU> [using_qnn:true, symbol:model.layers.18.self_attn] {
        (%9205:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8244:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)], %8245:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)]) -> (%9247:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=721)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)]) {
            linalg.CPU.LinearOp <name="model.layers.18.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=698, solved=0))] (%9205:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696)]) -> (%9206:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699)])
            linalg.CPU.LinearOp <name="model.layers.18.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=700, solved=0))] (%9205:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696)]) -> (%9207:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701)])
            linalg.CPU.LinearOp <name="model.layers.18.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=702, solved=0))] (%9205:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=696)]) -> (%9208:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703)])
            linalg.CPU.ViewOp <name="model.layers.18.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699, solved=0), )] (%9206:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699)]) -> (%9206:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699)])
            linalg.CPU.TransposeOp <name="model.layers.18.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699, solved=0), )] (%9206:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699)]) -> (%9209:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699)])
            linalg.CPU.ViewOp <name="model.layers.18.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701, solved=0), )] (%9207:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701)]) -> (%9207:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701)])
            linalg.CPU.TransposeOp <name="model.layers.18.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701, solved=0), )] (%9207:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701)]) -> (%9210:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701)])
            linalg.CPU.ViewOp <name="model.layers.18.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703, solved=0), )] (%9208:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703)]) -> (%9208:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703)])
            linalg.CPU.TransposeOp <name="model.layers.18.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703, solved=0), )] (%9208:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703)]) -> (%9211:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703)])
            linalg.CPU.RMSNormOp <name="model.layers.18.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=705, solved=0))] (%9209:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=699)]) -> (%9212:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)])
            linalg.CPU.RMSNormOp <name="model.layers.18.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=707, solved=0))] (%9210:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=701)]) -> (%9213:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)])
            linalg.CPU.ViewOp <name="model.layers.18.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.18.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.18.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), )] (%9212:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)]) -> (%9212:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)])
            linalg.CPU.SliceOp <name="model.layers.18.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), )] (%9212:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)]) -> (%9212:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)])
            linalg.CPU.NegOp <name="model.layers.18.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), )] (%9212:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)]) -> (%9214:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)])
            linalg.CPU.ConcatOp <name="model.layers.18.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), )] (%9214:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)], %9212:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)]) -> (%9215:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)])
            linalg.CPU.MulOp <name="model.layers.18.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), )] (%9215:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9216:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)])
            linalg.CPU.MulOp <name="model.layers.18.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), )] (%9212:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9217:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)])
            linalg.CPU.AddOp <name="model.layers.18.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), )] (%9217:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)], %9216:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)]) -> (%9218:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)])
            linalg.CPU.SliceOp <name="model.layers.18.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), )] (%9213:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)]) -> (%9213:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)])
            linalg.CPU.SliceOp <name="model.layers.18.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), )] (%9213:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)]) -> (%9213:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)])
            linalg.CPU.NegOp <name="model.layers.18.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), )] (%9213:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)]) -> (%9219:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)])
            linalg.CPU.ConcatOp <name="model.layers.18.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), )] (%9219:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)], %9213:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)]) -> (%9220:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)])
            linalg.CPU.MulOp <name="model.layers.18.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), )] (%9220:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9221:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)])
            linalg.CPU.MulOp <name="model.layers.18.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), )] (%9213:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9222:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)])
            linalg.CPU.AddOp <name="model.layers.18.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), )] (%9222:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)], %9221:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)]) -> (%9223:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)])
            linalg.CPU.CastTypeOp <name="model.layers.18.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=708, solved=0), )] (%9223:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=706)]) -> (%9224:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=708)])
            linalg.CPU.CastTypeOp <name="model.layers.18.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=708, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709, solved=0), )] (%9224:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=708)]) -> (%9225:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)])
            linalg.CPU.TransposeOp <name="model.layers.18.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709, solved=0), )] (%9225:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)]) -> (%9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)])
            linalg.CPU.CastTypeOp <name="model.layers.18.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=710, solved=0), )] (%9211:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=703)]) -> (%9228:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=710)])
            linalg.CPU.CastTypeOp <name="model.layers.18.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=710, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711, solved=0), )] (%9228:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=710)]) -> (%9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)])
            linalg.CPU.ConcatOp <name="model.layers.18.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21, solved=0), )] (%8244:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)]) -> (%9231:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)])
            linalg.CPU.ConcatOp <name="model.layers.18.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49, solved=0), )] (%8245:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)]) -> (%9232:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)])
            linalg.CPU.RepeatOp <name="model.layers.18.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21, solved=0), )] (%9231:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)]) -> (%9233:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)])
            linalg.CPU.RepeatOp <name="model.layers.18.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49, solved=0), )] (%9232:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)]) -> (%9234:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)])
            linalg.CPU.MatMulOp <name="model.layers.18.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712, solved=0), )] (%9218:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=704)], %9233:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=21)]) -> (%9235:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712)])
            linalg.CPU.MulOp <name="model.layers.18.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=713, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712, solved=0), )] (%9235:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712)], %9236:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=713), constant:[0.088388346]]) -> (%9237:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712)])
            linalg.CPU.ReduceMinOp <name="model.layers.18.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714, solved=0), )] (%9237:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712)]) -> (%9238:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714)])
            linalg.CPU.AddOp <name="model.layers.18.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=715, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714, solved=0), )] (%9238:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714)], %9239:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=715), constant:[-20]]) -> (%9240:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714)])
            linalg.CPU.EqualOp <name="model.layers.18.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=716, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=717, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9241:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=716), constant:[0]]) -> (%9242:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=717)])
            linalg.CPU.WhereOp <name="model.layers.18.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=717, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714, solved=0), )] (%9242:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=717)], %9237:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=712)], %9240:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714)]) -> (%9243:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714)])
            linalg.CPU.SoftmaxOp <name="model.layers.18.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=718, solved=0), )] (%9243:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=714)]) -> (%9244:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=718)])
            linalg.CPU.MatMulOp <name="model.layers.18.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=718, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719, solved=0), )] (%9244:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=718)], %9234:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=49)]) -> (%9245:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719)])
            linalg.CPU.TransposeOp <name="model.layers.18.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719, solved=0), )] (%9245:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719)]) -> (%9246:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719)])
            linalg.CPU.ViewOp <name="model.layers.18.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719, solved=0), )] (%9246:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719)]) -> (%9246:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719)])
            linalg.CPU.LinearOp <name="model.layers.18.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=721, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=720, solved=0))] (%9246:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=719)]) -> (%9247:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=721)])
            cf.ReturnOp (%9247:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=721)], %9227:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=709)], %9229:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=711)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.18.mlp <CPU> [using_qnn:true, symbol:model.layers.18.mlp] {
        (%9249:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=722)]) -> (%9255:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=730)]) {
            linalg.CPU.LinearOp <name="model.layers.18.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=722, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=725, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=724, solved=0))] (%9249:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=722)]) -> (%9250:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=725)])
            linalg.CPU.LinearOp <name="model.layers.18.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=722, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=726, solved=0))] (%9249:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=722)]) -> (%9251:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727)])
            linalg.CPU.SigmoidOp <name="model.layers.18.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=728, solved=0), )] (%9251:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727)]) -> (%9252:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=728)])
            linalg.CPU.MulOp <name="model.layers.18.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=728, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727, solved=0), )] (%9251:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727)], %9252:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=728)]) -> (%9253:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727)])
            linalg.CPU.MulOp <name="model.layers.18.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=725, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727, solved=0), )] (%9253:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727)], %9250:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=725)]) -> (%9254:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727)])
            linalg.CPU.LinearOp <name="model.layers.18.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=730, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=729, solved=0))] (%9254:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=727)]) -> (%9255:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=730)])
            cf.ReturnOp (%9255:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=730)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.19 <CPU> [using_qnn:true, symbol:model.layers.19] {
        (%9256:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8246:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)], %8247:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)]) -> (%9308:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)]) {
            linalg.CPU.RMSNormOp <name="model.layers.19.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=732, solved=0))] (%9256:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9257:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731)])
            graph.CallGraphOp @model.layers.19.self_attn (%9257:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8246:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)], %8247:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)]) -> (%9299:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=756)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)])
            linalg.CPU.AddOp <name="model.layers.19.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=756, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9256:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9299:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=756)]) -> (%9300:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.19.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=757, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=758, solved=0))] (%9300:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9301:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=757)])
            graph.CallGraphOp @model.layers.19.mlp (%9301:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=757)]) -> (%9307:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=765)])
            linalg.CPU.AddOp <name="model.layers.19.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=765, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9300:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9307:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=765)]) -> (%9308:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9308:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.19.self_attn <CPU> [using_qnn:true, symbol:model.layers.19.self_attn] {
        (%9257:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8246:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)], %8247:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)]) -> (%9299:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=756)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)]) {
            linalg.CPU.LinearOp <name="model.layers.19.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=733, solved=0))] (%9257:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731)]) -> (%9258:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734)])
            linalg.CPU.LinearOp <name="model.layers.19.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=735, solved=0))] (%9257:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731)]) -> (%9259:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736)])
            linalg.CPU.LinearOp <name="model.layers.19.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=737, solved=0))] (%9257:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=731)]) -> (%9260:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738)])
            linalg.CPU.ViewOp <name="model.layers.19.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734, solved=0), )] (%9258:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734)]) -> (%9258:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734)])
            linalg.CPU.TransposeOp <name="model.layers.19.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734, solved=0), )] (%9258:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734)]) -> (%9261:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734)])
            linalg.CPU.ViewOp <name="model.layers.19.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736, solved=0), )] (%9259:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736)]) -> (%9259:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736)])
            linalg.CPU.TransposeOp <name="model.layers.19.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736, solved=0), )] (%9259:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736)]) -> (%9262:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736)])
            linalg.CPU.ViewOp <name="model.layers.19.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738, solved=0), )] (%9260:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738)]) -> (%9260:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738)])
            linalg.CPU.TransposeOp <name="model.layers.19.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738, solved=0), )] (%9260:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738)]) -> (%9263:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738)])
            linalg.CPU.RMSNormOp <name="model.layers.19.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=740, solved=0))] (%9261:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=734)]) -> (%9264:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)])
            linalg.CPU.RMSNormOp <name="model.layers.19.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=742, solved=0))] (%9262:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=736)]) -> (%9265:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)])
            linalg.CPU.ViewOp <name="model.layers.19.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.19.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.19.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), )] (%9264:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)]) -> (%9264:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)])
            linalg.CPU.SliceOp <name="model.layers.19.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), )] (%9264:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)]) -> (%9264:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)])
            linalg.CPU.NegOp <name="model.layers.19.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), )] (%9264:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)]) -> (%9266:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)])
            linalg.CPU.ConcatOp <name="model.layers.19.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), )] (%9266:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)], %9264:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)]) -> (%9267:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)])
            linalg.CPU.MulOp <name="model.layers.19.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), )] (%9267:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9268:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)])
            linalg.CPU.MulOp <name="model.layers.19.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), )] (%9264:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9269:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)])
            linalg.CPU.AddOp <name="model.layers.19.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), )] (%9269:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)], %9268:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)]) -> (%9270:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)])
            linalg.CPU.SliceOp <name="model.layers.19.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), )] (%9265:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)]) -> (%9265:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)])
            linalg.CPU.SliceOp <name="model.layers.19.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), )] (%9265:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)]) -> (%9265:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)])
            linalg.CPU.NegOp <name="model.layers.19.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), )] (%9265:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)]) -> (%9271:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)])
            linalg.CPU.ConcatOp <name="model.layers.19.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), )] (%9271:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)], %9265:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)]) -> (%9272:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)])
            linalg.CPU.MulOp <name="model.layers.19.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), )] (%9272:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9273:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)])
            linalg.CPU.MulOp <name="model.layers.19.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), )] (%9265:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9274:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)])
            linalg.CPU.AddOp <name="model.layers.19.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), )] (%9274:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)], %9273:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)]) -> (%9275:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)])
            linalg.CPU.CastTypeOp <name="model.layers.19.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=743, solved=0), )] (%9275:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=741)]) -> (%9276:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=743)])
            linalg.CPU.CastTypeOp <name="model.layers.19.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=743, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744, solved=0), )] (%9276:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=743)]) -> (%9277:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)])
            linalg.CPU.TransposeOp <name="model.layers.19.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744, solved=0), )] (%9277:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)]) -> (%9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)])
            linalg.CPU.CastTypeOp <name="model.layers.19.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=745, solved=0), )] (%9263:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=738)]) -> (%9280:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=745)])
            linalg.CPU.CastTypeOp <name="model.layers.19.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=745, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746, solved=0), )] (%9280:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=745)]) -> (%9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)])
            linalg.CPU.ConcatOp <name="model.layers.19.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22, solved=0), )] (%8246:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)]) -> (%9283:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)])
            linalg.CPU.ConcatOp <name="model.layers.19.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50, solved=0), )] (%8247:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)]) -> (%9284:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)])
            linalg.CPU.RepeatOp <name="model.layers.19.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22, solved=0), )] (%9283:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)]) -> (%9285:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)])
            linalg.CPU.RepeatOp <name="model.layers.19.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50, solved=0), )] (%9284:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)]) -> (%9286:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)])
            linalg.CPU.MatMulOp <name="model.layers.19.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747, solved=0), )] (%9270:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=739)], %9285:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=22)]) -> (%9287:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747)])
            linalg.CPU.MulOp <name="model.layers.19.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=748, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747, solved=0), )] (%9287:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747)], %9288:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=748), constant:[0.088388346]]) -> (%9289:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747)])
            linalg.CPU.ReduceMinOp <name="model.layers.19.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749, solved=0), )] (%9289:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747)]) -> (%9290:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749)])
            linalg.CPU.AddOp <name="model.layers.19.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=750, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749, solved=0), )] (%9290:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749)], %9291:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=750), constant:[-20]]) -> (%9292:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749)])
            linalg.CPU.EqualOp <name="model.layers.19.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=751, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=752, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9293:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=751), constant:[0]]) -> (%9294:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=752)])
            linalg.CPU.WhereOp <name="model.layers.19.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=752, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749, solved=0), )] (%9294:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=752)], %9289:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=747)], %9292:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749)]) -> (%9295:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749)])
            linalg.CPU.SoftmaxOp <name="model.layers.19.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=753, solved=0), )] (%9295:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=749)]) -> (%9296:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=753)])
            linalg.CPU.MatMulOp <name="model.layers.19.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=753, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754, solved=0), )] (%9296:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=753)], %9286:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=50)]) -> (%9297:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754)])
            linalg.CPU.TransposeOp <name="model.layers.19.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754, solved=0), )] (%9297:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754)]) -> (%9298:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754)])
            linalg.CPU.ViewOp <name="model.layers.19.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754, solved=0), )] (%9298:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754)]) -> (%9298:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754)])
            linalg.CPU.LinearOp <name="model.layers.19.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=756, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=755, solved=0))] (%9298:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=754)]) -> (%9299:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=756)])
            cf.ReturnOp (%9299:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=756)], %9279:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=744)], %9281:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=746)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.19.mlp <CPU> [using_qnn:true, symbol:model.layers.19.mlp] {
        (%9301:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=757)]) -> (%9307:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=765)]) {
            linalg.CPU.LinearOp <name="model.layers.19.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=757, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=760, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=759, solved=0))] (%9301:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=757)]) -> (%9302:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=760)])
            linalg.CPU.LinearOp <name="model.layers.19.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=757, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=761, solved=0))] (%9301:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=757)]) -> (%9303:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762)])
            linalg.CPU.SigmoidOp <name="model.layers.19.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=763, solved=0), )] (%9303:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762)]) -> (%9304:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=763)])
            linalg.CPU.MulOp <name="model.layers.19.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=763, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762, solved=0), )] (%9303:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762)], %9304:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=763)]) -> (%9305:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762)])
            linalg.CPU.MulOp <name="model.layers.19.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=760, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762, solved=0), )] (%9305:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762)], %9302:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=760)]) -> (%9306:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762)])
            linalg.CPU.LinearOp <name="model.layers.19.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=765, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=764, solved=0))] (%9306:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=762)]) -> (%9307:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=765)])
            cf.ReturnOp (%9307:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=765)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.20 <CPU> [using_qnn:true, symbol:model.layers.20] {
        (%9308:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8248:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)], %8249:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)]) -> (%9360:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)]) {
            linalg.CPU.RMSNormOp <name="model.layers.20.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=767, solved=0))] (%9308:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9309:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766)])
            graph.CallGraphOp @model.layers.20.self_attn (%9309:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8248:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)], %8249:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)]) -> (%9351:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=791)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)])
            linalg.CPU.AddOp <name="model.layers.20.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=791, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9308:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9351:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=791)]) -> (%9352:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.20.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=792, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=793, solved=0))] (%9352:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9353:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=792)])
            graph.CallGraphOp @model.layers.20.mlp (%9353:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=792)]) -> (%9359:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=800)])
            linalg.CPU.AddOp <name="model.layers.20.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=800, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9352:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9359:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=800)]) -> (%9360:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9360:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.20.self_attn <CPU> [using_qnn:true, symbol:model.layers.20.self_attn] {
        (%9309:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8248:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)], %8249:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)]) -> (%9351:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=791)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)]) {
            linalg.CPU.LinearOp <name="model.layers.20.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=768, solved=0))] (%9309:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766)]) -> (%9310:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769)])
            linalg.CPU.LinearOp <name="model.layers.20.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=770, solved=0))] (%9309:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766)]) -> (%9311:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771)])
            linalg.CPU.LinearOp <name="model.layers.20.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=772, solved=0))] (%9309:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=766)]) -> (%9312:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773)])
            linalg.CPU.ViewOp <name="model.layers.20.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769, solved=0), )] (%9310:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769)]) -> (%9310:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769)])
            linalg.CPU.TransposeOp <name="model.layers.20.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769, solved=0), )] (%9310:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769)]) -> (%9313:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769)])
            linalg.CPU.ViewOp <name="model.layers.20.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771, solved=0), )] (%9311:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771)]) -> (%9311:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771)])
            linalg.CPU.TransposeOp <name="model.layers.20.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771, solved=0), )] (%9311:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771)]) -> (%9314:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771)])
            linalg.CPU.ViewOp <name="model.layers.20.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773, solved=0), )] (%9312:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773)]) -> (%9312:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773)])
            linalg.CPU.TransposeOp <name="model.layers.20.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773, solved=0), )] (%9312:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773)]) -> (%9315:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773)])
            linalg.CPU.RMSNormOp <name="model.layers.20.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=775, solved=0))] (%9313:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=769)]) -> (%9316:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)])
            linalg.CPU.RMSNormOp <name="model.layers.20.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=777, solved=0))] (%9314:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=771)]) -> (%9317:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)])
            linalg.CPU.ViewOp <name="model.layers.20.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.20.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.20.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), )] (%9316:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)]) -> (%9316:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)])
            linalg.CPU.SliceOp <name="model.layers.20.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), )] (%9316:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)]) -> (%9316:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)])
            linalg.CPU.NegOp <name="model.layers.20.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), )] (%9316:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)]) -> (%9318:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)])
            linalg.CPU.ConcatOp <name="model.layers.20.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), )] (%9318:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)], %9316:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)]) -> (%9319:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)])
            linalg.CPU.MulOp <name="model.layers.20.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), )] (%9319:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9320:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)])
            linalg.CPU.MulOp <name="model.layers.20.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), )] (%9316:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9321:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)])
            linalg.CPU.AddOp <name="model.layers.20.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), )] (%9321:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)], %9320:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)]) -> (%9322:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)])
            linalg.CPU.SliceOp <name="model.layers.20.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), )] (%9317:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)]) -> (%9317:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)])
            linalg.CPU.SliceOp <name="model.layers.20.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), )] (%9317:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)]) -> (%9317:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)])
            linalg.CPU.NegOp <name="model.layers.20.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), )] (%9317:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)]) -> (%9323:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)])
            linalg.CPU.ConcatOp <name="model.layers.20.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), )] (%9323:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)], %9317:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)]) -> (%9324:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)])
            linalg.CPU.MulOp <name="model.layers.20.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), )] (%9324:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9325:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)])
            linalg.CPU.MulOp <name="model.layers.20.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), )] (%9317:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9326:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)])
            linalg.CPU.AddOp <name="model.layers.20.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), )] (%9326:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)], %9325:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)]) -> (%9327:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)])
            linalg.CPU.CastTypeOp <name="model.layers.20.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=778, solved=0), )] (%9327:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=776)]) -> (%9328:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=778)])
            linalg.CPU.CastTypeOp <name="model.layers.20.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=778, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779, solved=0), )] (%9328:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=778)]) -> (%9329:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)])
            linalg.CPU.TransposeOp <name="model.layers.20.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779, solved=0), )] (%9329:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)]) -> (%9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)])
            linalg.CPU.CastTypeOp <name="model.layers.20.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=780, solved=0), )] (%9315:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=773)]) -> (%9332:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=780)])
            linalg.CPU.CastTypeOp <name="model.layers.20.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=780, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781, solved=0), )] (%9332:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=780)]) -> (%9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)])
            linalg.CPU.ConcatOp <name="model.layers.20.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23, solved=0), )] (%8248:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)]) -> (%9335:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)])
            linalg.CPU.ConcatOp <name="model.layers.20.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51, solved=0), )] (%8249:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)]) -> (%9336:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)])
            linalg.CPU.RepeatOp <name="model.layers.20.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23, solved=0), )] (%9335:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)]) -> (%9337:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)])
            linalg.CPU.RepeatOp <name="model.layers.20.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51, solved=0), )] (%9336:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)]) -> (%9338:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)])
            linalg.CPU.MatMulOp <name="model.layers.20.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782, solved=0), )] (%9322:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=774)], %9337:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=23)]) -> (%9339:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782)])
            linalg.CPU.MulOp <name="model.layers.20.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=783, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782, solved=0), )] (%9339:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782)], %9340:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=783), constant:[0.088388346]]) -> (%9341:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782)])
            linalg.CPU.ReduceMinOp <name="model.layers.20.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784, solved=0), )] (%9341:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782)]) -> (%9342:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784)])
            linalg.CPU.AddOp <name="model.layers.20.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=785, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784, solved=0), )] (%9342:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784)], %9343:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=785), constant:[-20]]) -> (%9344:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784)])
            linalg.CPU.EqualOp <name="model.layers.20.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=786, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=787, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9345:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=786), constant:[0]]) -> (%9346:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=787)])
            linalg.CPU.WhereOp <name="model.layers.20.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=787, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784, solved=0), )] (%9346:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=787)], %9341:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=782)], %9344:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784)]) -> (%9347:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784)])
            linalg.CPU.SoftmaxOp <name="model.layers.20.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=788, solved=0), )] (%9347:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=784)]) -> (%9348:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=788)])
            linalg.CPU.MatMulOp <name="model.layers.20.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=788, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789, solved=0), )] (%9348:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=788)], %9338:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=51)]) -> (%9349:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789)])
            linalg.CPU.TransposeOp <name="model.layers.20.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789, solved=0), )] (%9349:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789)]) -> (%9350:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789)])
            linalg.CPU.ViewOp <name="model.layers.20.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789, solved=0), )] (%9350:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789)]) -> (%9350:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789)])
            linalg.CPU.LinearOp <name="model.layers.20.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=791, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=790, solved=0))] (%9350:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=789)]) -> (%9351:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=791)])
            cf.ReturnOp (%9351:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=791)], %9331:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=779)], %9333:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=781)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.20.mlp <CPU> [using_qnn:true, symbol:model.layers.20.mlp] {
        (%9353:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=792)]) -> (%9359:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=800)]) {
            linalg.CPU.LinearOp <name="model.layers.20.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=792, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=795, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=794, solved=0))] (%9353:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=792)]) -> (%9354:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=795)])
            linalg.CPU.LinearOp <name="model.layers.20.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=792, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=796, solved=0))] (%9353:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=792)]) -> (%9355:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797)])
            linalg.CPU.SigmoidOp <name="model.layers.20.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=798, solved=0), )] (%9355:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797)]) -> (%9356:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=798)])
            linalg.CPU.MulOp <name="model.layers.20.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=798, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797, solved=0), )] (%9355:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797)], %9356:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=798)]) -> (%9357:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797)])
            linalg.CPU.MulOp <name="model.layers.20.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=795, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797, solved=0), )] (%9357:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797)], %9354:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=795)]) -> (%9358:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797)])
            linalg.CPU.LinearOp <name="model.layers.20.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=800, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=799, solved=0))] (%9358:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=797)]) -> (%9359:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=800)])
            cf.ReturnOp (%9359:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=800)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.21 <CPU> [using_qnn:true, symbol:model.layers.21] {
        (%9360:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8250:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)], %8251:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)]) -> (%9412:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)]) {
            linalg.CPU.RMSNormOp <name="model.layers.21.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=802, solved=0))] (%9360:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9361:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801)])
            graph.CallGraphOp @model.layers.21.self_attn (%9361:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8250:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)], %8251:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)]) -> (%9403:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=826)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)])
            linalg.CPU.AddOp <name="model.layers.21.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=826, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9360:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9403:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=826)]) -> (%9404:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.21.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=827, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=828, solved=0))] (%9404:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9405:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=827)])
            graph.CallGraphOp @model.layers.21.mlp (%9405:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=827)]) -> (%9411:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=835)])
            linalg.CPU.AddOp <name="model.layers.21.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=835, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9404:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9411:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=835)]) -> (%9412:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9412:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.21.self_attn <CPU> [using_qnn:true, symbol:model.layers.21.self_attn] {
        (%9361:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8250:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)], %8251:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)]) -> (%9403:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=826)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)]) {
            linalg.CPU.LinearOp <name="model.layers.21.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=803, solved=0))] (%9361:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801)]) -> (%9362:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804)])
            linalg.CPU.LinearOp <name="model.layers.21.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=805, solved=0))] (%9361:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801)]) -> (%9363:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806)])
            linalg.CPU.LinearOp <name="model.layers.21.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=807, solved=0))] (%9361:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=801)]) -> (%9364:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808)])
            linalg.CPU.ViewOp <name="model.layers.21.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804, solved=0), )] (%9362:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804)]) -> (%9362:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804)])
            linalg.CPU.TransposeOp <name="model.layers.21.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804, solved=0), )] (%9362:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804)]) -> (%9365:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804)])
            linalg.CPU.ViewOp <name="model.layers.21.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806, solved=0), )] (%9363:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806)]) -> (%9363:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806)])
            linalg.CPU.TransposeOp <name="model.layers.21.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806, solved=0), )] (%9363:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806)]) -> (%9366:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806)])
            linalg.CPU.ViewOp <name="model.layers.21.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808, solved=0), )] (%9364:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808)]) -> (%9364:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808)])
            linalg.CPU.TransposeOp <name="model.layers.21.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808, solved=0), )] (%9364:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808)]) -> (%9367:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808)])
            linalg.CPU.RMSNormOp <name="model.layers.21.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=810, solved=0))] (%9365:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=804)]) -> (%9368:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)])
            linalg.CPU.RMSNormOp <name="model.layers.21.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=812, solved=0))] (%9366:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=806)]) -> (%9369:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)])
            linalg.CPU.ViewOp <name="model.layers.21.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.21.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.21.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), )] (%9368:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)]) -> (%9368:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)])
            linalg.CPU.SliceOp <name="model.layers.21.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), )] (%9368:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)]) -> (%9368:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)])
            linalg.CPU.NegOp <name="model.layers.21.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), )] (%9368:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)]) -> (%9370:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)])
            linalg.CPU.ConcatOp <name="model.layers.21.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), )] (%9370:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)], %9368:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)]) -> (%9371:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)])
            linalg.CPU.MulOp <name="model.layers.21.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), )] (%9371:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9372:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)])
            linalg.CPU.MulOp <name="model.layers.21.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), )] (%9368:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9373:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)])
            linalg.CPU.AddOp <name="model.layers.21.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), )] (%9373:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)], %9372:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)]) -> (%9374:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)])
            linalg.CPU.SliceOp <name="model.layers.21.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), )] (%9369:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)]) -> (%9369:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)])
            linalg.CPU.SliceOp <name="model.layers.21.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), )] (%9369:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)]) -> (%9369:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)])
            linalg.CPU.NegOp <name="model.layers.21.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), )] (%9369:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)]) -> (%9375:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)])
            linalg.CPU.ConcatOp <name="model.layers.21.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), )] (%9375:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)], %9369:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)]) -> (%9376:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)])
            linalg.CPU.MulOp <name="model.layers.21.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), )] (%9376:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9377:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)])
            linalg.CPU.MulOp <name="model.layers.21.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), )] (%9369:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9378:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)])
            linalg.CPU.AddOp <name="model.layers.21.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), )] (%9378:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)], %9377:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)]) -> (%9379:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)])
            linalg.CPU.CastTypeOp <name="model.layers.21.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=813, solved=0), )] (%9379:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=811)]) -> (%9380:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=813)])
            linalg.CPU.CastTypeOp <name="model.layers.21.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=813, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814, solved=0), )] (%9380:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=813)]) -> (%9381:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)])
            linalg.CPU.TransposeOp <name="model.layers.21.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814, solved=0), )] (%9381:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)]) -> (%9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)])
            linalg.CPU.CastTypeOp <name="model.layers.21.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=815, solved=0), )] (%9367:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=808)]) -> (%9384:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=815)])
            linalg.CPU.CastTypeOp <name="model.layers.21.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=815, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816, solved=0), )] (%9384:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=815)]) -> (%9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)])
            linalg.CPU.ConcatOp <name="model.layers.21.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24, solved=0), )] (%8250:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)]) -> (%9387:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)])
            linalg.CPU.ConcatOp <name="model.layers.21.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52, solved=0), )] (%8251:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)]) -> (%9388:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)])
            linalg.CPU.RepeatOp <name="model.layers.21.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24, solved=0), )] (%9387:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)]) -> (%9389:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)])
            linalg.CPU.RepeatOp <name="model.layers.21.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52, solved=0), )] (%9388:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)]) -> (%9390:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)])
            linalg.CPU.MatMulOp <name="model.layers.21.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817, solved=0), )] (%9374:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=809)], %9389:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=24)]) -> (%9391:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817)])
            linalg.CPU.MulOp <name="model.layers.21.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=818, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817, solved=0), )] (%9391:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817)], %9392:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=818), constant:[0.088388346]]) -> (%9393:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817)])
            linalg.CPU.ReduceMinOp <name="model.layers.21.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819, solved=0), )] (%9393:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817)]) -> (%9394:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819)])
            linalg.CPU.AddOp <name="model.layers.21.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=820, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819, solved=0), )] (%9394:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819)], %9395:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=820), constant:[-20]]) -> (%9396:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819)])
            linalg.CPU.EqualOp <name="model.layers.21.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=821, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=822, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9397:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=821), constant:[0]]) -> (%9398:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=822)])
            linalg.CPU.WhereOp <name="model.layers.21.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=822, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819, solved=0), )] (%9398:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=822)], %9393:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=817)], %9396:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819)]) -> (%9399:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819)])
            linalg.CPU.SoftmaxOp <name="model.layers.21.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=823, solved=0), )] (%9399:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=819)]) -> (%9400:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=823)])
            linalg.CPU.MatMulOp <name="model.layers.21.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=823, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824, solved=0), )] (%9400:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=823)], %9390:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=52)]) -> (%9401:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824)])
            linalg.CPU.TransposeOp <name="model.layers.21.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824, solved=0), )] (%9401:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824)]) -> (%9402:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824)])
            linalg.CPU.ViewOp <name="model.layers.21.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824, solved=0), )] (%9402:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824)]) -> (%9402:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824)])
            linalg.CPU.LinearOp <name="model.layers.21.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=826, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=825, solved=0))] (%9402:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=824)]) -> (%9403:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=826)])
            cf.ReturnOp (%9403:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=826)], %9383:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=814)], %9385:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=816)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.21.mlp <CPU> [using_qnn:true, symbol:model.layers.21.mlp] {
        (%9405:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=827)]) -> (%9411:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=835)]) {
            linalg.CPU.LinearOp <name="model.layers.21.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=827, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=830, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=829, solved=0))] (%9405:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=827)]) -> (%9406:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=830)])
            linalg.CPU.LinearOp <name="model.layers.21.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=827, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=831, solved=0))] (%9405:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=827)]) -> (%9407:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832)])
            linalg.CPU.SigmoidOp <name="model.layers.21.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=833, solved=0), )] (%9407:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832)]) -> (%9408:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=833)])
            linalg.CPU.MulOp <name="model.layers.21.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=833, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832, solved=0), )] (%9407:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832)], %9408:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=833)]) -> (%9409:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832)])
            linalg.CPU.MulOp <name="model.layers.21.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=830, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832, solved=0), )] (%9409:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832)], %9406:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=830)]) -> (%9410:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832)])
            linalg.CPU.LinearOp <name="model.layers.21.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=835, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=834, solved=0))] (%9410:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=832)]) -> (%9411:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=835)])
            cf.ReturnOp (%9411:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=835)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.22 <CPU> [using_qnn:true, symbol:model.layers.22] {
        (%9412:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8252:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)], %8253:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)]) -> (%9464:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)]) {
            linalg.CPU.RMSNormOp <name="model.layers.22.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=837, solved=0))] (%9412:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9413:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836)])
            graph.CallGraphOp @model.layers.22.self_attn (%9413:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8252:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)], %8253:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)]) -> (%9455:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=861)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)])
            linalg.CPU.AddOp <name="model.layers.22.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=861, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9412:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9455:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=861)]) -> (%9456:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.22.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=862, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=863, solved=0))] (%9456:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9457:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=862)])
            graph.CallGraphOp @model.layers.22.mlp (%9457:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=862)]) -> (%9463:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=870)])
            linalg.CPU.AddOp <name="model.layers.22.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=870, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9456:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9463:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=870)]) -> (%9464:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9464:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.22.self_attn <CPU> [using_qnn:true, symbol:model.layers.22.self_attn] {
        (%9413:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8252:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)], %8253:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)]) -> (%9455:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=861)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)]) {
            linalg.CPU.LinearOp <name="model.layers.22.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=838, solved=0))] (%9413:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836)]) -> (%9414:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839)])
            linalg.CPU.LinearOp <name="model.layers.22.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=840, solved=0))] (%9413:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836)]) -> (%9415:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841)])
            linalg.CPU.LinearOp <name="model.layers.22.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=842, solved=0))] (%9413:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=836)]) -> (%9416:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843)])
            linalg.CPU.ViewOp <name="model.layers.22.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839, solved=0), )] (%9414:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839)]) -> (%9414:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839)])
            linalg.CPU.TransposeOp <name="model.layers.22.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839, solved=0), )] (%9414:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839)]) -> (%9417:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839)])
            linalg.CPU.ViewOp <name="model.layers.22.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841, solved=0), )] (%9415:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841)]) -> (%9415:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841)])
            linalg.CPU.TransposeOp <name="model.layers.22.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841, solved=0), )] (%9415:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841)]) -> (%9418:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841)])
            linalg.CPU.ViewOp <name="model.layers.22.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843, solved=0), )] (%9416:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843)]) -> (%9416:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843)])
            linalg.CPU.TransposeOp <name="model.layers.22.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843, solved=0), )] (%9416:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843)]) -> (%9419:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843)])
            linalg.CPU.RMSNormOp <name="model.layers.22.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=845, solved=0))] (%9417:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=839)]) -> (%9420:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)])
            linalg.CPU.RMSNormOp <name="model.layers.22.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=847, solved=0))] (%9418:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=841)]) -> (%9421:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)])
            linalg.CPU.ViewOp <name="model.layers.22.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.22.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.22.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), )] (%9420:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)]) -> (%9420:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)])
            linalg.CPU.SliceOp <name="model.layers.22.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), )] (%9420:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)]) -> (%9420:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)])
            linalg.CPU.NegOp <name="model.layers.22.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), )] (%9420:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)]) -> (%9422:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)])
            linalg.CPU.ConcatOp <name="model.layers.22.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), )] (%9422:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)], %9420:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)]) -> (%9423:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)])
            linalg.CPU.MulOp <name="model.layers.22.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), )] (%9423:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9424:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)])
            linalg.CPU.MulOp <name="model.layers.22.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), )] (%9420:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9425:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)])
            linalg.CPU.AddOp <name="model.layers.22.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), )] (%9425:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)], %9424:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)]) -> (%9426:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)])
            linalg.CPU.SliceOp <name="model.layers.22.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), )] (%9421:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)]) -> (%9421:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)])
            linalg.CPU.SliceOp <name="model.layers.22.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), )] (%9421:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)]) -> (%9421:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)])
            linalg.CPU.NegOp <name="model.layers.22.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), )] (%9421:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)]) -> (%9427:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)])
            linalg.CPU.ConcatOp <name="model.layers.22.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), )] (%9427:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)], %9421:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)]) -> (%9428:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)])
            linalg.CPU.MulOp <name="model.layers.22.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), )] (%9428:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9429:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)])
            linalg.CPU.MulOp <name="model.layers.22.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), )] (%9421:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9430:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)])
            linalg.CPU.AddOp <name="model.layers.22.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), )] (%9430:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)], %9429:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)]) -> (%9431:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)])
            linalg.CPU.CastTypeOp <name="model.layers.22.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=848, solved=0), )] (%9431:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=846)]) -> (%9432:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=848)])
            linalg.CPU.CastTypeOp <name="model.layers.22.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=848, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849, solved=0), )] (%9432:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=848)]) -> (%9433:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)])
            linalg.CPU.TransposeOp <name="model.layers.22.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849, solved=0), )] (%9433:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)]) -> (%9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)])
            linalg.CPU.CastTypeOp <name="model.layers.22.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=850, solved=0), )] (%9419:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=843)]) -> (%9436:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=850)])
            linalg.CPU.CastTypeOp <name="model.layers.22.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=850, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851, solved=0), )] (%9436:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=850)]) -> (%9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)])
            linalg.CPU.ConcatOp <name="model.layers.22.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25, solved=0), )] (%8252:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)]) -> (%9439:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)])
            linalg.CPU.ConcatOp <name="model.layers.22.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53, solved=0), )] (%8253:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)]) -> (%9440:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)])
            linalg.CPU.RepeatOp <name="model.layers.22.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25, solved=0), )] (%9439:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)]) -> (%9441:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)])
            linalg.CPU.RepeatOp <name="model.layers.22.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53, solved=0), )] (%9440:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)]) -> (%9442:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)])
            linalg.CPU.MatMulOp <name="model.layers.22.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852, solved=0), )] (%9426:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=844)], %9441:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=25)]) -> (%9443:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852)])
            linalg.CPU.MulOp <name="model.layers.22.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=853, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852, solved=0), )] (%9443:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852)], %9444:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=853), constant:[0.088388346]]) -> (%9445:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852)])
            linalg.CPU.ReduceMinOp <name="model.layers.22.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854, solved=0), )] (%9445:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852)]) -> (%9446:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854)])
            linalg.CPU.AddOp <name="model.layers.22.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=855, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854, solved=0), )] (%9446:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854)], %9447:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=855), constant:[-20]]) -> (%9448:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854)])
            linalg.CPU.EqualOp <name="model.layers.22.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=856, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=857, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9449:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=856), constant:[0]]) -> (%9450:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=857)])
            linalg.CPU.WhereOp <name="model.layers.22.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=857, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854, solved=0), )] (%9450:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=857)], %9445:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=852)], %9448:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854)]) -> (%9451:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854)])
            linalg.CPU.SoftmaxOp <name="model.layers.22.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=858, solved=0), )] (%9451:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=854)]) -> (%9452:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=858)])
            linalg.CPU.MatMulOp <name="model.layers.22.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=858, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859, solved=0), )] (%9452:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=858)], %9442:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=53)]) -> (%9453:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859)])
            linalg.CPU.TransposeOp <name="model.layers.22.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859, solved=0), )] (%9453:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859)]) -> (%9454:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859)])
            linalg.CPU.ViewOp <name="model.layers.22.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859, solved=0), )] (%9454:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859)]) -> (%9454:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859)])
            linalg.CPU.LinearOp <name="model.layers.22.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=861, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=860, solved=0))] (%9454:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=859)]) -> (%9455:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=861)])
            cf.ReturnOp (%9455:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=861)], %9435:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=849)], %9437:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=851)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.22.mlp <CPU> [using_qnn:true, symbol:model.layers.22.mlp] {
        (%9457:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=862)]) -> (%9463:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=870)]) {
            linalg.CPU.LinearOp <name="model.layers.22.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=862, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=865, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=864, solved=0))] (%9457:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=862)]) -> (%9458:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=865)])
            linalg.CPU.LinearOp <name="model.layers.22.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=862, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=866, solved=0))] (%9457:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=862)]) -> (%9459:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867)])
            linalg.CPU.SigmoidOp <name="model.layers.22.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=868, solved=0), )] (%9459:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867)]) -> (%9460:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=868)])
            linalg.CPU.MulOp <name="model.layers.22.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=868, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867, solved=0), )] (%9459:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867)], %9460:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=868)]) -> (%9461:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867)])
            linalg.CPU.MulOp <name="model.layers.22.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=865, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867, solved=0), )] (%9461:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867)], %9458:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=865)]) -> (%9462:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867)])
            linalg.CPU.LinearOp <name="model.layers.22.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=870, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=869, solved=0))] (%9462:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=867)]) -> (%9463:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=870)])
            cf.ReturnOp (%9463:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=870)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.23 <CPU> [using_qnn:true, symbol:model.layers.23] {
        (%9464:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8254:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)], %8255:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)]) -> (%9516:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)]) {
            linalg.CPU.RMSNormOp <name="model.layers.23.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=872, solved=0))] (%9464:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9465:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871)])
            graph.CallGraphOp @model.layers.23.self_attn (%9465:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8254:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)], %8255:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)]) -> (%9507:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=896)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)])
            linalg.CPU.AddOp <name="model.layers.23.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=896, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9464:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9507:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=896)]) -> (%9508:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.23.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=897, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=898, solved=0))] (%9508:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9509:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=897)])
            graph.CallGraphOp @model.layers.23.mlp (%9509:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=897)]) -> (%9515:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=905)])
            linalg.CPU.AddOp <name="model.layers.23.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=905, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9508:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9515:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=905)]) -> (%9516:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9516:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.23.self_attn <CPU> [using_qnn:true, symbol:model.layers.23.self_attn] {
        (%9465:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8254:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)], %8255:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)]) -> (%9507:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=896)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)]) {
            linalg.CPU.LinearOp <name="model.layers.23.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=873, solved=0))] (%9465:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871)]) -> (%9466:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874)])
            linalg.CPU.LinearOp <name="model.layers.23.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=875, solved=0))] (%9465:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871)]) -> (%9467:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876)])
            linalg.CPU.LinearOp <name="model.layers.23.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=877, solved=0))] (%9465:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=871)]) -> (%9468:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878)])
            linalg.CPU.ViewOp <name="model.layers.23.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874, solved=0), )] (%9466:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874)]) -> (%9466:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874)])
            linalg.CPU.TransposeOp <name="model.layers.23.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874, solved=0), )] (%9466:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874)]) -> (%9469:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874)])
            linalg.CPU.ViewOp <name="model.layers.23.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876, solved=0), )] (%9467:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876)]) -> (%9467:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876)])
            linalg.CPU.TransposeOp <name="model.layers.23.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876, solved=0), )] (%9467:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876)]) -> (%9470:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876)])
            linalg.CPU.ViewOp <name="model.layers.23.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878, solved=0), )] (%9468:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878)]) -> (%9468:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878)])
            linalg.CPU.TransposeOp <name="model.layers.23.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878, solved=0), )] (%9468:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878)]) -> (%9471:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878)])
            linalg.CPU.RMSNormOp <name="model.layers.23.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=880, solved=0))] (%9469:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=874)]) -> (%9472:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)])
            linalg.CPU.RMSNormOp <name="model.layers.23.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=882, solved=0))] (%9470:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=876)]) -> (%9473:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)])
            linalg.CPU.ViewOp <name="model.layers.23.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.23.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.23.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), )] (%9472:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)]) -> (%9472:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)])
            linalg.CPU.SliceOp <name="model.layers.23.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), )] (%9472:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)]) -> (%9472:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)])
            linalg.CPU.NegOp <name="model.layers.23.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), )] (%9472:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)]) -> (%9474:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)])
            linalg.CPU.ConcatOp <name="model.layers.23.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), )] (%9474:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)], %9472:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)]) -> (%9475:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)])
            linalg.CPU.MulOp <name="model.layers.23.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), )] (%9475:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9476:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)])
            linalg.CPU.MulOp <name="model.layers.23.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), )] (%9472:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9477:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)])
            linalg.CPU.AddOp <name="model.layers.23.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), )] (%9477:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)], %9476:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)]) -> (%9478:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)])
            linalg.CPU.SliceOp <name="model.layers.23.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), )] (%9473:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)]) -> (%9473:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)])
            linalg.CPU.SliceOp <name="model.layers.23.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), )] (%9473:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)]) -> (%9473:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)])
            linalg.CPU.NegOp <name="model.layers.23.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), )] (%9473:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)]) -> (%9479:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)])
            linalg.CPU.ConcatOp <name="model.layers.23.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), )] (%9479:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)], %9473:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)]) -> (%9480:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)])
            linalg.CPU.MulOp <name="model.layers.23.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), )] (%9480:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9481:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)])
            linalg.CPU.MulOp <name="model.layers.23.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), )] (%9473:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9482:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)])
            linalg.CPU.AddOp <name="model.layers.23.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), )] (%9482:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)], %9481:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)]) -> (%9483:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)])
            linalg.CPU.CastTypeOp <name="model.layers.23.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=883, solved=0), )] (%9483:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=881)]) -> (%9484:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=883)])
            linalg.CPU.CastTypeOp <name="model.layers.23.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=883, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884, solved=0), )] (%9484:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=883)]) -> (%9485:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)])
            linalg.CPU.TransposeOp <name="model.layers.23.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884, solved=0), )] (%9485:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)]) -> (%9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)])
            linalg.CPU.CastTypeOp <name="model.layers.23.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=885, solved=0), )] (%9471:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=878)]) -> (%9488:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=885)])
            linalg.CPU.CastTypeOp <name="model.layers.23.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=885, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886, solved=0), )] (%9488:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=885)]) -> (%9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)])
            linalg.CPU.ConcatOp <name="model.layers.23.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26, solved=0), )] (%8254:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)]) -> (%9491:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)])
            linalg.CPU.ConcatOp <name="model.layers.23.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54, solved=0), )] (%8255:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)]) -> (%9492:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)])
            linalg.CPU.RepeatOp <name="model.layers.23.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26, solved=0), )] (%9491:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)]) -> (%9493:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)])
            linalg.CPU.RepeatOp <name="model.layers.23.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54, solved=0), )] (%9492:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)]) -> (%9494:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)])
            linalg.CPU.MatMulOp <name="model.layers.23.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887, solved=0), )] (%9478:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=879)], %9493:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=26)]) -> (%9495:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887)])
            linalg.CPU.MulOp <name="model.layers.23.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=888, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887, solved=0), )] (%9495:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887)], %9496:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=888), constant:[0.088388346]]) -> (%9497:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887)])
            linalg.CPU.ReduceMinOp <name="model.layers.23.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889, solved=0), )] (%9497:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887)]) -> (%9498:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889)])
            linalg.CPU.AddOp <name="model.layers.23.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=890, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889, solved=0), )] (%9498:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889)], %9499:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=890), constant:[-20]]) -> (%9500:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889)])
            linalg.CPU.EqualOp <name="model.layers.23.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=891, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=892, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9501:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=891), constant:[0]]) -> (%9502:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=892)])
            linalg.CPU.WhereOp <name="model.layers.23.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=892, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889, solved=0), )] (%9502:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=892)], %9497:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=887)], %9500:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889)]) -> (%9503:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889)])
            linalg.CPU.SoftmaxOp <name="model.layers.23.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=893, solved=0), )] (%9503:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=889)]) -> (%9504:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=893)])
            linalg.CPU.MatMulOp <name="model.layers.23.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=893, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894, solved=0), )] (%9504:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=893)], %9494:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=54)]) -> (%9505:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894)])
            linalg.CPU.TransposeOp <name="model.layers.23.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894, solved=0), )] (%9505:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894)]) -> (%9506:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894)])
            linalg.CPU.ViewOp <name="model.layers.23.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894, solved=0), )] (%9506:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894)]) -> (%9506:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894)])
            linalg.CPU.LinearOp <name="model.layers.23.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=896, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=895, solved=0))] (%9506:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=894)]) -> (%9507:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=896)])
            cf.ReturnOp (%9507:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=896)], %9487:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=884)], %9489:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=886)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.23.mlp <CPU> [using_qnn:true, symbol:model.layers.23.mlp] {
        (%9509:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=897)]) -> (%9515:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=905)]) {
            linalg.CPU.LinearOp <name="model.layers.23.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=897, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=900, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=899, solved=0))] (%9509:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=897)]) -> (%9510:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=900)])
            linalg.CPU.LinearOp <name="model.layers.23.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=897, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=901, solved=0))] (%9509:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=897)]) -> (%9511:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902)])
            linalg.CPU.SigmoidOp <name="model.layers.23.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=903, solved=0), )] (%9511:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902)]) -> (%9512:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=903)])
            linalg.CPU.MulOp <name="model.layers.23.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=903, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902, solved=0), )] (%9511:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902)], %9512:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=903)]) -> (%9513:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902)])
            linalg.CPU.MulOp <name="model.layers.23.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=900, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902, solved=0), )] (%9513:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902)], %9510:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=900)]) -> (%9514:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902)])
            linalg.CPU.LinearOp <name="model.layers.23.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=905, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=904, solved=0))] (%9514:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=902)]) -> (%9515:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=905)])
            cf.ReturnOp (%9515:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=905)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.24 <CPU> [using_qnn:true, symbol:model.layers.24] {
        (%9516:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8256:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)], %8257:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)]) -> (%9568:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)]) {
            linalg.CPU.RMSNormOp <name="model.layers.24.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=907, solved=0))] (%9516:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9517:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906)])
            graph.CallGraphOp @model.layers.24.self_attn (%9517:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8256:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)], %8257:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)]) -> (%9559:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=931)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)])
            linalg.CPU.AddOp <name="model.layers.24.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=931, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9516:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9559:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=931)]) -> (%9560:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.24.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=932, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=933, solved=0))] (%9560:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9561:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=932)])
            graph.CallGraphOp @model.layers.24.mlp (%9561:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=932)]) -> (%9567:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=940)])
            linalg.CPU.AddOp <name="model.layers.24.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=940, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9560:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9567:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=940)]) -> (%9568:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9568:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.24.self_attn <CPU> [using_qnn:true, symbol:model.layers.24.self_attn] {
        (%9517:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8256:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)], %8257:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)]) -> (%9559:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=931)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)]) {
            linalg.CPU.LinearOp <name="model.layers.24.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=908, solved=0))] (%9517:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906)]) -> (%9518:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909)])
            linalg.CPU.LinearOp <name="model.layers.24.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=910, solved=0))] (%9517:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906)]) -> (%9519:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911)])
            linalg.CPU.LinearOp <name="model.layers.24.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=912, solved=0))] (%9517:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=906)]) -> (%9520:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913)])
            linalg.CPU.ViewOp <name="model.layers.24.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909, solved=0), )] (%9518:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909)]) -> (%9518:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909)])
            linalg.CPU.TransposeOp <name="model.layers.24.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909, solved=0), )] (%9518:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909)]) -> (%9521:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909)])
            linalg.CPU.ViewOp <name="model.layers.24.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911, solved=0), )] (%9519:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911)]) -> (%9519:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911)])
            linalg.CPU.TransposeOp <name="model.layers.24.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911, solved=0), )] (%9519:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911)]) -> (%9522:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911)])
            linalg.CPU.ViewOp <name="model.layers.24.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913, solved=0), )] (%9520:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913)]) -> (%9520:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913)])
            linalg.CPU.TransposeOp <name="model.layers.24.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913, solved=0), )] (%9520:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913)]) -> (%9523:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913)])
            linalg.CPU.RMSNormOp <name="model.layers.24.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=915, solved=0))] (%9521:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=909)]) -> (%9524:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)])
            linalg.CPU.RMSNormOp <name="model.layers.24.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=917, solved=0))] (%9522:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=911)]) -> (%9525:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)])
            linalg.CPU.ViewOp <name="model.layers.24.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.24.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.24.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), )] (%9524:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)]) -> (%9524:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)])
            linalg.CPU.SliceOp <name="model.layers.24.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), )] (%9524:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)]) -> (%9524:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)])
            linalg.CPU.NegOp <name="model.layers.24.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), )] (%9524:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)]) -> (%9526:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)])
            linalg.CPU.ConcatOp <name="model.layers.24.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), )] (%9526:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)], %9524:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)]) -> (%9527:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)])
            linalg.CPU.MulOp <name="model.layers.24.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), )] (%9527:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9528:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)])
            linalg.CPU.MulOp <name="model.layers.24.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), )] (%9524:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9529:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)])
            linalg.CPU.AddOp <name="model.layers.24.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), )] (%9529:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)], %9528:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)]) -> (%9530:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)])
            linalg.CPU.SliceOp <name="model.layers.24.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), )] (%9525:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)]) -> (%9525:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)])
            linalg.CPU.SliceOp <name="model.layers.24.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), )] (%9525:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)]) -> (%9525:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)])
            linalg.CPU.NegOp <name="model.layers.24.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), )] (%9525:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)]) -> (%9531:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)])
            linalg.CPU.ConcatOp <name="model.layers.24.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), )] (%9531:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)], %9525:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)]) -> (%9532:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)])
            linalg.CPU.MulOp <name="model.layers.24.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), )] (%9532:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9533:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)])
            linalg.CPU.MulOp <name="model.layers.24.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), )] (%9525:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9534:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)])
            linalg.CPU.AddOp <name="model.layers.24.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), )] (%9534:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)], %9533:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)]) -> (%9535:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)])
            linalg.CPU.CastTypeOp <name="model.layers.24.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=918, solved=0), )] (%9535:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=916)]) -> (%9536:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=918)])
            linalg.CPU.CastTypeOp <name="model.layers.24.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=918, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919, solved=0), )] (%9536:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=918)]) -> (%9537:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)])
            linalg.CPU.TransposeOp <name="model.layers.24.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919, solved=0), )] (%9537:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)]) -> (%9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)])
            linalg.CPU.CastTypeOp <name="model.layers.24.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=920, solved=0), )] (%9523:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=913)]) -> (%9540:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=920)])
            linalg.CPU.CastTypeOp <name="model.layers.24.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=920, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921, solved=0), )] (%9540:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=920)]) -> (%9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)])
            linalg.CPU.ConcatOp <name="model.layers.24.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27, solved=0), )] (%8256:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)]) -> (%9543:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)])
            linalg.CPU.ConcatOp <name="model.layers.24.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55, solved=0), )] (%8257:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)]) -> (%9544:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)])
            linalg.CPU.RepeatOp <name="model.layers.24.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27, solved=0), )] (%9543:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)]) -> (%9545:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)])
            linalg.CPU.RepeatOp <name="model.layers.24.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55, solved=0), )] (%9544:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)]) -> (%9546:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)])
            linalg.CPU.MatMulOp <name="model.layers.24.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922, solved=0), )] (%9530:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=914)], %9545:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=27)]) -> (%9547:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922)])
            linalg.CPU.MulOp <name="model.layers.24.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=923, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922, solved=0), )] (%9547:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922)], %9548:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=923), constant:[0.088388346]]) -> (%9549:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922)])
            linalg.CPU.ReduceMinOp <name="model.layers.24.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924, solved=0), )] (%9549:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922)]) -> (%9550:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924)])
            linalg.CPU.AddOp <name="model.layers.24.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=925, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924, solved=0), )] (%9550:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924)], %9551:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=925), constant:[-20]]) -> (%9552:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924)])
            linalg.CPU.EqualOp <name="model.layers.24.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=926, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=927, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9553:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=926), constant:[0]]) -> (%9554:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=927)])
            linalg.CPU.WhereOp <name="model.layers.24.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=927, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924, solved=0), )] (%9554:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=927)], %9549:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=922)], %9552:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924)]) -> (%9555:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924)])
            linalg.CPU.SoftmaxOp <name="model.layers.24.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=928, solved=0), )] (%9555:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=924)]) -> (%9556:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=928)])
            linalg.CPU.MatMulOp <name="model.layers.24.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=928, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929, solved=0), )] (%9556:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=928)], %9546:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=55)]) -> (%9557:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929)])
            linalg.CPU.TransposeOp <name="model.layers.24.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929, solved=0), )] (%9557:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929)]) -> (%9558:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929)])
            linalg.CPU.ViewOp <name="model.layers.24.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929, solved=0), )] (%9558:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929)]) -> (%9558:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929)])
            linalg.CPU.LinearOp <name="model.layers.24.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=931, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=930, solved=0))] (%9558:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=929)]) -> (%9559:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=931)])
            cf.ReturnOp (%9559:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=931)], %9539:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=919)], %9541:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=921)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.24.mlp <CPU> [using_qnn:true, symbol:model.layers.24.mlp] {
        (%9561:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=932)]) -> (%9567:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=940)]) {
            linalg.CPU.LinearOp <name="model.layers.24.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=932, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=935, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=934, solved=0))] (%9561:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=932)]) -> (%9562:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=935)])
            linalg.CPU.LinearOp <name="model.layers.24.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=932, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=936, solved=0))] (%9561:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=932)]) -> (%9563:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937)])
            linalg.CPU.SigmoidOp <name="model.layers.24.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=938, solved=0), )] (%9563:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937)]) -> (%9564:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=938)])
            linalg.CPU.MulOp <name="model.layers.24.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=938, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937, solved=0), )] (%9563:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937)], %9564:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=938)]) -> (%9565:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937)])
            linalg.CPU.MulOp <name="model.layers.24.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=935, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937, solved=0), )] (%9565:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937)], %9562:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=935)]) -> (%9566:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937)])
            linalg.CPU.LinearOp <name="model.layers.24.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=940, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=939, solved=0))] (%9566:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=937)]) -> (%9567:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=940)])
            cf.ReturnOp (%9567:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=940)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.25 <CPU> [using_qnn:true, symbol:model.layers.25] {
        (%9568:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8258:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)], %8259:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)]) -> (%9620:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)]) {
            linalg.CPU.RMSNormOp <name="model.layers.25.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=942, solved=0))] (%9568:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9569:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941)])
            graph.CallGraphOp @model.layers.25.self_attn (%9569:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8258:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)], %8259:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)]) -> (%9611:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=966)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)])
            linalg.CPU.AddOp <name="model.layers.25.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=966, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9568:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9611:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=966)]) -> (%9612:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.25.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=967, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=968, solved=0))] (%9612:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9613:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=967)])
            graph.CallGraphOp @model.layers.25.mlp (%9613:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=967)]) -> (%9619:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=975)])
            linalg.CPU.AddOp <name="model.layers.25.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=975, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9612:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9619:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=975)]) -> (%9620:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9620:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.25.self_attn <CPU> [using_qnn:true, symbol:model.layers.25.self_attn] {
        (%9569:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8258:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)], %8259:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)]) -> (%9611:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=966)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)]) {
            linalg.CPU.LinearOp <name="model.layers.25.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=943, solved=0))] (%9569:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941)]) -> (%9570:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944)])
            linalg.CPU.LinearOp <name="model.layers.25.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=945, solved=0))] (%9569:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941)]) -> (%9571:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946)])
            linalg.CPU.LinearOp <name="model.layers.25.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=947, solved=0))] (%9569:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=941)]) -> (%9572:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948)])
            linalg.CPU.ViewOp <name="model.layers.25.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944, solved=0), )] (%9570:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944)]) -> (%9570:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944)])
            linalg.CPU.TransposeOp <name="model.layers.25.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944, solved=0), )] (%9570:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944)]) -> (%9573:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944)])
            linalg.CPU.ViewOp <name="model.layers.25.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946, solved=0), )] (%9571:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946)]) -> (%9571:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946)])
            linalg.CPU.TransposeOp <name="model.layers.25.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946, solved=0), )] (%9571:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946)]) -> (%9574:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946)])
            linalg.CPU.ViewOp <name="model.layers.25.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948, solved=0), )] (%9572:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948)]) -> (%9572:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948)])
            linalg.CPU.TransposeOp <name="model.layers.25.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948, solved=0), )] (%9572:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948)]) -> (%9575:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948)])
            linalg.CPU.RMSNormOp <name="model.layers.25.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=950, solved=0))] (%9573:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=944)]) -> (%9576:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)])
            linalg.CPU.RMSNormOp <name="model.layers.25.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=952, solved=0))] (%9574:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=946)]) -> (%9577:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)])
            linalg.CPU.ViewOp <name="model.layers.25.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.25.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.25.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), )] (%9576:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)]) -> (%9576:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)])
            linalg.CPU.SliceOp <name="model.layers.25.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), )] (%9576:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)]) -> (%9576:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)])
            linalg.CPU.NegOp <name="model.layers.25.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), )] (%9576:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)]) -> (%9578:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)])
            linalg.CPU.ConcatOp <name="model.layers.25.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), )] (%9578:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)], %9576:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)]) -> (%9579:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)])
            linalg.CPU.MulOp <name="model.layers.25.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), )] (%9579:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9580:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)])
            linalg.CPU.MulOp <name="model.layers.25.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), )] (%9576:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9581:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)])
            linalg.CPU.AddOp <name="model.layers.25.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), )] (%9581:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)], %9580:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)]) -> (%9582:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)])
            linalg.CPU.SliceOp <name="model.layers.25.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), )] (%9577:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)]) -> (%9577:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)])
            linalg.CPU.SliceOp <name="model.layers.25.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), )] (%9577:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)]) -> (%9577:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)])
            linalg.CPU.NegOp <name="model.layers.25.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), )] (%9577:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)]) -> (%9583:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)])
            linalg.CPU.ConcatOp <name="model.layers.25.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), )] (%9583:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)], %9577:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)]) -> (%9584:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)])
            linalg.CPU.MulOp <name="model.layers.25.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), )] (%9584:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9585:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)])
            linalg.CPU.MulOp <name="model.layers.25.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), )] (%9577:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9586:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)])
            linalg.CPU.AddOp <name="model.layers.25.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), )] (%9586:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)], %9585:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)]) -> (%9587:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)])
            linalg.CPU.CastTypeOp <name="model.layers.25.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=953, solved=0), )] (%9587:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=951)]) -> (%9588:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=953)])
            linalg.CPU.CastTypeOp <name="model.layers.25.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=953, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954, solved=0), )] (%9588:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=953)]) -> (%9589:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)])
            linalg.CPU.TransposeOp <name="model.layers.25.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954, solved=0), )] (%9589:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)]) -> (%9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)])
            linalg.CPU.CastTypeOp <name="model.layers.25.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=955, solved=0), )] (%9575:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=948)]) -> (%9592:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=955)])
            linalg.CPU.CastTypeOp <name="model.layers.25.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=955, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956, solved=0), )] (%9592:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=955)]) -> (%9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)])
            linalg.CPU.ConcatOp <name="model.layers.25.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28, solved=0), )] (%8258:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)]) -> (%9595:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)])
            linalg.CPU.ConcatOp <name="model.layers.25.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56, solved=0), )] (%8259:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)]) -> (%9596:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)])
            linalg.CPU.RepeatOp <name="model.layers.25.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28, solved=0), )] (%9595:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)]) -> (%9597:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)])
            linalg.CPU.RepeatOp <name="model.layers.25.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56, solved=0), )] (%9596:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)]) -> (%9598:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)])
            linalg.CPU.MatMulOp <name="model.layers.25.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957, solved=0), )] (%9582:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=949)], %9597:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=28)]) -> (%9599:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957)])
            linalg.CPU.MulOp <name="model.layers.25.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=958, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957, solved=0), )] (%9599:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957)], %9600:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=958), constant:[0.088388346]]) -> (%9601:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957)])
            linalg.CPU.ReduceMinOp <name="model.layers.25.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959, solved=0), )] (%9601:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957)]) -> (%9602:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959)])
            linalg.CPU.AddOp <name="model.layers.25.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=960, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959, solved=0), )] (%9602:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959)], %9603:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=960), constant:[-20]]) -> (%9604:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959)])
            linalg.CPU.EqualOp <name="model.layers.25.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=961, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=962, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9605:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=961), constant:[0]]) -> (%9606:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=962)])
            linalg.CPU.WhereOp <name="model.layers.25.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=962, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959, solved=0), )] (%9606:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=962)], %9601:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=957)], %9604:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959)]) -> (%9607:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959)])
            linalg.CPU.SoftmaxOp <name="model.layers.25.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=963, solved=0), )] (%9607:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=959)]) -> (%9608:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=963)])
            linalg.CPU.MatMulOp <name="model.layers.25.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=963, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964, solved=0), )] (%9608:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=963)], %9598:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=56)]) -> (%9609:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964)])
            linalg.CPU.TransposeOp <name="model.layers.25.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964, solved=0), )] (%9609:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964)]) -> (%9610:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964)])
            linalg.CPU.ViewOp <name="model.layers.25.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964, solved=0), )] (%9610:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964)]) -> (%9610:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964)])
            linalg.CPU.LinearOp <name="model.layers.25.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=966, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=965, solved=0))] (%9610:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=964)]) -> (%9611:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=966)])
            cf.ReturnOp (%9611:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=966)], %9591:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=954)], %9593:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=956)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.25.mlp <CPU> [using_qnn:true, symbol:model.layers.25.mlp] {
        (%9613:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=967)]) -> (%9619:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=975)]) {
            linalg.CPU.LinearOp <name="model.layers.25.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=967, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=970, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=969, solved=0))] (%9613:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=967)]) -> (%9614:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=970)])
            linalg.CPU.LinearOp <name="model.layers.25.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=967, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=971, solved=0))] (%9613:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=967)]) -> (%9615:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972)])
            linalg.CPU.SigmoidOp <name="model.layers.25.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=973, solved=0), )] (%9615:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972)]) -> (%9616:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=973)])
            linalg.CPU.MulOp <name="model.layers.25.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=973, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972, solved=0), )] (%9615:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972)], %9616:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=973)]) -> (%9617:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972)])
            linalg.CPU.MulOp <name="model.layers.25.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=970, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972, solved=0), )] (%9617:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972)], %9614:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=970)]) -> (%9618:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972)])
            linalg.CPU.LinearOp <name="model.layers.25.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=975, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=974, solved=0))] (%9618:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=972)]) -> (%9619:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=975)])
            cf.ReturnOp (%9619:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=975)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.26 <CPU> [using_qnn:true, symbol:model.layers.26] {
        (%9620:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8260:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)], %8261:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)]) -> (%9672:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)]) {
            linalg.CPU.RMSNormOp <name="model.layers.26.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=977, solved=0))] (%9620:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9621:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976)])
            graph.CallGraphOp @model.layers.26.self_attn (%9621:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8260:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)], %8261:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)]) -> (%9663:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1001)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)])
            linalg.CPU.AddOp <name="model.layers.26.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1001, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9620:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9663:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1001)]) -> (%9664:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.26.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1002, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1003, solved=0))] (%9664:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9665:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1002)])
            graph.CallGraphOp @model.layers.26.mlp (%9665:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1002)]) -> (%9671:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1010)])
            linalg.CPU.AddOp <name="model.layers.26.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1010, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9664:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9671:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1010)]) -> (%9672:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9672:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.26.self_attn <CPU> [using_qnn:true, symbol:model.layers.26.self_attn] {
        (%9621:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8260:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)], %8261:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)]) -> (%9663:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1001)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)]) {
            linalg.CPU.LinearOp <name="model.layers.26.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=978, solved=0))] (%9621:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976)]) -> (%9622:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979)])
            linalg.CPU.LinearOp <name="model.layers.26.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=980, solved=0))] (%9621:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976)]) -> (%9623:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981)])
            linalg.CPU.LinearOp <name="model.layers.26.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=982, solved=0))] (%9621:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=976)]) -> (%9624:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983)])
            linalg.CPU.ViewOp <name="model.layers.26.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979, solved=0), )] (%9622:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979)]) -> (%9622:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979)])
            linalg.CPU.TransposeOp <name="model.layers.26.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979, solved=0), )] (%9622:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979)]) -> (%9625:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979)])
            linalg.CPU.ViewOp <name="model.layers.26.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981, solved=0), )] (%9623:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981)]) -> (%9623:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981)])
            linalg.CPU.TransposeOp <name="model.layers.26.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981, solved=0), )] (%9623:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981)]) -> (%9626:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981)])
            linalg.CPU.ViewOp <name="model.layers.26.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983, solved=0), )] (%9624:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983)]) -> (%9624:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983)])
            linalg.CPU.TransposeOp <name="model.layers.26.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983, solved=0), )] (%9624:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983)]) -> (%9627:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983)])
            linalg.CPU.RMSNormOp <name="model.layers.26.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=985, solved=0))] (%9625:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=979)]) -> (%9628:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)])
            linalg.CPU.RMSNormOp <name="model.layers.26.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=987, solved=0))] (%9626:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=981)]) -> (%9629:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)])
            linalg.CPU.ViewOp <name="model.layers.26.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.26.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.26.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), )] (%9628:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)]) -> (%9628:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)])
            linalg.CPU.SliceOp <name="model.layers.26.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), )] (%9628:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)]) -> (%9628:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)])
            linalg.CPU.NegOp <name="model.layers.26.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), )] (%9628:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)]) -> (%9630:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)])
            linalg.CPU.ConcatOp <name="model.layers.26.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), )] (%9630:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)], %9628:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)]) -> (%9631:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)])
            linalg.CPU.MulOp <name="model.layers.26.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), )] (%9631:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9632:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)])
            linalg.CPU.MulOp <name="model.layers.26.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), )] (%9628:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9633:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)])
            linalg.CPU.AddOp <name="model.layers.26.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), )] (%9633:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)], %9632:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)]) -> (%9634:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)])
            linalg.CPU.SliceOp <name="model.layers.26.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), )] (%9629:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)]) -> (%9629:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)])
            linalg.CPU.SliceOp <name="model.layers.26.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), )] (%9629:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)]) -> (%9629:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)])
            linalg.CPU.NegOp <name="model.layers.26.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), )] (%9629:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)]) -> (%9635:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)])
            linalg.CPU.ConcatOp <name="model.layers.26.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), )] (%9635:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)], %9629:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)]) -> (%9636:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)])
            linalg.CPU.MulOp <name="model.layers.26.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), )] (%9636:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9637:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)])
            linalg.CPU.MulOp <name="model.layers.26.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), )] (%9629:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9638:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)])
            linalg.CPU.AddOp <name="model.layers.26.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), )] (%9638:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)], %9637:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)]) -> (%9639:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)])
            linalg.CPU.CastTypeOp <name="model.layers.26.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=988, solved=0), )] (%9639:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=986)]) -> (%9640:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=988)])
            linalg.CPU.CastTypeOp <name="model.layers.26.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=988, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989, solved=0), )] (%9640:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=988)]) -> (%9641:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)])
            linalg.CPU.TransposeOp <name="model.layers.26.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989, solved=0), )] (%9641:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)]) -> (%9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)])
            linalg.CPU.CastTypeOp <name="model.layers.26.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=990, solved=0), )] (%9627:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=983)]) -> (%9644:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=990)])
            linalg.CPU.CastTypeOp <name="model.layers.26.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=990, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991, solved=0), )] (%9644:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=990)]) -> (%9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)])
            linalg.CPU.ConcatOp <name="model.layers.26.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29, solved=0), )] (%8260:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)]) -> (%9647:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)])
            linalg.CPU.ConcatOp <name="model.layers.26.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57, solved=0), )] (%8261:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)]) -> (%9648:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)])
            linalg.CPU.RepeatOp <name="model.layers.26.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29, solved=0), )] (%9647:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)]) -> (%9649:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)])
            linalg.CPU.RepeatOp <name="model.layers.26.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57, solved=0), )] (%9648:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)]) -> (%9650:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)])
            linalg.CPU.MatMulOp <name="model.layers.26.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992, solved=0), )] (%9634:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=984)], %9649:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=29)]) -> (%9651:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992)])
            linalg.CPU.MulOp <name="model.layers.26.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=993, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992, solved=0), )] (%9651:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992)], %9652:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=993), constant:[0.088388346]]) -> (%9653:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992)])
            linalg.CPU.ReduceMinOp <name="model.layers.26.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994, solved=0), )] (%9653:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992)]) -> (%9654:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994)])
            linalg.CPU.AddOp <name="model.layers.26.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=995, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994, solved=0), )] (%9654:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994)], %9655:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=995), constant:[-20]]) -> (%9656:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994)])
            linalg.CPU.EqualOp <name="model.layers.26.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=996, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=997, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9657:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=996), constant:[0]]) -> (%9658:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=997)])
            linalg.CPU.WhereOp <name="model.layers.26.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=997, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994, solved=0), )] (%9658:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=997)], %9653:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=992)], %9656:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994)]) -> (%9659:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994)])
            linalg.CPU.SoftmaxOp <name="model.layers.26.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=998, solved=0), )] (%9659:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=994)]) -> (%9660:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=998)])
            linalg.CPU.MatMulOp <name="model.layers.26.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=998, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999, solved=0), )] (%9660:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=998)], %9650:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=57)]) -> (%9661:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999)])
            linalg.CPU.TransposeOp <name="model.layers.26.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999, solved=0), )] (%9661:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999)]) -> (%9662:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999)])
            linalg.CPU.ViewOp <name="model.layers.26.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999, solved=0), )] (%9662:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999)]) -> (%9662:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999)])
            linalg.CPU.LinearOp <name="model.layers.26.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1001, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1000, solved=0))] (%9662:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=999)]) -> (%9663:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1001)])
            cf.ReturnOp (%9663:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1001)], %9643:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=989)], %9645:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=991)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.26.mlp <CPU> [using_qnn:true, symbol:model.layers.26.mlp] {
        (%9665:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1002)]) -> (%9671:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1010)]) {
            linalg.CPU.LinearOp <name="model.layers.26.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1002, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1005, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1004, solved=0))] (%9665:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1002)]) -> (%9666:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1005)])
            linalg.CPU.LinearOp <name="model.layers.26.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1002, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1006, solved=0))] (%9665:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1002)]) -> (%9667:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007)])
            linalg.CPU.SigmoidOp <name="model.layers.26.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1008, solved=0), )] (%9667:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007)]) -> (%9668:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1008)])
            linalg.CPU.MulOp <name="model.layers.26.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1008, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007, solved=0), )] (%9667:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007)], %9668:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1008)]) -> (%9669:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007)])
            linalg.CPU.MulOp <name="model.layers.26.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1005, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007, solved=0), )] (%9669:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007)], %9666:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1005)]) -> (%9670:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007)])
            linalg.CPU.LinearOp <name="model.layers.26.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1010, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1009, solved=0))] (%9670:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1007)]) -> (%9671:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1010)])
            cf.ReturnOp (%9671:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1010)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.27 <CPU> [using_qnn:true, symbol:model.layers.27] {
        (%9672:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8262:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)], %8263:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)]) -> (%9724:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)]) {
            linalg.CPU.RMSNormOp <name="model.layers.27.input_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1012, solved=0))] (%9672:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9673:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011)])
            graph.CallGraphOp @model.layers.27.self_attn (%9673:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8262:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)], %8263:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)]) -> (%9715:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1036)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)])
            linalg.CPU.AddOp <name="model.layers.27.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1036, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9672:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9715:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1036)]) -> (%9716:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            linalg.CPU.RMSNormOp <name="model.layers.27.post_attention_layernorm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1037, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1038, solved=0))] (%9716:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)]) -> (%9717:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1037)])
            graph.CallGraphOp @model.layers.27.mlp (%9717:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1037)]) -> (%9723:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1045)])
            linalg.CPU.AddOp <name="model.layers.27.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1045, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60, solved=0), )] (%9716:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9723:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1045)]) -> (%9724:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)])
            cf.ReturnOp (%9724:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=60)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.27.self_attn <CPU> [using_qnn:true, symbol:model.layers.27.self_attn] {
        (%9673:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)], %8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %8262:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)], %8263:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)]) -> (%9715:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1036)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)]) {
            linalg.CPU.LinearOp <name="model.layers.27.self_attn.q_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1013, solved=0))] (%9673:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011)]) -> (%9674:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014)])
            linalg.CPU.LinearOp <name="model.layers.27.self_attn.k_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1015, solved=0))] (%9673:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011)]) -> (%9675:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016)])
            linalg.CPU.LinearOp <name="model.layers.27.self_attn.v_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1017, solved=0))] (%9673:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1011)]) -> (%9676:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018)])
            linalg.CPU.ViewOp <name="model.layers.27.self_attn.View.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014, solved=0), )] (%9674:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014)]) -> (%9674:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014)])
            linalg.CPU.TransposeOp <name="model.layers.27.self_attn.Transpose.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014, solved=0), )] (%9674:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014)]) -> (%9677:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014)])
            linalg.CPU.ViewOp <name="model.layers.27.self_attn.View.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016, solved=0), )] (%9675:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016)]) -> (%9675:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016)])
            linalg.CPU.TransposeOp <name="model.layers.27.self_attn.Transpose.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016, solved=0), )] (%9675:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016)]) -> (%9678:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016)])
            linalg.CPU.ViewOp <name="model.layers.27.self_attn.View.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018, solved=0), )] (%9676:tensor<[1, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018)]) -> (%9676:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018)])
            linalg.CPU.TransposeOp <name="model.layers.27.self_attn.Transpose.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018, solved=0), )] (%9676:tensor<[1, 32, 8, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018)]) -> (%9679:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018)])
            linalg.CPU.RMSNormOp <name="model.layers.27.self_attn.q_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1020, solved=0))] (%9677:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1014)]) -> (%9680:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)])
            linalg.CPU.RMSNormOp <name="model.layers.27.self_attn.k_norm"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), weight_weight:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1022, solved=0))] (%9678:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1016)]) -> (%9681:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)])
            linalg.CPU.ViewOp <name="model.layers.27.self_attn.View.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), )] (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)])
            linalg.CPU.ViewOp <name="model.layers.27.self_attn.View.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), )] (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)])
            linalg.CPU.SliceOp <name="model.layers.27.self_attn.Slice.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), )] (%9680:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)]) -> (%9680:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)])
            linalg.CPU.SliceOp <name="model.layers.27.self_attn.Slice.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), )] (%9680:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)]) -> (%9680:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)])
            linalg.CPU.NegOp <name="model.layers.27.self_attn.Neg.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), )] (%9680:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)]) -> (%9682:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)])
            linalg.CPU.ConcatOp <name="model.layers.27.self_attn.Concat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), )] (%9682:tensor<[1, 16, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)], %9680:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)]) -> (%9683:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)])
            linalg.CPU.MulOp <name="model.layers.27.self_attn.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), )] (%9683:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9684:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)])
            linalg.CPU.MulOp <name="model.layers.27.self_attn.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), )] (%9680:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9685:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)])
            linalg.CPU.AddOp <name="model.layers.27.self_attn.Add.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), )] (%9685:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)], %9684:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)]) -> (%9686:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)])
            linalg.CPU.SliceOp <name="model.layers.27.self_attn.Slice.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), )] (%9681:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)]) -> (%9681:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)])
            linalg.CPU.SliceOp <name="model.layers.27.self_attn.Slice.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), )] (%9681:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)]) -> (%9681:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)])
            linalg.CPU.NegOp <name="model.layers.27.self_attn.Neg.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), )] (%9681:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)]) -> (%9687:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)])
            linalg.CPU.ConcatOp <name="model.layers.27.self_attn.Concat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), )] (%9687:tensor<[1, 8, 32, 64], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)], %9681:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)]) -> (%9688:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)])
            linalg.CPU.MulOp <name="model.layers.27.self_attn.Mul.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), )] (%9688:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)], %8267:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=63)]) -> (%9689:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)])
            linalg.CPU.MulOp <name="model.layers.27.self_attn.Mul.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), )] (%9681:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)], %8268:tensor<[1, 1, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32), uuid=65)]) -> (%9690:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)])
            linalg.CPU.AddOp <name="model.layers.27.self_attn.Add.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), )] (%9690:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)], %9689:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)]) -> (%9691:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)])
            linalg.CPU.CastTypeOp <name="model.layers.27.self_attn.CastType.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=1023, solved=0), )] (%9691:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1021)]) -> (%9692:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=1023)])
            linalg.CPU.CastTypeOp <name="model.layers.27.self_attn.CastType.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=1023, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024, solved=0), )] (%9692:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=1023)]) -> (%9693:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)])
            linalg.CPU.TransposeOp <name="model.layers.27.self_attn.Transpose.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024, solved=0), )] (%9693:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)]) -> (%9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)])
            linalg.CPU.CastTypeOp <name="model.layers.27.self_attn.CastType.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018, solved=0), outputs_0:QuantSpec(Raw(type: Float16), uuid=1025, solved=0), )] (%9679:tensor<[1, 8, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1018)]) -> (%9696:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=1025)])
            linalg.CPU.CastTypeOp <name="model.layers.27.self_attn.CastType.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: Float16), uuid=1025, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026, solved=0), )] (%9696:tensor<[1, 8, 32, 128], Float16, CPU>[quant_recipe:QuantSpec(Raw(type: Float16), uuid=1025)]) -> (%9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)])
            linalg.CPU.ConcatOp <name="model.layers.27.self_attn.Concat.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30, solved=0), )] (%8262:tensor<[1, 8, 128, 992], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)]) -> (%9699:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)])
            linalg.CPU.ConcatOp <name="model.layers.27.self_attn.Concat.3"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58, solved=0), )] (%8263:tensor<[1, 8, 992, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)]) -> (%9700:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)])
            linalg.CPU.RepeatOp <name="model.layers.27.self_attn.Repeat.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30, solved=0), )] (%9699:tensor<[1, 8, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)]) -> (%9701:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)])
            linalg.CPU.RepeatOp <name="model.layers.27.self_attn.Repeat.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58, solved=0), outputs_0:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58, solved=0), )] (%9700:tensor<[1, 8, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)]) -> (%9702:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)])
            linalg.CPU.MatMulOp <name="model.layers.27.self_attn.MatMul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027, solved=0), )] (%9686:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1019)], %9701:tensor<[1, 16, 128, 1024], Int8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: -128, quant_max: 127, quant_to_type: Int8, scale_type: Float32), uuid=30)]) -> (%9703:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027)])
            linalg.CPU.MulOp <name="model.layers.27.self_attn.Mul.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1028, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027, solved=0), )] (%9703:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027)], %9704:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1028), constant:[0.088388346]]) -> (%9705:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027)])
            linalg.CPU.ReduceMinOp <name="model.layers.27.self_attn.ReduceMin.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029, solved=0), )] (%9705:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027)]) -> (%9706:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029)])
            linalg.CPU.AddOp <name="model.layers.27.self_attn.Add.2"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1030, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029, solved=0), )] (%9706:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029)], %9707:tensor<[1], Float32, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1030), constant:[-20]]) -> (%9708:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029)])
            linalg.CPU.EqualOp <name="model.layers.27.self_attn.Equal.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt16), uuid=2, solved=0), inputs_1:QuantSpec(Raw(type: UInt16), uuid=1031, solved=0), outputs_0:QuantSpec(Raw(type: UInt8), uuid=1032, solved=0), )] (%8207:tensor<[1, 1, 32, 1024], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=2)], %9709:tensor<[1], UInt16, CPU>[quant_recipe:QuantSpec(Raw(type: UInt16), uuid=1031), constant:[0]]) -> (%9710:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=1032)])
            linalg.CPU.WhereOp <name="model.layers.27.self_attn.Where.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(Raw(type: UInt8), uuid=1032, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027, solved=0), inputs_2:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029, solved=0), )] (%9710:tensor<[1, 1, 32, 1024], UInt8, CPU>[quant_recipe:QuantSpec(Raw(type: UInt8), uuid=1032)], %9705:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1027)], %9708:tensor<[1, 16, 32, 1], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029)]) -> (%9711:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029)])
            linalg.CPU.SoftmaxOp <name="model.layers.27.self_attn.Softmax.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1033, solved=0), )] (%9711:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1029)]) -> (%9712:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1033)])
            linalg.CPU.MatMulOp <name="model.layers.27.self_attn.MatMul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1033, solved=0), inputs_1:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034, solved=0), )] (%9712:tensor<[1, 16, 32, 1024], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1033)], %9702:tensor<[1, 16, 1024, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=58)]) -> (%9713:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034)])
            linalg.CPU.TransposeOp <name="model.layers.27.self_attn.Transpose.4"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034, solved=0), )] (%9713:tensor<[1, 16, 32, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034)]) -> (%9714:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034)])
            linalg.CPU.ViewOp <name="model.layers.27.self_attn.View.5"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034, solved=0), )] (%9714:tensor<[1, 32, 16, 128], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034)]) -> (%9714:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034)])
            linalg.CPU.LinearOp <name="model.layers.27.self_attn.o_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1036, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1035, solved=0))] (%9714:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1034)]) -> (%9715:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1036)])
            cf.ReturnOp (%9715:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1036)], %9695:tensor<[1, 8, 128, 32], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1024)], %9697:tensor<[1, 8, 32, 128], UInt8PerTensor, CPU>[quant_recipe:QuantSpec(SymPerTensor(quant_min: 0, quant_max: 255, quant_to_type: UInt8, scale_type: Float32), uuid=1026)]) -> ()
        }
    }
    graph.SubGraphOp @model.layers.27.mlp <CPU> [using_qnn:true, symbol:model.layers.27.mlp] {
        (%9717:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1037)]) -> (%9723:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1045)]) {
            linalg.CPU.LinearOp <name="model.layers.27.mlp.up_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1037, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1040, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1039, solved=0))] (%9717:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1037)]) -> (%9718:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1040)])
            linalg.CPU.LinearOp <name="model.layers.27.mlp.gate_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1037, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1041, solved=0))] (%9717:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1037)]) -> (%9719:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042)])
            linalg.CPU.SigmoidOp <name="model.layers.27.mlp.Unknown.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1043, solved=0), )] (%9719:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042)]) -> (%9720:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1043)])
            linalg.CPU.MulOp <name="model.layers.27.mlp.Mul.0"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1043, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042, solved=0), )] (%9719:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042)], %9720:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65535, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1043)]) -> (%9721:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042)])
            linalg.CPU.MulOp <name="model.layers.27.mlp.Mul.1"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042, solved=0), inputs_1:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1040, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042, solved=0), )] (%9721:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042)], %9718:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1040)]) -> (%9722:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042)])
            linalg.CPU.LinearOp <name="model.layers.27.mlp.down_proj"> [quant_recipe:QuantAnnotation(inputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042, solved=0), outputs_0:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1045, solved=0), weight_weight:QuantSpec(LPBQ(quant_min: -8, quant_max: 7, block_size: 32, ch_axis: -1, scale_level_0_bitwidth: 4, quant_to_type: UInt4, scale_1_type: Float32), uuid=1044, solved=0))] (%9722:tensor<[1, 32, 6144], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1042)]) -> (%9723:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1045)])
            cf.ReturnOp (%9723:tensor<[1, 32, 2048], UInt16PerTensor, CPU>[quant_recipe:QuantSpec(AsymPerTensor(quant_min: 0, quant_max: 65536, quant_to_type: UInt16, scale_type: Float32, zero_point_type: Int32), uuid=1045)]) -> ()
        }
    }
    //        
    //      o o    
    //            
    //       
    //             
    //        
}
 
