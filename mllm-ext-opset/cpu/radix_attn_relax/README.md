# Radix Attention Relax

The radix attention in mllm suppose that qkv has some dim. But some models does not match this assumption. So we create a relax version of radix attention to support any dim.
