/**
 * @file mllm.cpp
 * @author chenghua Wang (chenghua.wang.edu@gmail.com)
 * @brief
 * @version 0.1
 * @date 2025-07-22
 *
 * @copyright Copyright (c) 2025
 *
 */
#include "mllm/mllm.hpp"
#include "mllm/engine/Context.hpp"

namespace mllm {

void initializeContext() {
  // TODO
}

void shutdownContext() {
  // TODO
}

void setRandomSeed(uint32_t seed) {
  // TODO
}

void setMaximumNumThreads(uint32_t num_threads) {
  // TODO
}

void memoryReport() {
  // TODO
}

bool isOpenCLAvailable() {
  // TODO
  return false;
}

bool isQnnAvailable() {
  // TODO
  return false;
}

}  // namespace mllm
